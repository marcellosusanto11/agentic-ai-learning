{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b3e4020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup Keys\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b709fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "auth.authenticate_user()\n",
    "gmail_service = build('gmail', 'v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f84dd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain.agents import create_agent\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.messages import AnyMessage, HumanMessage, AIMessage, SystemMessage, ToolMessage\n",
    "from langchain.tools import tool\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.types import interrupt, Command\n",
    "from typing import TypedDict, Annotated, List\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "import re\n",
    "import ast\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "import gspread\n",
    "from google.auth import default\n",
    "import pandas as pd\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import base64\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "# Initialize ChromaDB client\n",
    "client = chromadb.Client(Settings(\n",
    "    persist_directory=\"/content/chroma_db\",\n",
    "    anonymized_telemetry=False\n",
    "))\n",
    "\n",
    "# Create or get collection\n",
    "collection = client.get_or_create_collection(\n",
    "    name=\"user_personas\",\n",
    "    metadata={\"description\": \"User persona and preference data\"}\n",
    ")\n",
    "\n",
    "###########\n",
    "# UTILITY #\n",
    "###########\n",
    "def extract_dict_from_string(text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extract and convert a dictionary from a string that may contain extra text.\n",
    "    Tries JSON first, then falls back to ast.literal_eval.\n",
    "    \"\"\"\n",
    "    # Strip markdown code fences if present\n",
    "    cleaned = text.strip()\n",
    "\n",
    "    if re.search(r'```json', cleaned):\n",
    "      list_substr = cleaned.split(\"```json\")\n",
    "      cleaned = list_substr[1]\n",
    "    if re.search(r'```', cleaned):\n",
    "      list_substr = cleaned.split(\"```\")\n",
    "      cleaned = list_substr[0]\n",
    "\n",
    "    cleaned = cleaned.strip()\n",
    "\n",
    "    try:\n",
    "        result = json.loads(cleaned)\n",
    "        if isinstance(result, dict):\n",
    "            return result\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "\n",
    "    print(f\"❌ Failed to extract dict from response:\\n{text[:200]}\")\n",
    "    return {}\n",
    "\n",
    "def sync_personas_from_sheets(url:str, df_append:pd.DataFrame = pd.DataFrame()):\n",
    "    \"\"\"Sync persona data from Google Sheets to ChromaDB\"\"\"\n",
    "\n",
    "    # Get latest data from sheet\n",
    "    creds, _ = default()\n",
    "    gc = gspread.authorize(creds)\n",
    "    sheet = gc.open_by_url(url).sheet1\n",
    "    data = sheet.get_all_records()\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Append new info\n",
    "    df = pd.DataFrame\n",
    "\n",
    "    # Clear existing collection\n",
    "    client.delete_collection(\"user_personas\")\n",
    "    collection = client.create_collection(\"user_personas\")\n",
    "\n",
    "    # Re-populate\n",
    "    documents = []\n",
    "    metadatas = []\n",
    "    ids = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        doc_text = \" | \".join([f\"{k}: {v}\" for k, v in row.items()])\n",
    "        documents.append(doc_text)\n",
    "        metadatas.append({key: str(value) for key, value in row.items()})\n",
    "        ids.append(f\"user_{idx}\")\n",
    "\n",
    "    collection.add(documents=documents, metadatas=metadatas, ids=ids)\n",
    "    print(f\"✅ Synced {len(documents)} personas from Google Sheets\")\n",
    "\n",
    "    return collection\n",
    "\n",
    "##########\n",
    "# PROMPT #\n",
    "##########\n",
    "BASE_PROMPT = \"\"\"\n",
    "  ROLE\n",
    "  You are an intelligent Email Classification Agent designed to help busy professionals manage their inbox efficiently by categorizing incoming emails based on urgency, relevance, and required action.\n",
    "\n",
    "  # BACKGROUND: USER PERSONA\n",
    "  You are assisting {name}, a {persona}\n",
    "\"\"\"\n",
    "\n",
    "PROMPT_ROUTER = \"\"\"\n",
    "  {base_prompt}\n",
    "\n",
    "  INSTRUCTION\n",
    "  Classify user intent\n",
    "\n",
    "  Use \"email_workflow\" if:\n",
    "    - User provides an email to analyze/classify\n",
    "    - User asks to draft/send an email\n",
    "    - User mentions responding to an email\n",
    "\n",
    "    Use \"general_query\" if:\n",
    "    - User asks about calendar availability\n",
    "    - User asks to schedule a meeting (without email context)\n",
    "    - General questions or requests\n",
    "\n",
    "  INPUT\n",
    "  {message}\n",
    "\n",
    "  OUTPUT, in json format\n",
    "  ```json\n",
    "  name : [The inferred user name]\n",
    "  user_intent : [email_workflow/general_query]\n",
    "  ```\n",
    "\"\"\"\n",
    "\n",
    "PROMPT_PERSONA = \"\"\"\n",
    "  ROLE\n",
    "  You are an AI that can help inferred the user persona based on the chain of message asked by that user\n",
    "\n",
    "  INPUT\n",
    "  {conversation}\n",
    "\n",
    "  OUTPUT\n",
    "  Summary of the user persona\n",
    "\"\"\"\n",
    "\n",
    "PROMPT_TRIAGE = \"\"\"\n",
    "  {base_prompt}\n",
    "\n",
    "  # INSTRUCTION\n",
    "  For each incoming email, analyze its content, sender, subject, and context to categorize it into one of three actions: IGNORE, NOTIFY, or RESPOND.\n",
    "\n",
    "  # RULES: EMAIL CATEGORY DEFINITIONS\n",
    "\n",
    "  ## IGNORE\n",
    "  Emails that require NO action and NO attention.\n",
    "\n",
    "  **Criteria:**\n",
    "  Marketing newsletters, spam emails, mass company announcements\n",
    "\n",
    "  ## NOTIFY\n",
    "  Emails that Marcel should be AWARE of but don't require immediate response.\n",
    "\n",
    "  **Criteria:**\n",
    "  Team member out sick, build system notifications, project status updates\n",
    "\n",
    "  ## RESPOND\n",
    "  Emails that require Marcel's direct action, response, or decision.\n",
    "\n",
    "  **Criteria:**\n",
    "  Direct questions from team members, meeting requests, critical bug reports\n",
    "\n",
    "  INPUT\n",
    "  Email : {email}\n",
    "\n",
    "  OUTPUT, in json format\n",
    "  ```json\n",
    "  from : [The sender of the email]\n",
    "  to : [The user that get the email]\n",
    "  subject : [The subject of the email]\n",
    "  email_content : [The content of the email]\n",
    "  email_classification : [IGNORE/NOTIFY/RESPOND]\n",
    "  classification_reason : [The reason behind the value of email_classification]\n",
    "  ```\n",
    "\"\"\"\n",
    "\n",
    "PROMPT_RESPOND = \"\"\"\n",
    "  {base_prompt}\n",
    "\n",
    "  INSTRUCTION\n",
    "  Draft and call send_email tool with :\n",
    "  - to_email: recipient's email address\n",
    "  - subject: email subject line\n",
    "  - body: the complete email you drafted\n",
    "\n",
    "  INPUT\n",
    "  From : {from}\n",
    "  To : {to}\n",
    "  Subject : {subject}\n",
    "  Content : {email_content}\n",
    "\n",
    "  OUTPUT, in json format\n",
    "  ```json\n",
    "  respond_subject : [Subject of the respond email based on user persona]\n",
    "  respond_content : [Content of the respond email based on user persona]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "########\n",
    "# TOOL #\n",
    "########\n",
    "@tool\n",
    "def send_email(to_email: str, subject: str, body: str) -> str:\n",
    "  \"\"\"\n",
    "  Actually send an email via Gmail API.\n",
    "  The LLM should provide the to_email, subject, and body.\n",
    "\n",
    "  Args:\n",
    "      to_email: Recipient email address\n",
    "      subject: Email subject line\n",
    "      body: Complete email body (already drafted by LLM)\n",
    "\n",
    "  Returns:\n",
    "      Confirmation message\n",
    "  \"\"\"\n",
    "\n",
    "  try:\n",
    "      # Create message\n",
    "      message = MIMEText(body, 'plain')\n",
    "      message['to'] = to_email\n",
    "      message['subject'] = subject\n",
    "\n",
    "      # Encode message\n",
    "      raw_message = base64.urlsafe_b64encode(message.as_bytes()).decode('utf-8')\n",
    "\n",
    "      # Send email\n",
    "      send_message = gmail_service.users().messages().send(\n",
    "          userId='me',\n",
    "          body={'raw': raw_message}\n",
    "      ).execute()\n",
    "\n",
    "      return f\"✅ Email sent successfully to {to_email}! Message ID: {send_message['id']}\"\n",
    "\n",
    "  except Exception as e:\n",
    "      return f\"❌ Failed to send email: {str(e)}\"\n",
    "\n",
    "\n",
    "#########\n",
    "# AGENT #\n",
    "#########\n",
    "class AgentState(TypedDict):\n",
    "  task: str\n",
    "  name: str\n",
    "  persona: str\n",
    "  user_intent: str\n",
    "  sender: str\n",
    "  email_subject: str\n",
    "  email_content: str\n",
    "  email_classification: str\n",
    "  classification_reason: str\n",
    "  email_respond_subject: str\n",
    "  email_respond_content: str\n",
    "\n",
    "class EmailAgent:\n",
    "  def __init__(self, tools, middleware):\n",
    "    self.config = {'configurable': {'thread_id': 101}}\n",
    "    self.checkpointer = InMemorySaver()\n",
    "\n",
    "    # Store tools as dictionary\n",
    "    self.tools = {t.name: t for t in tools}\n",
    "\n",
    "    # create LLM with tool binding\n",
    "    self.llm = init_chat_model(\n",
    "        model=\"claude-haiku-4-5-20251001\",\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    # Bind tools to the model\n",
    "    self.llm_with_tools = self.llm.bind_tools(tools)\n",
    "\n",
    "    # to initiate the Graph\n",
    "    self.graph = StateGraph(AgentState)\n",
    "    self.graph.add_node('router', self.call_agent_plan)\n",
    "    self.graph.add_node('persona', self.call_get_user_persona)\n",
    "    self.graph.add_edge('router', 'persona')\n",
    "    self.graph.add_node('generate', self.call_agent_generate)\n",
    "    self.graph.add_edge('research', 'generate')\n",
    "    self.graph.add_conditional_edges(\n",
    "        'generate',\n",
    "        self.check_revision_iteration,\n",
    "        {True: 'reflect', False: END})\n",
    "    self.graph.add_node('reflect', self.call_agent_reflect)\n",
    "    self.graph.add_edge('reflect', 'research')\n",
    "    self.graph.set_entry_point('plan')\n",
    "\n",
    "    self.graph_np = self.graph.compile(\n",
    "        checkpointer=self.checkpointer,\n",
    "        )\n",
    "\n",
    "  def _update_state(self, new_dict:dict, state: AgentState):\n",
    "    \"\"\"Check whether the state will be updated based on the JSON output from the LLM response \"\"\"\n",
    "    for key, value in new_dict.items():\n",
    "      if key in state:\n",
    "        print(f\"  ✅ Updated '{key}'\")\n",
    "      else:\n",
    "        print(f\"  ⚠️  Unknown key '{key}' - skipped\")\n",
    "\n",
    "  def call_agent_router(self, state:AgentState):\n",
    "\n",
    "    # Initial sync of the user persona data\n",
    "    sync_personas_from_sheets(\"https://docs.google.com/spreadsheets/d/1Kg-j1_zjdk2UJdVNQanTsF_mLu8S4X9LuXYiBLOBWGA/edit?gid=0#gid=0\")\n",
    "\n",
    "    # Invoke LLM\n",
    "    message = HumanMessage(content = PROMPT_ROUTER.format(\n",
    "        base_prompt=BASE_PROMPT,\n",
    "        message=state['task'],\n",
    "      )\n",
    "    )\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ROUTING}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    result = self.llm.invoke(message)\n",
    "    json_result = extract_dict_from_string(result.content)\n",
    "    self._update_state(json_result, state)\n",
    "\n",
    "    print(f\"\\nUser : {json_result.get('name', '')}\")\n",
    "    print(f\"\\Task Type : {json_result.get('user_intent', '')}\")\n",
    "\n",
    "    return {\n",
    "      'name': json_result.get('name', ''),\n",
    "      'user_intent': json_result.get('user_intent', ''),\n",
    "    }\n",
    "\n",
    "  def call_get_user_persona(self, state:AgentState):\n",
    "    \"\"\" Retrieve user persona and preference information \"\"\"\n",
    "\n",
    "    # Filter by specific user\n",
    "    result = collection.get(\n",
    "          where={\"name\": state['name']}\n",
    "      )\n",
    "\n",
    "    if len(result['metadata']) > 0 :\n",
    "      print(f\"✅ User Persona {state['name']} found, proceed with it\")\n",
    "\n",
    "      return result['metadata'][0]\n",
    "\n",
    "    else:\n",
    "      if state['']\n",
    "      print(f\"❌ No user persona found, proceed with default\")\n",
    "      result = {\n",
    "          'name':state['name'],\n",
    "          'persona':'User not specified, treat it as default persona'\n",
    "      }\n",
    "\n",
    "  def execute(self, message) :\n",
    "    \"\"\"Function to run the agent graph flow\"\"\"\n",
    "\n",
    "    self.input_message = message\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TOPIC FROM THE USER\")\n",
    "    print(f\"{'='*60}\")\n",
    "    pprint(f\"{self.input_message}\")\n",
    "\n",
    "    # ✅ Initialize ALL required state fields\n",
    "    initial_state = {\n",
    "        'task': self.input_message,\n",
    "        'name': '',\n",
    "        'persona': '',\n",
    "        'user_intent': '',\n",
    "        'sender': '',\n",
    "        'email_subject': '',\n",
    "        'email_content' : '',\n",
    "        'email_classification': '',\n",
    "        'classification_reason': '',\n",
    "        'email_respond_subject': '',\n",
    "        'email_respond_content' : ''\n",
    "    }\n",
    "\n",
    "    # Run the graph\n",
    "    result = self.graph_np.invoke(\n",
    "        initial_state,\n",
    "        config=self.config\n",
    "    )\n",
    "\n",
    "    # Get final answer\n",
    "    final_answer = result['essay']\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
