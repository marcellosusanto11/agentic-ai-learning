{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "q52_-d_bHTe6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup Keys\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.10\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fn8IlbCrJg6s"
   },
   "source": [
    "# EssayMaker with Agent Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "0TQrL_OQHU_X",
    "outputId": "f1aaa172-26b3-4380-bd1a-6ee86d093679"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain.agents import create_agent\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.messages import AnyMessage, HumanMessage, AIMessage, SystemMessage, ToolMessage\n",
    "from langchain.tools import tool\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.types import interrupt, Command\n",
    "from typing import TypedDict, Annotated, List\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "import re\n",
    "import ast\n",
    "import json\n",
    "import hashlib\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from pprint import pprint\n",
    "\n",
    "# Utility function\n",
    "def extract_dict_from_string(text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extract and convert a dictionary from a string that may contain extra text.\n",
    "    Tries JSON first, then falls back to ast.literal_eval.\n",
    "    \"\"\"\n",
    "    # Strip markdown code fences if present\n",
    "    cleaned = text.strip()\n",
    "\n",
    "    if re.search(r'```json', cleaned):\n",
    "      list_substr = cleaned.split(\"```json\")\n",
    "      cleaned = list_substr[1]\n",
    "    if re.search(r'```', cleaned):\n",
    "      list_substr = cleaned.split(\"```\")\n",
    "      cleaned = list_substr[0]\n",
    "\n",
    "    cleaned = cleaned.strip()\n",
    "\n",
    "    try:\n",
    "        result = json.loads(cleaned)\n",
    "        if isinstance(result, dict):\n",
    "            return result\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "\n",
    "    print(f\"âŒ Failed to extract dict from response:\\n{text[:200]}\")\n",
    "    return {}\n",
    "\n",
    "# Build tool\n",
    "search_tool = TavilySearchResults(max_results=2)\n",
    "\n",
    "# Research Memory - abstracted storage for future migration to Supabase/pgvector\n",
    "class ResearchMemory:\n",
    "    \"\"\"Abstracted research memory. ChromaDB now, Supabase/pgvector for production.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.client = chromadb.Client(Settings(anonymized_telemetry=False))\n",
    "\n",
    "        # Collection for research results (shared across all users)\n",
    "        self.research_collection = self.client.get_or_create_collection(\n",
    "            name=\"essay_research\",\n",
    "            metadata={\"description\": \"Cached research from Tavily searches\"}\n",
    "        )\n",
    "\n",
    "        # Collection for user preferences (per user_id, built from feedback over time)\n",
    "        self.preference_collection = self.client.get_or_create_collection(\n",
    "            name=\"user_preferences\",\n",
    "            metadata={\"description\": \"User essay preferences learned from feedback\"}\n",
    "        )\n",
    "\n",
    "    # --- Research Memory ---\n",
    "    def store_research(self, research_text: str, outline: str, revision: int):\n",
    "        \"\"\"Store research results for future retrieval. Shared across all users.\"\"\"\n",
    "        doc_id = hashlib.md5(research_text[:200].encode()).hexdigest()\n",
    "        self.research_collection.upsert(\n",
    "            documents=[research_text],\n",
    "            metadatas=[{\n",
    "                \"outline_snippet\": outline[:500],\n",
    "                \"revision\": str(revision)\n",
    "            }],\n",
    "            ids=[doc_id]\n",
    "        )\n",
    "        print(f\"  âœ… Stored research in memory (id: {doc_id[:8]}...)\")\n",
    "\n",
    "    def retrieve_research(self, query: str, n_results: int = 3) -> str:\n",
    "        \"\"\"Retrieve existing research relevant to the query. Searches across all users.\"\"\"\n",
    "        if self.research_collection.count() == 0:\n",
    "            print(f\"  â„¹ï¸  Research memory is empty\")\n",
    "            return \"\"\n",
    "        results = self.research_collection.query(\n",
    "            query_texts=[query],\n",
    "            n_results=n_results\n",
    "        )\n",
    "        if results['documents'] and results['documents'][0]:\n",
    "            print(f\"  âœ… Found {len(results['documents'][0])} existing research entries\")\n",
    "            return \"\\n---\\n\".join(results['documents'][0])\n",
    "        print(f\"  â„¹ï¸  No relevant research found in memory\")\n",
    "        return \"\"\n",
    "\n",
    "    def clear_research(self):\n",
    "        \"\"\"Clear research for a fresh essay topic.\"\"\"\n",
    "        self.client.delete_collection(\"essay_research\")\n",
    "        self.research_collection = self.client.get_or_create_collection(name=\"essay_research\")\n",
    "        print(f\"  âœ… Research memory cleared\")\n",
    "\n",
    "    # --- User Preference Memory ---\n",
    "    def store_feedback(self, user_id: str, requirement: str, feedback: str, score: int):\n",
    "        \"\"\"Store user feedback to learn preferences over time.\"\"\"\n",
    "        doc_id = hashlib.md5(f\"{user_id}_{requirement[:100]}_{score}\".encode()).hexdigest()\n",
    "        self.preference_collection.upsert(\n",
    "            documents=[f\"Requirement: {requirement}\\nFeedback: {feedback}\\nScore: {score}\"],\n",
    "            metadatas=[{\n",
    "                \"user_id\": user_id,\n",
    "                \"score\": str(score),\n",
    "                \"requirement_snippet\": requirement[:500]\n",
    "            }],\n",
    "            ids=[doc_id]\n",
    "        )\n",
    "        print(f\"  âœ… Stored user feedback for preference learning\")\n",
    "\n",
    "    def retrieve_preferences(self, user_id: str, topic: str, n_results: int = 3) -> str:\n",
    "        \"\"\"Retrieve past feedback for a user to personalize future essays.\"\"\"\n",
    "        if self.preference_collection.count() == 0:\n",
    "            return \"\"\n",
    "        results = self.preference_collection.query(\n",
    "            query_texts=[topic],\n",
    "            n_results=n_results,\n",
    "            where={\"user_id\": user_id}\n",
    "        )\n",
    "        if results['documents'] and results['documents'][0]:\n",
    "            print(f\"  âœ… Found {len(results['documents'][0])} past preference entries for user '{user_id}'\")\n",
    "            return \"\\n---\\n\".join(results['documents'][0])\n",
    "        return \"\"\n",
    "\n",
    "# Setup prompt for each task\n",
    "PROMPT_PLAN = \"\"\"\n",
    "  You are an expert essay planner. Your job is to create a detailed and well-structured outline for an essay that will be no longer than 5 paragraphs\n",
    "\n",
    "  Given the topic and requirements from the user, you must produce an outline that includes:\n",
    "  1. A strong thesis statement\n",
    "  2. An introduction section with a hook and context\n",
    "  3. 3-5 main body sections, each with:\n",
    "    - A clear section title\n",
    "    - 2-3 key points to cover\n",
    "    - A brief description of what each point should address\n",
    "  4. A conclusion section that ties everything together\n",
    "\n",
    "  Guidelines:\n",
    "  - The outline should be logical and flow naturally from one section to the next\n",
    "  - Each section should build upon the previous one\n",
    "  - Make sure the outline directly addresses the user's requirements\n",
    "  - Tailor the depth and complexity to match the required essay length and academic level\n",
    "\n",
    "  User Input:\n",
    "  {user_input}\n",
    "\n",
    "  Agent Output in JSON Format where \"\" represent the keys :\n",
    "  - \"requirement\", derrived from user input\n",
    "  - \"outline\", the outline produced by the agent based on the prompt\n",
    "  - \"max_revisions\", the maximum revision of the draft essay based on the user input, if it's not specified by the user return 0\n",
    "  - \"max_web_search\", the maximum web search that can be done by the agent based on the user input, if it's not specified by the user return 0\n",
    "\"\"\"\n",
    "\n",
    "PROMPT_RESEARCH = \"\"\"\n",
    "  You are an expert research assistant. Your job is to gather relevant information and sources to support an essay based on a given outline.\n",
    "  If the feedback is not empty, focus on doing search to help gain information to assess the feedback\n",
    "  You can do up to {max_web_search} searches.\n",
    "\n",
    "  **Existing Research from Previous Iterations:**\n",
    "  The following research has already been gathered. Use this as context â€” you may skip topics\n",
    "  already well-covered and focus your search quota on gaps or feedback-driven areas.\n",
    "  You are free to use your full search quota if you believe the existing research is insufficient.\n",
    "  If the existing research is empty, proceed with full research.\n",
    "\n",
    "  Existing Research:\n",
    "  {existing_research}\n",
    "\n",
    "  For each section and key point in the outline, you must:\n",
    "  1. Review the existing research above to see what's already covered\n",
    "  2. Search the web for points that need new or better sources\n",
    "  3. Extract key facts, statistics, quotes, or arguments that support the point\n",
    "  4. Note the source URL and title for citation purposes\n",
    "  5. Prioritize recent and authoritative sources (academic journals, reputable news, official reports)\n",
    "\n",
    "  Guidelines:\n",
    "  - Search for each main section and key point separately to ensure thorough coverage\n",
    "  - If a search does not return useful results, try rephrasing the query\n",
    "  - Avoid using low-quality or unreliable sources (forums, opinion blogs without credentials)\n",
    "  - Collect at least 2-3 supporting pieces of information per key point\n",
    "  - Organize the collected information according to the outline structure\n",
    "\n",
    "  Essay Outline:\n",
    "  {outline}\n",
    "\n",
    "  Feedback:\n",
    "  {feedback}\n",
    "\n",
    "  Agent Output in JSON Format where \"\" represent the keys :\n",
    "  - \"research\", that containsFor each section in the outline, provide with this format\n",
    "    - Section title\n",
    "    - Key Point\n",
    "      - Supporting fact/quote/argument\n",
    "      - Source: [title] (URL)\n",
    "\"\"\"\n",
    "\n",
    "PROMPT_GENERATE = \"\"\"\n",
    "  You are an expert essay writer. Your job is to write a well-structured, coherent, and polished essay based on the provided outline and research materials.\n",
    "\n",
    "  Guidelines:\n",
    "  - Follow the outline structure closely\n",
    "  - Integrate the research findings naturally into the essay â€” do not simply list facts\n",
    "  - Write in a clear, engaging, and appropriate academic tone\n",
    "  - Each paragraph should have a clear topic sentence and flow logically\n",
    "  - Use transitions between sections to maintain coherence\n",
    "  - Support claims with evidence from the research materials\n",
    "  - Include proper in-text citations where relevant (e.g., \"According to [Source], ...\")\n",
    "  - Match the tone and complexity to the user's original requirements\n",
    "  - Do NOT make up facts or statistics that are not in the provided research\n",
    "\n",
    "  Essay Outline:\n",
    "  {outline}\n",
    "\n",
    "  Research Materials:\n",
    "  {research}\n",
    "\n",
    "  User Requirements:\n",
    "  {requirement}\n",
    "\n",
    "  **User Writing Preferences (from past sessions):**\n",
    "  The following are past feedback and preferences from this user. Use them to tailor\n",
    "  the essay's tone, depth, and style to what this user prefers.\n",
    "  If empty, use standard academic tone.\n",
    "\n",
    "  {user_preferences}\n",
    "\n",
    "  Agent Output in JSON Format where \"\" represent the keys :\n",
    "  - \"essay\", Write the full essay from introduction to conclusion.\n",
    "\"\"\"\n",
    "\n",
    "PROMPT_REFLECT = \"\"\"\n",
    "You are an expert essay editor and evaluator. Your job is to critically evaluate an essay and provide detailed, constructive feedback.\n",
    "\n",
    "Evaluate the essay based on the following criteria:\n",
    "1. Structure & Organization\n",
    "   - Does the essay follow a logical flow?\n",
    "   - Are transitions between sections smooth?\n",
    "   - Is the outline structure well executed?\n",
    "\n",
    "2. Thesis & Argumentation\n",
    "   - Is the thesis clear and strong?\n",
    "   - Does the essay consistently support the thesis?\n",
    "   - Are arguments well-developed and convincing?\n",
    "\n",
    "3. Evidence & Support\n",
    "   - Is the essay well-supported with evidence?\n",
    "   - Are sources credible and properly referenced?\n",
    "   - Are facts and statistics used effectively?\n",
    "\n",
    "4. Writing Quality\n",
    "   - Is the tone appropriate and consistent?\n",
    "   - Is the writing clear and concise?\n",
    "   - Are there any grammatical or spelling errors?\n",
    "\n",
    "5. Alignment with Requirements\n",
    "   - Does the essay meet all of the user's original requirements?\n",
    "   - Is the length and depth appropriate?\n",
    "   - Is the target audience addressed correctly?\n",
    "\n",
    "Essay to Evaluate:\n",
    "{essay}\n",
    "\n",
    "User's Original Requirements:\n",
    "{requirement}\n",
    "\n",
    "Agent Output in JSON Format where \"\" represent the keys :\n",
    "- \"score\", give the rating from the scale of 0-10, integer only\n",
    "- \"feedback\", the detailed evaluation along with the revision priorities\n",
    "- \"need_to_revised\", based on the assessment of the agent return only yes/no where yes mean the draft need to be revised, make sure that it's aligned with the 'score'\n",
    "\"\"\"\n",
    "\n",
    "# Agent state\n",
    "class AgentState(TypedDict):\n",
    "    task: str\n",
    "    user_id: str\n",
    "    requirement: str\n",
    "    outline: str\n",
    "    research: str\n",
    "    essay: str\n",
    "    feedback: str\n",
    "    score: int\n",
    "    need_to_revised: str\n",
    "    content: List[str]\n",
    "    revision_number: int\n",
    "\n",
    "    # user input\n",
    "    max_revisions: int\n",
    "    max_web_search: int\n",
    "\n",
    "# Build model with LangGraph\n",
    "class EssayWriterAgent:\n",
    "    def __init__(self, tools, middleware, max_revision:int = 3):\n",
    "        self.config = {'configurable': {'thread_id': 101}}\n",
    "        self.max_revision = max_revision\n",
    "        self.checkpointer = InMemorySaver()\n",
    "        self.research_memory = ResearchMemory()\n",
    "\n",
    "        # Store tools as dictionary\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "\n",
    "        # create LLM with tool binding\n",
    "        self.llm = init_chat_model(\n",
    "            model=\"claude-haiku-4-5-20251001\",\n",
    "            temperature=0.5,\n",
    "        )\n",
    "\n",
    "        # Bind tools to the model\n",
    "        self.llm_with_tools = self.llm.bind_tools(tools)\n",
    "\n",
    "        # to initiate the Graph\n",
    "        self.graph = StateGraph(AgentState)\n",
    "        self.graph.add_node('plan', self.call_agent_plan)\n",
    "        self.graph.add_node('research', self.call_agent_research)\n",
    "        self.graph.add_edge('plan', 'research')\n",
    "        self.graph.add_node('generate', self.call_agent_generate)\n",
    "        self.graph.add_edge('research', 'generate')\n",
    "        self.graph.add_conditional_edges(\n",
    "            'generate',\n",
    "            self.check_revision_iteration,\n",
    "            {True: 'reflect', False: END})\n",
    "        self.graph.add_node('reflect', self.call_agent_reflect)\n",
    "        self.graph.add_edge('reflect', 'research')\n",
    "        self.graph.set_entry_point('plan')\n",
    "\n",
    "        self.graph_np = self.graph.compile(\n",
    "            checkpointer=self.checkpointer,\n",
    "            )\n",
    "\n",
    "    def _update_state(self, new_dict:dict, state: AgentState):\n",
    "      \"\"\"Check whether the state will be updated based on the JSON output from the LLM response \"\"\"\n",
    "      for key, value in new_dict.items():\n",
    "        if key in state:\n",
    "          print(f\"  âœ… Updated '{key}'\")\n",
    "        else:\n",
    "          print(f\"  âš ï¸  Unknown key '{key}' - skipped\")\n",
    "\n",
    "    def _invoke_agent(self, human_message, answer_type:str = 'invoke'):\n",
    "      \"\"\"Get the LLM output and add to state\"\"\"\n",
    "      print(f\"  âœ… Added HumanMessage to state content\")\n",
    "\n",
    "      # If it's invoke\n",
    "      if answer_type == 'invoke':\n",
    "\n",
    "        result = self.llm.invoke([human_message])\n",
    "\n",
    "        print(f\"  âœ… Added Last AIMessage to state content\")\n",
    "\n",
    "        return result\n",
    "\n",
    "      # If it's stream\n",
    "      elif answer_type == 'stream':\n",
    "\n",
    "        messages = [human_message]\n",
    "\n",
    "        while True:\n",
    "          response = self.llm_with_tools.invoke(messages)\n",
    "          messages.append(response)\n",
    "\n",
    "          # If no tool calls, LLM is done\n",
    "          if not response.tool_calls:\n",
    "            pprint(messages[-1])\n",
    "            print(f\"  âœ… Added Last AIMessage to state content\")\n",
    "\n",
    "            return messages[-1]\n",
    "\n",
    "          # Execute tool calls\n",
    "          for tc in response.tool_calls:\n",
    "            print(f\"  ðŸ”§ Calling tool: {tc['name']}\")\n",
    "            print(f\"     Args: {tc['args']}\")\n",
    "\n",
    "            result = self.tools[tc['name']].invoke(tc['args'])\n",
    "\n",
    "            result_str = str(result)\n",
    "            print(f\"     Result: {result_str[:150]}{'...' if len(result_str) > 150 else ''}\\n\")\n",
    "\n",
    "            messages.append(ToolMessage(\n",
    "                tool_call_id=tc['id'],\n",
    "                name=tc['name'],\n",
    "                content=str(result)\n",
    "            ))\n",
    "\n",
    "    def call_agent_plan(self, state: AgentState):\n",
    "      \"\"\"Function to call agent with the promt to produce the outline of the essay\"\"\"\n",
    "      # Invoke LLM\n",
    "      message = HumanMessage(content = PROMPT_PLAN.format(\n",
    "          user_input=state['task']\n",
    "        )\n",
    "      )\n",
    "\n",
    "      print(f\"\\n{'='*60}\")\n",
    "      print(f\"GENERATING OUTLINE\")\n",
    "      print(f\"{'='*60}\")\n",
    "\n",
    "      result = self._invoke_agent(message)\n",
    "      json_result = extract_dict_from_string(result.content)\n",
    "      self._update_state(json_result, state)\n",
    "\n",
    "      print(f\"\\n=== âœ… Requirement ===\")\n",
    "      pprint(f\"{json_result.get('requirement', '')}\")\n",
    "      print(f\"\\n=== âœ… Outline ===\")\n",
    "      pprint(f\"{json_result.get('outline', '')}\")\n",
    "\n",
    "      return {\n",
    "        'outline': json_result.get('outline', ''),\n",
    "        'requirement': json_result.get('requirement', ''),\n",
    "        'max_revisions': state['max_revisions'] if json_result.get('max_revisions', 1) == 0 else json_result.get('max_revisions', 1),\n",
    "        'max_web_search': state['max_web_search'] if json_result.get('max_web_search', 3) == 0 else json_result.get('max_web_search', 3),\n",
    "        'content': state['content'] + [message, result]\n",
    "      }\n",
    "\n",
    "    def call_agent_research(self, state: AgentState):\n",
    "      \"\"\"Function to call agent with the prompt to produce the resource to make the essay\"\"\"\n",
    "\n",
    "      # Retrieve existing research from memory\n",
    "      query = f\"{state['outline'][:500]}\\n{state['feedback'][:500]}\"\n",
    "      existing_research = self.research_memory.retrieve_research(query)\n",
    "\n",
    "      # Invoke LLM\n",
    "      message = HumanMessage(content = PROMPT_RESEARCH.format(\n",
    "          outline=state['outline'],\n",
    "          feedback=state['feedback'],\n",
    "          max_web_search=state['max_web_search'],\n",
    "          existing_research=existing_research if existing_research else \"(none yet)\"\n",
    "        )\n",
    "      )\n",
    "\n",
    "      print(f\"\\n{'='*60}\")\n",
    "      print(f\"GENERATING RESEARCH\")\n",
    "      print(f\"{'='*60}\")\n",
    "\n",
    "      result = self._invoke_agent(message, 'stream')\n",
    "      json_result = extract_dict_from_string(result.content)\n",
    "      self._update_state(json_result, state)\n",
    "\n",
    "      print(f\"\\n=== âœ… Research ===\")\n",
    "      pprint(f\"{json_result.get('research', '')}\")\n",
    "\n",
    "      # Store new research to memory\n",
    "      new_research = json_result.get('research', '')\n",
    "      if new_research:\n",
    "          self.research_memory.store_research(\n",
    "              str(new_research), state['outline'],\n",
    "              state['revision_number']\n",
    "          )\n",
    "\n",
    "      return {\n",
    "        'research': json_result.get('research', ''),\n",
    "        'content': state['content'] + [message, result]\n",
    "      }\n",
    "\n",
    "    def call_agent_generate(self, state: AgentState):\n",
    "      \"\"\"Function to call agent with the prompt to produce the draft for the essay\"\"\"\n",
    "\n",
    "      # Retrieve user preferences from past feedback\n",
    "      user_preferences = self.research_memory.retrieve_preferences(\n",
    "          state['user_id'], state['task']\n",
    "      )\n",
    "\n",
    "      # Invoke LLM\n",
    "      message = HumanMessage(content = PROMPT_GENERATE.format(\n",
    "          outline=state['outline'],\n",
    "          research=state['research'],\n",
    "          requirement=state['requirement'],\n",
    "          user_preferences=user_preferences if user_preferences else \"(no past preferences)\"\n",
    "        )\n",
    "      )\n",
    "\n",
    "      print(f\"\\n{'='*60}\")\n",
    "      print(f\"GENERATING DRAFT - ITERATION {state['revision_number'] + 1}\")\n",
    "      print(f\"{'='*60}\")\n",
    "\n",
    "      result = self._invoke_agent(message)\n",
    "      json_result = extract_dict_from_string(result.content)\n",
    "      self._update_state(json_result, state)\n",
    "\n",
    "      print(f\"\\n=== âœ… Essay ===\")\n",
    "      pprint(f\"{json_result.get('essay', '')}\")\n",
    "\n",
    "      return {\n",
    "        'essay': json_result.get('essay', ''),\n",
    "        'content': state['content'] + [message, result]\n",
    "      }\n",
    "\n",
    "    def check_revision_iteration(self, state: AgentState):\n",
    "      \"\"\"Function to decide whether the draft need to be assess by Reflect agent\"\"\"\n",
    "\n",
    "      print(f\"\\n{'='*60}\")\n",
    "      print(f\"DETERMINE DRAFT NEED TO BE ASSESSED ?\")\n",
    "      print(f\"{'='*60}\")\n",
    "\n",
    "      # # Draft will always be assessed if it's in the 1st iteration\n",
    "      if state['revision_number'] < state['max_revisions']:\n",
    "        return True\n",
    "      else:\n",
    "        if state['need_to_revised'] == 'yes' :\n",
    "          revised_input = input(f\"\\nâ¸ï¸  Reflect agent say it's need to be revised (Score : {state['score']}), would you want to proceed with revision ? (yes/no)\").strip().lower()\n",
    "        elif state['need_to_revised'] != 'yes' :\n",
    "          revised_input = input(f\"\\nâ¸ï¸  Reflect agent say the draft is already good ðŸ‘ (Score : {state['score']}), would you want to proceed with revision ? (yes/no)\").strip().lower()\n",
    "\n",
    "        if revised_input == 'yes' :\n",
    "          return True\n",
    "        else :\n",
    "          return False\n",
    "\n",
    "    def call_agent_reflect(self, state: AgentState):\n",
    "      \"\"\"Function to call agent with the prompt to evaluate the essay draft\"\"\"\n",
    "\n",
    "      # Invoke LLM\n",
    "      message = HumanMessage(content = PROMPT_REFLECT.format(\n",
    "          essay=state['essay'],\n",
    "          requirement=state['requirement'],\n",
    "        )\n",
    "      )\n",
    "\n",
    "      print(f\"\\n{'='*60}\")\n",
    "      print(f\"ASSESSING DRAFT - ITERATION {state['revision_number'] + 1}\")\n",
    "      print(f\"{'='*60}\")\n",
    "\n",
    "      result = self._invoke_agent(message)\n",
    "      json_result = extract_dict_from_string(result.content)\n",
    "      self._update_state(json_result, state)\n",
    "\n",
    "      print(f\"\\n=== âœ… Feedback ===\")\n",
    "      pprint(f\"{json_result.get('feedback', '')}\")\n",
    "\n",
    "      print(f\"\\nDraft Score : {json_result.get('score', 0)}\")\n",
    "\n",
    "      # Store feedback as user preference (persists across sessions)\n",
    "      self.research_memory.store_feedback(\n",
    "          state['user_id'],\n",
    "          state['requirement'],\n",
    "          json_result.get('feedback', ''),\n",
    "          json_result.get('score', 0)\n",
    "      )\n",
    "\n",
    "      return {\n",
    "        'feedback': json_result.get('feedback', ''),\n",
    "        'score': json_result.get('score', 0),\n",
    "        'need_to_revised': json_result.get('need_to_revised', 'yes'),\n",
    "        'revision_number': state['revision_number'] + 1,\n",
    "      }\n",
    "\n",
    "    def execute(self, message, user_id: str = \"default\") :\n",
    "      \"\"\"Function to run the agent graph flow\"\"\"\n",
    "\n",
    "      self.input_message = message\n",
    "\n",
    "      # Clear research cache for new topic, but KEEP preferences (cross-session)\n",
    "      self.research_memory.clear_research()\n",
    "\n",
    "      print(f\"\\n{'='*60}\")\n",
    "      print(f\"TOPIC FROM THE USER\")\n",
    "      print(f\"{'='*60}\")\n",
    "      pprint(f\"{self.input_message}\")\n",
    "\n",
    "      # âœ… Initialize ALL required state fields\n",
    "      initial_state = {\n",
    "          'task': self.input_message,\n",
    "          'user_id': user_id,\n",
    "          'requirement': '',\n",
    "          'outline': '',\n",
    "          'research': '',\n",
    "          'essay': '',\n",
    "          'feedback': '',\n",
    "          'need_to_revised' : 'yes',\n",
    "          'score': 0,\n",
    "          'content': [],\n",
    "          'revision_number': 0,\n",
    "          'max_revisions': self.max_revision,\n",
    "          'max_web_search': 3,\n",
    "      }\n",
    "\n",
    "      # Run the graph\n",
    "      result = self.graph_np.invoke(\n",
    "          initial_state,\n",
    "          config=self.config\n",
    "      )\n",
    "\n",
    "      # Get final answer\n",
    "      final_answer = result['essay']\n",
    "\n",
    "      # Change it to HTML mode\n",
    "      print(f\"\\n{'='*60}\")\n",
    "      print(f\"CHANGE THE ESSAY TO HTML MODE\")\n",
    "      print(f\"{'='*60}\")\n",
    "\n",
    "      PROMPT_HTML = \"\"\"\n",
    "        Please help change this text to HTML mode, highlight the key point from the essay with bold and red pastel color\n",
    "\n",
    "        Text : {final_answer}\n",
    "      \"\"\"\n",
    "\n",
    "      message_html = HumanMessage(content = PROMPT_HTML.format(\n",
    "          final_answer=final_answer,\n",
    "        )\n",
    "      )\n",
    "      final_answer_html = self._invoke_agent(message_html)\n",
    "\n",
    "      print(f\"\\n âœ… HTML Generated\")\n",
    "\n",
    "      return final_answer_html\n",
    "\n",
    "\n",
    "# Define system prompt\n",
    "bot = EssayWriterAgent([search_tool], [], 3)\n",
    "\n",
    "# Display LangGraph structure\n",
    "try:\n",
    "    # Try to visualize the graph\n",
    "    display(Image(bot.graph_np.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Visualization error: {e}\")\n",
    "    print(\"\\nGraph structure (ASCII):\")\n",
    "    print(bot.graph_np.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eXDPzoKBJvv8",
    "outputId": "7206cf0f-262d-4836-dad9-c8865549499d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ… Research memory cleared\n",
      "\n",
      "============================================================\n",
      "TOPIC FROM THE USER\n",
      "============================================================\n",
      "('\\n'\n",
      " \"    Make me an essay about the thing's discussed in thins linkedin post \"\n",
      " 'https://www.linkedin.com/posts/activity-7430165848746614784-qrSO?utm_source=share&utm_medium=member_desktop&rcm=ACoAACMcvqkBIzfqjaPJhbXtUzkIg2WDtIH4i0Q\\n'\n",
      " '    Search for other relevant source, I want to know the latest research on '\n",
      " 'this part \"in favor of duration-indexed causal effects, quantile treatment '\n",
      " 'effects, and distributional methods built for heavy-tailed setting\"\\n'\n",
      " '    you can do 5 web search and 1 revision\\n'\n",
      " '    ')\n",
      "\n",
      "============================================================\n",
      "GENERATING OUTLINE\n",
      "============================================================\n",
      "  âœ… Added HumanMessage to state content\n",
      "  âœ… Added Last AIMessage to state content\n",
      "  âœ… Updated 'requirement'\n",
      "  âœ… Updated 'outline'\n",
      "  âœ… Updated 'max_web_search'\n",
      "  âœ… Updated 'max_revisions'\n",
      "\n",
      "=== âœ… Requirement ===\n",
      "('Create a 5-paragraph essay about advanced causal inference methods, '\n",
      " 'specifically focusing on: (1) duration-indexed causal effects, (2) quantile '\n",
      " 'treatment effects, and (3) distributional methods for heavy-tailed settings. '\n",
      " 'The essay should incorporate the latest research findings on these '\n",
      " 'econometric and statistical topics from the LinkedIn post and supplementary '\n",
      " 'academic sources.')\n",
      "\n",
      "=== âœ… Outline ===\n",
      "(\"{'thesis_statement': 'Modern causal inference has evolved beyond traditional \"\n",
      " 'average treatment effects to encompass duration-indexed causal effects, '\n",
      " 'quantile treatment effects, and distributional methods designed for '\n",
      " 'heavy-tailed data, representing a paradigm shift in how researchers '\n",
      " 'understand and measure treatment heterogeneity across populations and time '\n",
      " \"horizons.', 'introduction': {'hook': 'Traditional econometric methods have \"\n",
      " 'long relied on estimating average treatment effects, yet this approach masks '\n",
      " 'critical heterogeneity in how different individuals and groups respond to '\n",
      " \"interventions.', 'context': 'Recent advances in causal inference methodology \"\n",
      " 'have introduced more sophisticated approaches that capture treatment effects '\n",
      " 'across different quantiles, time horizons, and distributional '\n",
      " 'characteristics, particularly in settings with extreme values and non-normal '\n",
      " \"data.', 'transition': 'Understanding these three interconnected \"\n",
      " 'methodological advancesâ€”duration-indexed effects, quantile approaches, and '\n",
      " 'heavy-tailed distributional methodsâ€”is essential for modern empirical '\n",
      " \"research.'}, 'body_section_1': {'title': 'Duration-Indexed Causal Effects: \"\n",
      " \"Moving Beyond Static Treatment Analysis', 'key_points': [{'point': \"\n",
      " \"'Definition and motivation', 'description': 'Explain how duration-indexed \"\n",
      " 'causal effects extend beyond single-point-in-time treatment measurements to '\n",
      " 'capture how treatment effects evolve and persist over different time '\n",
      " \"horizons'}, {'point': 'Applications and advantages', 'description': 'Discuss \"\n",
      " 'practical applications in policy evaluation, labor economics, and medical '\n",
      " \"research where understanding temporal dynamics of treatment is crucial'}, \"\n",
      " \"{'point': 'Recent research developments', 'description': 'Cover latest \"\n",
      " 'methodological innovations in estimating time-varying treatment effects and '\n",
      " \"their implementation in empirical studies'}]}, 'body_section_2': {'title': \"\n",
      " \"'Quantile Treatment Effects: Capturing Heterogeneous Responses Across the \"\n",
      " \"Distribution', 'key_points': [{'point': 'Limitations of mean-based \"\n",
      " \"analysis', 'description': 'Explain why average treatment effects can be \"\n",
      " 'misleading and how quantile treatment effects reveal differential impacts '\n",
      " \"across the outcome distribution'}, {'point': 'Methodological framework', \"\n",
      " \"'description': 'Describe quantile regression approaches and recent advances \"\n",
      " 'in identifying causal quantile effects under various identification '\n",
      " \"assumptions'}, {'point': 'Empirical implications', 'description': \"\n",
      " \"'Illustrate how quantile effects inform policy design by showing which \"\n",
      " \"population segments benefit most or least from interventions'}]}, \"\n",
      " \"'body_section_3': {'title': 'Distributional Methods for Heavy-Tailed \"\n",
      " \"Settings: Addressing Extreme Values and Non-Normal Data', 'key_points': \"\n",
      " \"[{'point': 'Challenges of heavy-tailed distributions', 'description': \"\n",
      " \"'Explain the statistical and inferential challenges posed by heavy-tailed \"\n",
      " \"data (e.g., income, financial returns) and why traditional methods fail'}, \"\n",
      " \"{'point': 'Methodological innovations', 'description': 'Review recent \"\n",
      " 'developments in robust causal inference methods specifically designed for '\n",
      " 'heavy-tailed settings, including tail-robust estimators and distributional '\n",
      " \"approaches'}, {'point': 'Practical applications', 'description': 'Discuss \"\n",
      " 'applications in economics, finance, and epidemiology where extreme values '\n",
      " \"significantly impact causal conclusions'}]}, 'body_section_4': {'title': \"\n",
      " \"'Integration and Future Directions: Synthesizing Advanced Causal Methods', \"\n",
      " \"'key_points': [{'point': 'Complementary nature of approaches', \"\n",
      " \"'description': 'Explain how duration-indexed, quantile, and distributional \"\n",
      " \"methods can be combined for comprehensive causal analysis'}, {'point': \"\n",
      " \"'Computational and practical considerations', 'description': 'Address \"\n",
      " 'implementation challenges and software availability for practitioners '\n",
      " \"adopting these advanced methods'}, {'point': 'Emerging research frontiers', \"\n",
      " \"'description': 'Identify cutting-edge developments and open questions in \"\n",
      " \"causal inference methodology'}]}, 'conclusion': {'summary': 'The three \"\n",
      " 'methodological advancesâ€”duration-indexed causal effects, quantile treatment '\n",
      " 'effects, and distributional methods for heavy-tailed settingsâ€”collectively '\n",
      " 'represent a maturation of causal inference that moves beyond oversimplified '\n",
      " \"average effects.', 'significance': 'These methods enable researchers to \"\n",
      " 'provide more nuanced, heterogeneous, and robust estimates of causal effects '\n",
      " \"that better reflect real-world complexity.', 'closing_statement': 'As \"\n",
      " 'empirical research becomes increasingly sophisticated, adoption of these '\n",
      " 'advanced causal inference techniques will be essential for generating '\n",
      " \"credible and actionable evidence for policy and practice.'}}\")\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "slice(None, 500, None)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m html = \u001b[43mbot\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\"\"\u001b[39;49m\n\u001b[32m      2\u001b[39m \u001b[33;43m    Make me an essay about the thing\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43ms discussed in thins linkedin post https://www.linkedin.com/posts/activity-7430165848746614784-qrSO?utm_source=share&utm_medium=member_desktop&rcm=ACoAACMcvqkBIzfqjaPJhbXtUzkIg2WDtIH4i0Q\u001b[39;49m\n\u001b[32m      3\u001b[39m \u001b[33;43m    Search for other relevant source, I want to know the latest research on this part \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43min favor of duration-indexed causal effects, quantile treatment effects, and distributional methods built for heavy-tailed setting\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      4\u001b[39m \u001b[33;43m    you can do 5 web search and 1 revision\u001b[39;49m\n\u001b[32m      5\u001b[39m \u001b[33;43m    \u001b[39;49m\u001b[33;43m\"\"\"\u001b[39;49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcello\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 581\u001b[39m, in \u001b[36mEssayWriterAgent.execute\u001b[39m\u001b[34m(self, message, user_id)\u001b[39m\n\u001b[32m    564\u001b[39m initial_state = {\n\u001b[32m    565\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtask\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mself\u001b[39m.input_message,\n\u001b[32m    566\u001b[39m     \u001b[33m'\u001b[39m\u001b[33muser_id\u001b[39m\u001b[33m'\u001b[39m: user_id,\n\u001b[32m   (...)\u001b[39m\u001b[32m    577\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmax_web_search\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m3\u001b[39m,\n\u001b[32m    578\u001b[39m }\n\u001b[32m    580\u001b[39m \u001b[38;5;66;03m# Run the graph\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgraph_np\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    582\u001b[39m \u001b[43m    \u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    583\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\n\u001b[32m    584\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    586\u001b[39m \u001b[38;5;66;03m# Get final answer\u001b[39;00m\n\u001b[32m    587\u001b[39m final_answer = result[\u001b[33m'\u001b[39m\u001b[33messay\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project/agentic_ai_learning/.venv/lib/python3.12/site-packages/langgraph/pregel/main.py:3071\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3068\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3069\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3071\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3072\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3073\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3074\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3076\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3077\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3078\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3079\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3082\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3084\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3085\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3086\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project/agentic_ai_learning/.venv/lib/python3.12/site-packages/langgraph/pregel/main.py:2646\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2644\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2645\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2646\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2647\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2653\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2655\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2656\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project/agentic_ai_learning/.venv/lib/python3.12/site-packages/langgraph/pregel/_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project/agentic_ai_learning/.venv/lib/python3.12/site-packages/langgraph/pregel/_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project/agentic_ai_learning/.venv/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Project/agentic_ai_learning/.venv/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 422\u001b[39m, in \u001b[36mEssayWriterAgent.call_agent_research\u001b[39m\u001b[34m(self, state)\u001b[39m\n\u001b[32m    419\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Function to call agent with the prompt to produce the resource to make the essay\"\"\"\u001b[39;00m\n\u001b[32m    421\u001b[39m \u001b[38;5;66;03m# Retrieve existing research from memory\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m422\u001b[39m query = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43moutline\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mstate[\u001b[33m'\u001b[39m\u001b[33mfeedback\u001b[39m\u001b[33m'\u001b[39m][:\u001b[32m500\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    423\u001b[39m existing_research = \u001b[38;5;28mself\u001b[39m.research_memory.retrieve_research(query)\n\u001b[32m    425\u001b[39m \u001b[38;5;66;03m# Invoke LLM\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: slice(None, 500, None)",
      "During task with name 'research' and id 'abc2e347-7cec-3744-9208-085957c2eb86'"
     ]
    }
   ],
   "source": [
    "html = bot.execute(\"\"\"\n",
    "    Make me an essay about the thing's discussed in thins linkedin post https://www.linkedin.com/posts/activity-7430165848746614784-qrSO?utm_source=share&utm_medium=member_desktop&rcm=ACoAACMcvqkBIzfqjaPJhbXtUzkIg2WDtIH4i0Q\n",
    "    Search for other relevant source, I want to know the latest research on this part \"in favor of duration-indexed causal effects, quantile treatment effects, and distributional methods built for heavy-tailed setting\"\n",
    "    you can do 5 web search and 1 revision\n",
    "    \"\"\"\n",
    "    , user_id=\"cello\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<iframe srcdoc=\"```html\n",
       "&lt;!DOCTYPE html&gt;\n",
       "&lt;html lang=&quot;en&quot;&gt;\n",
       "&lt;head&gt;\n",
       "    &lt;meta charset=&quot;UTF-8&quot;&gt;\n",
       "    &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;\n",
       "    &lt;title&gt;Bung Hatta and Democratic Indonesia&lt;/title&gt;\n",
       "    &lt;style&gt;\n",
       "        body {\n",
       "            font-family: Arial, sans-serif;\n",
       "            line-height: 1.6;\n",
       "            max-width: 900px;\n",
       "            margin: 0 auto;\n",
       "            padding: 20px;\n",
       "            background-color: #f5f5f5;\n",
       "        }\n",
       "        h1 {\n",
       "            color: #333;\n",
       "            text-align: center;\n",
       "        }\n",
       "        p {\n",
       "            text-align: justify;\n",
       "            color: #444;\n",
       "            margin-bottom: 15px;\n",
       "        }\n",
       "        .highlight {\n",
       "            background-color: #FFB3BA;\n",
       "            font-weight: bold;\n",
       "            color: #C41E3A;\n",
       "            padding: 2px 4px;\n",
       "        }\n",
       "    &lt;/style&gt;\n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "\n",
       "&lt;h1&gt;Bung Hatta and the Struggle for Democratic Indonesia: A Vice President&#x27;s Principled Stand Against Authoritarianism&lt;/h1&gt;\n",
       "\n",
       "&lt;p&gt;In the formative years of the Indonesian Republic, two towering figuresâ€”Soekarno and Bung Hattaâ€”stood at the helm of a newly independent nation, yet their visions for the country&#x27;s future could not have been more divergent. On August 17, 1945, Sukarno and Hatta formally declared Indonesia&#x27;s independence at Sukarno&#x27;s residence in Jakarta, raising the red and white national flag and singing the national anthem Indonesia Raya. The following day, a new constitution was promulgated, and Hatta was selected as Indonesia&#x27;s first vice president by the PPKI to accompany Sukarno, who had been elected as the nation&#x27;s first president. During the National Revolution (1945-1949), these two leaders worked together to secure Indonesia&#x27;s independence from the Dutch, driven by pressure from radical youth groups and the urgent necessity of establishing a sovereign state. However, beneath this initial partnership lay &lt;span class=&quot;highlight&quot;&gt;fundamentally incompatible political philosophies that would eventually tear apart their collaborative leadership&lt;/span&gt;. Bung Hatta&#x27;s tenure as Indonesia&#x27;s first Vice President was marked by ideological differences and growing political friction with Soekarno, ultimately leading to his resignation and highlighting the fundamental tensions between democratic and authoritarian governance in early Indonesia.&lt;/p&gt;\n",
       "\n",
       "&lt;p&gt;From the outset of his vice presidency, &lt;span class=&quot;highlight&quot;&gt;Bung Hatta demonstrated an unwavering commitment to parliamentary democracy and constitutional governance&lt;/span&gt;. Indonesia soon adopted a constitution which advocated parliamentary democracy and reduced the president to the role of a ceremonial head of stateâ€”a framework that reflected Hatta&#x27;s democratic vision. Hatta signed the Declaration No. X, Declaration of November 1, and Declaration of November 3, 1945, which fundamentally changed the system of Indonesian government and transformed the presidential cabinet into a parliamentary cabinet as a way towards democratic government. Moreover, Hatta played a crucial role in drafting constitutional frameworks and advocating for checks and balances on executive power. On October 16, 1945, an edict issued by Hatta gave the Central National Committee of Indonesia (KNIP) legislative powers in addition to its advisory role to the president, thereby distributing power across multiple institutions. In October 1945, Hatta authorized the formation of political parties in Indonesia, recognizing that a healthy democracy required political pluralism. Most significantly, in November 1945, Hatta made the decision which took away the president&#x27;s role as Head of Government and transferred it to a prime ministerâ€”a move that Hatta was able to make because Sukarno was unable to attend the meetings in question, leaving Hatta in charge. These early actions revealed Hatta&#x27;s deep commitment to limiting executive power and establishing institutional safeguards against authoritarianism, principles that would define his entire political career.&lt;/p&gt;\n",
       "\n",
       "&lt;p&gt;As the years progressed, however, a profound ideological divergence emerged between the two leaders regarding the proper structure of Indonesian governance and economic policy. Soekarno increasingly preferred centralized power and rejected Western-style democracy as unsuitable for Indonesia&#x27;s unique character. On February 21, 1957, Sukarno detailed his plan for what would become known as &quot;Guided Democracy&quot; (Demokrasi Terpimpin), arguing that Western-style democracy was not suited to Indonesia&#x27;s nature. Sukarno envisioned himself as president playing the role of village elders at the national level, arguing that a national consensus could express itself under presidential guidance. This vision was further reinforced when President Sukarno made an official visit to the People&#x27;s Republic of China in October 1956 and was impressed with Mao Zedong&#x27;s centralization of power, concluding that this model was due to strong leadership. In stark contrast, &lt;span class=&quot;highlight&quot;&gt;Hatta remained a moderate, administratively oriented leader who believed that dealing with Indonesia&#x27;s grave economic crises was of primary importance and feared that Sukarno&#x27;s policies would bankrupt the country&lt;/span&gt;. As a man who believed in democracy, Hatta was beginning to feel disillusioned with Sukarno&#x27;s increasing autocracy and authoritarianism. Hatta had continued to advise Sukarno against taking the authoritarian road, but he was consistently ignored. The two leaders also fundamentally disagreed on how to handle the Communist Party (PKI). Hatta said he and Sukarno had fundamental disagreement on this issue: Sukarno believed that Communist gains were made entirely on the basis of promises which they were not required to fulfill, and therefore thought Communists should be brought into government and forced to accept responsibility for their promises. Hatta entirely disagreed with Sukarno&#x27;s view and repeatedly pointed out to him that the PKI was not a conventional political party and would use any position in government to burrow into the army and bureaucracy. Hatta lashed out against the &quot;irreligious ideologies&quot; of communism and its &quot;international conspiratorial character.&quot; These irreconcilable differences over democracy, centralized power, and communist influence would drive an ever-widening wedge between the two leaders.&lt;/p&gt;\n",
       "\n",
       "&lt;p&gt;Throughout the period from 1950 to 1956, Hatta&#x27;s influence steadily declined as Soekarno consolidated power through military alliances and increasingly marginalized democratic institutions. Because the presidency was a ceremonial role under the parliamentary system, this made the office of vice president increasingly pointless, particularly as Sukarno maneuvered to reclaim executive authority. Hatta&#x27;s term as prime minister was not renewed, leaving him with little to do as vice president and further diminishing his ability to influence national policy. Hatta remained aloof from the regime after his visit to the People&#x27;s Republic of China in October 1957, declining to assume the Vice-presidential office once again. Recognizing that his democratic vision was being systematically dismantled and that his counsel was no longer heeded, Hatta made the fateful decision to withdraw from active politics. &lt;span class=&quot;highlight&quot;&gt;On December 1, 1956, Hatta officially resigned from the vice presidency&lt;/span&gt;. While on the surface it seemed as if Hatta was retiring for practical reasonsâ€”the presidency was a ceremonial role, making the office of vice president pointless, and Hatta thought that the country was wasting money paying his wagesâ€”the deeper truth was far more significant. &lt;span class=&quot;highlight&quot;&gt;Hatta&#x27;s attitude to resign on December 1, 1956 was more due to his opposition to Sukarno&#x27;s authoritarian attitude in implementing political policies&lt;/span&gt;. Different political views with Soekarno could not be harmonized any more, and the chaotic political situation left Hatta feeling that he did not have the power to resolve the issues confronting the nation. His resignation has become an ironic phenomenon in the leadership history of Indonesia, representing the end of the &quot;Dwi Tunggal&quot; (dual leadership) which became a &quot;Dwi-Tanggal&quot; (dual separation), causing many people&#x27;s disappointment. In this symbolic gesture, Hatta rejected Soekarno&#x27;s authoritarian direction and refused to lend legitimacy to a system he believed was fundamentally incompatible with democratic governance.&lt;/p&gt;\n",
       "\n",
       "&lt;p&gt;The conflict between Hatta and Sukarno fundamentally shaped Indonesia&#x27;s political trajectory and revealed the profound tensions inherent in the struggle between democratic and authoritarian governance. The period from 1950-1959 was characterized as &quot;Liberal democracy&quot; in Indonesia, which was then replaced by &quot;Guided Democracy&quot; (1959-1966) following Sukarno&#x27;s consolidation of power. Hatta&#x27;s resignation marked the symbolic end of the democratic vision for early Indonesia and the beginning of authoritarian centralization under Sukarno. Yet &lt;span class=&quot;highlight&quot;&gt;Hatta&#x27;s principled stance, though unsuccessful in changing Soekarno&#x27;s course, represented an important alternative vision for Indonesia&#x27;s future based on parliamentary democracy, cooperative economics, and constitutional governance&lt;/span&gt;. Hatta&#x27;s contributions to the Indonesian people were extraordinary, demonstrated through his work in politics, economy, education, and people&#x27;s welfare. Indeed, after Sukarno&#x27;s downfall, Hatta came out of retirement to serve as special adviser to President Suharto on the problem of government corruption, demonstrating that his commitment to good governance and democratic principles remained unshaken throughout his life. &lt;span class=&quot;highlight&quot;&gt;Bung Hatta&#x27;s legacy reminds us that principled opposition to authoritarianism, even when politically unsuccessful, preserves an essential vision of what a nation might becomeâ€”a vision that can inspire future generations to reclaim democratic values and constitutional governance&lt;/span&gt;.&lt;/p&gt;\n",
       "\n",
       "&lt;/body&gt;\n",
       "&lt;/html&gt;\n",
       "```\n",
       "\n",
       "I&#x27;ve converted the text to HTML format with the following features:\n",
       "\n",
       "âœ… **Key highlights in bold with red pastel background:**\n",
       "- Incompatible political philosophies\n",
       "- Unwavering commitment to parliamentary democracy\n",
       "- Hatta&#x27;s moderate and economically-focused leadership\n",
       "- His resignation on December 1, 1956\n",
       "- His opposition to Sukarno&#x27;s authoritarianism\n",
       "- His principled stance and legacy\n",
       "\n",
       "The red pastel color (#FFB3BA) combined with bold red text (#C41E3A) makes the key points stand out clearly while maintaining readability.\" style=\"width:100%; height:600px; border:none; border-radius:8px;\" sandbox=\"allow-same-origin\"></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "import html as html_lib\n",
    "\n",
    "escaped = html_lib.escape(html.content)\n",
    "\n",
    "display(HTML(f\"\"\"\n",
    "<iframe srcdoc=\"{escaped}\" style=\"width:100%; height:600px; border:none; border-radius:8px;\" sandbox=\"allow-same-origin\"></iframe>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wG_Iyr6-sIc2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Agentic AI Learning",
   "language": "python",
   "name": "agentic_ai_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
