{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "q52_-d_bHTe6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup Keys\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.27\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fn8IlbCrJg6s"
   },
   "source": [
    "# EssayMaker with Agent Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "0TQrL_OQHU_X",
    "outputId": "f1aaa172-26b3-4380-bd1a-6ee86d093679"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcellosusanto/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'create_agent' from 'langchain.agents' (/Users/marcellosusanto/Library/Python/3.9/lib/python/site-packages/langchain/agents/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image, display\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_agent\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m init_chat_model\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpoint\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmemory\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InMemorySaver\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'create_agent' from 'langchain.agents' (/Users/marcellosusanto/Library/Python/3.9/lib/python/site-packages/langchain/agents/__init__.py)"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain.agents import create_agent\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.messages import AnyMessage, HumanMessage, AIMessage, SystemMessage, ToolMessage\n",
    "from langchain.tools import tool\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.types import interrupt, Command\n",
    "from typing import TypedDict, Annotated, List\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "import re\n",
    "import ast\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "# Utility function\n",
    "def extract_dict_from_string(text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extract and convert a dictionary from a string that may contain extra text.\n",
    "    Tries JSON first, then falls back to ast.literal_eval.\n",
    "    \"\"\"\n",
    "    # Strip markdown code fences if present\n",
    "    cleaned = text.strip()\n",
    "\n",
    "    if re.search(r'```json', cleaned):\n",
    "      list_substr = cleaned.split(\"```json\")\n",
    "      cleaned = list_substr[1]\n",
    "    if re.search(r'```', cleaned):\n",
    "      list_substr = cleaned.split(\"```\")\n",
    "      cleaned = list_substr[0]\n",
    "\n",
    "    cleaned = cleaned.strip()\n",
    "\n",
    "    try:\n",
    "        result = json.loads(cleaned)\n",
    "        if isinstance(result, dict):\n",
    "            return result\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "\n",
    "    print(f\"âŒ Failed to extract dict from response:\\n{text[:200]}\")\n",
    "    return {}\n",
    "\n",
    "# Build tool\n",
    "search_tool = TavilySearchResults(max_results=2)\n",
    "\n",
    "# Setup prompt for each task\n",
    "PROMPT_PLAN = \"\"\"\n",
    "  You are an expert essay planner. Your job is to create a detailed and well-structured outline for an essay that will be no longer than 5 paragraphs\n",
    "\n",
    "  Given the topic and requirements from the user, you must produce an outline that includes:\n",
    "  1. A strong thesis statement\n",
    "  2. An introduction section with a hook and context\n",
    "  3. 3-5 main body sections, each with:\n",
    "    - A clear section title\n",
    "    - 2-3 key points to cover\n",
    "    - A brief description of what each point should address\n",
    "  4. A conclusion section that ties everything together\n",
    "\n",
    "  Guidelines:\n",
    "  - The outline should be logical and flow naturally from one section to the next\n",
    "  - Each section should build upon the previous one\n",
    "  - Make sure the outline directly addresses the user's requirements\n",
    "  - Tailor the depth and complexity to match the required essay length and academic level\n",
    "\n",
    "  User Input:\n",
    "  {user_input}\n",
    "\n",
    "  Agent Output in JSON Format where \"\" represent the keys :\n",
    "  - \"requirement\", derrived from user input\n",
    "  - \"outline\", the outline produced by the agent based on the prompt\n",
    "  - \"max_revisions\", the maximum revision of the draft essay based on the user input, if it's not specified by the user return 0\n",
    "  - \"max_web_search\", the maximum web search that can be done by the agent based on the user input, if it's not specified by the user return 0\n",
    "\"\"\"\n",
    "\n",
    "PROMPT_RESEARCH = \"\"\"\n",
    "  You are an expert research assistant. Your job is to gather relevant information and sources to support an essay based on a given outline.\n",
    "  If the feedback is not empty, focus on doing search to help gain information to assess the feedback\n",
    "  Do no more than {max_web_search} search.\n",
    "\n",
    "  For each section and key point in the outline, you must:\n",
    "  1. Search the web for relevant, credible sources using tavily_seach tool\n",
    "  2. Extract key facts, statistics, quotes, or arguments that support the point\n",
    "  3. Note the source URL and title for citation purposes\n",
    "  4. Prioritize recent and authoritative sources (academic journals, reputable news, official reports)\n",
    "\n",
    "  Guidelines:\n",
    "  - Search for each main section and key point separately to ensure thorough coverage\n",
    "  - If a search does not return useful results, try rephrasing the query\n",
    "  - Avoid using low-quality or unreliable sources (forums, opinion blogs without credentials)\n",
    "  - Collect at least 2-3 supporting pieces of information per key point\n",
    "  - Organize the collected information according to the outline structure\n",
    "\n",
    "  Essay Outline:\n",
    "  {outline}\n",
    "\n",
    "  Feedback:\n",
    "  {feedback}\n",
    "\n",
    "  Agent Output in JSON Format where \"\" represent the keys :\n",
    "  - \"research\", that containsFor each section in the outline, provide with this format\n",
    "    - Section title\n",
    "    - Key Point\n",
    "      - Supporting fact/quote/argument\n",
    "      - Source: [title] (URL)\n",
    "\"\"\"\n",
    "\n",
    "PROMPT_GENERATE = \"\"\"\n",
    "  You are an expert essay writer. Your job is to write a well-structured, coherent, and polished essay based on the provided outline and research materials.\n",
    "\n",
    "  Guidelines:\n",
    "  - Follow the outline structure closely\n",
    "  - Integrate the research findings naturally into the essay â€” do not simply list facts\n",
    "  - Write in a clear, engaging, and appropriate academic tone\n",
    "  - Each paragraph should have a clear topic sentence and flow logically\n",
    "  - Use transitions between sections to maintain coherence\n",
    "  - Support claims with evidence from the research materials\n",
    "  - Include proper in-text citations where relevant (e.g., \"According to [Source], ...\")\n",
    "  - Match the tone and complexity to the user's original requirements\n",
    "  - Do NOT make up facts or statistics that are not in the provided research\n",
    "\n",
    "  Essay Outline:\n",
    "  {outline}\n",
    "\n",
    "  Research Materials:\n",
    "  {research}\n",
    "\n",
    "  User Requirements:\n",
    "  {requirement}\n",
    "\n",
    "  Agent Output in JSON Format where \"\" represent the keys :\n",
    "  - \"essay\", Write the full essay from introduction to conclusion.\n",
    "\"\"\"\n",
    "\n",
    "PROMPT_REFLECT = \"\"\"\n",
    "You are an expert essay editor and evaluator. Your job is to critically evaluate an essay and provide detailed, constructive feedback.\n",
    "\n",
    "Evaluate the essay based on the following criteria:\n",
    "1. Structure & Organization\n",
    "   - Does the essay follow a logical flow?\n",
    "   - Are transitions between sections smooth?\n",
    "   - Is the outline structure well executed?\n",
    "\n",
    "2. Thesis & Argumentation\n",
    "   - Is the thesis clear and strong?\n",
    "   - Does the essay consistently support the thesis?\n",
    "   - Are arguments well-developed and convincing?\n",
    "\n",
    "3. Evidence & Support\n",
    "   - Is the essay well-supported with evidence?\n",
    "   - Are sources credible and properly referenced?\n",
    "   - Are facts and statistics used effectively?\n",
    "\n",
    "4. Writing Quality\n",
    "   - Is the tone appropriate and consistent?\n",
    "   - Is the writing clear and concise?\n",
    "   - Are there any grammatical or spelling errors?\n",
    "\n",
    "5. Alignment with Requirements\n",
    "   - Does the essay meet all of the user's original requirements?\n",
    "   - Is the length and depth appropriate?\n",
    "   - Is the target audience addressed correctly?\n",
    "\n",
    "Essay to Evaluate:\n",
    "{essay}\n",
    "\n",
    "User's Original Requirements:\n",
    "{requirement}\n",
    "\n",
    "Agent Output in JSON Format where \"\" represent the keys :\n",
    "- \"score\", give the rating from the scale of 0-10, integer only\n",
    "- \"feedback\", the detailed evaluation along with the revision priorities\n",
    "- \"need_to_revised\", based on the assessment of the agent return only yes/no where yes mean the draft need to be revised, make sure that it's aligned with the 'score'\n",
    "\"\"\"\n",
    "\n",
    "# Agent state\n",
    "class AgentState(TypedDict):\n",
    "    task: str\n",
    "    requirement: str\n",
    "    outline: str\n",
    "    research: str\n",
    "    essay: str\n",
    "    feedback: str\n",
    "    score: int\n",
    "    need_to_revised: str\n",
    "    content: List[str]\n",
    "    revision_number: int\n",
    "\n",
    "    # user input\n",
    "    max_revisions: int\n",
    "    max_web_search: int\n",
    "\n",
    "# Build model with LangGraph\n",
    "class EssayWriterAgent:\n",
    "    def __init__(self, tools, middleware, max_revision:int = 3):\n",
    "        self.config = {'configurable': {'thread_id': 101}}\n",
    "        self.max_revision = max_revision\n",
    "        self.checkpointer = InMemorySaver()\n",
    "\n",
    "        # Store tools as dictionary\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "\n",
    "        # create LLM with tool binding\n",
    "        self.llm = init_chat_model(\n",
    "            model=\"claude-haiku-4-5-20251001\",\n",
    "            temperature=0.5,\n",
    "        )\n",
    "\n",
    "        # Bind tools to the model\n",
    "        self.llm_with_tools = self.llm.bind_tools(tools)\n",
    "\n",
    "        # to initiate the Graph\n",
    "        self.graph = StateGraph(AgentState)\n",
    "        self.graph.add_node('plan', self.call_agent_plan)\n",
    "        self.graph.add_node('research', self.call_agent_research)\n",
    "        self.graph.add_edge('plan', 'research')\n",
    "        self.graph.add_node('generate', self.call_agent_generate)\n",
    "        self.graph.add_edge('research', 'generate')\n",
    "        self.graph.add_conditional_edges(\n",
    "            'generate',\n",
    "            self.check_revision_iteration,\n",
    "            {True: 'reflect', False: END})\n",
    "        self.graph.add_node('reflect', self.call_agent_reflect)\n",
    "        self.graph.add_edge('reflect', 'research')\n",
    "        self.graph.set_entry_point('plan')\n",
    "\n",
    "        self.graph_np = self.graph.compile(\n",
    "            checkpointer=self.checkpointer,\n",
    "            )\n",
    "\n",
    "    def _update_state(self, new_dict:dict, state: AgentState):\n",
    "      \"\"\"Check whether the state will be updated based on the JSON output from the LLM response \"\"\"\n",
    "      for key, value in new_dict.items():\n",
    "        if key in state:\n",
    "          print(f\"  âœ… Updated '{key}'\")\n",
    "        else:\n",
    "          print(f\"  âš ï¸  Unknown key '{key}' - skipped\")\n",
    "\n",
    "    def _invoke_agent(self, human_message, answer_type:str = 'invoke'):\n",
    "      \"\"\"Get the LLM output and add to state\"\"\"\n",
    "      print(f\"  âœ… Added HumanMessage to state content\")\n",
    "\n",
    "      # If it's invoke\n",
    "      if answer_type == 'invoke':\n",
    "\n",
    "        result = self.llm.invoke([human_message])\n",
    "\n",
    "        print(f\"  âœ… Added Last AIMessage to state content\")\n",
    "\n",
    "        return result\n",
    "\n",
    "      # If it's stream\n",
    "      elif answer_type == 'stream':\n",
    "\n",
    "        messages = [human_message]\n",
    "\n",
    "        while True:\n",
    "          response = self.llm_with_tools.invoke(messages)\n",
    "          messages.append(response)\n",
    "\n",
    "          # If no tool calls, LLM is done\n",
    "          if not response.tool_calls:\n",
    "            pprint(messages[-1])\n",
    "            print(f\"  âœ… Added Last AIMessage to state content\")\n",
    "\n",
    "            return messages[-1]\n",
    "\n",
    "          # Execute tool calls\n",
    "          for tc in response.tool_calls:\n",
    "            print(f\"  ðŸ”§ Calling tool: {tc['name']}\")\n",
    "            print(f\"     Args: {tc['args']}\")\n",
    "\n",
    "            result = self.tools[tc['name']].invoke(tc['args'])\n",
    "\n",
    "            result_str = str(result)\n",
    "            print(f\"     Result: {result_str[:150]}{'...' if len(result_str) > 150 else ''}\\n\")\n",
    "\n",
    "            messages.append(ToolMessage(\n",
    "                tool_call_id=tc['id'],\n",
    "                name=tc['name'],\n",
    "                content=str(result)\n",
    "            ))\n",
    "\n",
    "    def call_agent_plan(self, state: AgentState):\n",
    "      \"\"\"Function to call agent with the promt to produce the outline of the essay\"\"\"\n",
    "      # Invoke LLM\n",
    "      message = HumanMessage(content = PROMPT_PLAN.format(\n",
    "          user_input=state['task']\n",
    "        )\n",
    "      )\n",
    "\n",
    "      print(f\"\\n{'='*60}\")\n",
    "      print(f\"GENERATING OUTLINE\")\n",
    "      print(f\"{'='*60}\")\n",
    "\n",
    "      result = self._invoke_agent(message)\n",
    "      json_result = extract_dict_from_string(result.content)\n",
    "      self._update_state(json_result, state)\n",
    "\n",
    "      print(f\"\\n=== âœ… Requirement ===\")\n",
    "      pprint(f\"{json_result.get('requirement', '')}\")\n",
    "      print(f\"\\n=== âœ… Outline ===\")\n",
    "      pprint(f\"{json_result.get('outline', '')}\")\n",
    "\n",
    "      return {\n",
    "        'outline': json_result.get('outline', ''),\n",
    "        'requirement': json_result.get('requirement', ''),\n",
    "        'max_revisions': state['max_revisions'] if json_result.get('max_revisions', 1) == 0 else json_result.get('max_revisions', 1),\n",
    "        'max_web_search': state['max_web_search'] if json_result.get('max_web_search', 3) == 0 else json_result.get('max_web_search', 3),\n",
    "        'content': state['content'] + [message, result]\n",
    "      }\n",
    "\n",
    "    def call_agent_research(self, state: AgentState):\n",
    "      \"\"\"Function to call agent with the prompt to produce the resource to make the essay\"\"\"\n",
    "      # Invoke LLM\n",
    "      message = HumanMessage(content = PROMPT_RESEARCH.format(\n",
    "          outline=state['outline'],\n",
    "          feedback=state['feedback'],\n",
    "          max_web_search=state['max_web_search']\n",
    "        )\n",
    "      )\n",
    "\n",
    "      print(f\"\\n{'='*60}\")\n",
    "      print(f\"GENERATING RESEARCH\")\n",
    "      print(f\"{'='*60}\")\n",
    "\n",
    "      result = self._invoke_agent(message, 'stream')\n",
    "      json_result = extract_dict_from_string(result.content)\n",
    "      self._update_state(json_result, state)\n",
    "\n",
    "      print(f\"\\n=== âœ… Research ===\")\n",
    "      pprint(f\"{json_result.get('research', '')}\")\n",
    "\n",
    "      return {\n",
    "        'research': json_result.get('research', ''),\n",
    "        'content': state['content'] + [message, result]\n",
    "      }\n",
    "\n",
    "    def call_agent_generate(self, state: AgentState):\n",
    "      \"\"\"Function to call agent with the prompt to produce the draft for the essay\"\"\"\n",
    "      # Invoke LLM\n",
    "      message = HumanMessage(content = PROMPT_GENERATE.format(\n",
    "          outline=state['outline'],\n",
    "          research=state['research'],\n",
    "          requirement=state['requirement'],\n",
    "        )\n",
    "      )\n",
    "\n",
    "      print(f\"\\n{'='*60}\")\n",
    "      print(f\"GENERATING DRAFT - ITERATION {state['revision_number'] + 1}\")\n",
    "      print(f\"{'='*60}\")\n",
    "\n",
    "      result = self._invoke_agent(message)\n",
    "      json_result = extract_dict_from_string(result.content)\n",
    "      self._update_state(json_result, state)\n",
    "\n",
    "      print(f\"\\n=== âœ… Essay ===\")\n",
    "      pprint(f\"{json_result.get('essay', '')}\")\n",
    "\n",
    "      return {\n",
    "        'essay': json_result.get('essay', ''),\n",
    "        'content': state['content'] + [message, result]\n",
    "      }\n",
    "\n",
    "    def check_revision_iteration(self, state: AgentState):\n",
    "      \"\"\"Function to decide whether the draft need to be assess by Reflect agent\"\"\"\n",
    "\n",
    "      print(f\"\\n{'='*60}\")\n",
    "      print(f\"DETERMINE DRAFT NEED TO BE ASSESSED ?\")\n",
    "      print(f\"{'='*60}\")\n",
    "\n",
    "      # # Draft will always be assessed if it's in the 1st iteration\n",
    "      if state['revision_number'] < state['max_revisions']:\n",
    "        return True\n",
    "      else:\n",
    "        if state['need_to_revised'] == 'yes' :\n",
    "          revised_input = input(f\"\\nâ¸ï¸  Reflect agent say it's need to be revised (Score : {state['score']}), would you want to proceed with revision ? (yes/no)\").strip().lower()\n",
    "        elif state['need_to_revised'] != 'yes' :\n",
    "          revised_input = input(f\"\\nâ¸ï¸  Reflect agent say the draft is already good ðŸ‘ (Score : {state['score']}), would you want to proceed with revision ? (yes/no)\").strip().lower()\n",
    "\n",
    "        if revised_input == 'yes' :\n",
    "          return True\n",
    "        else :\n",
    "          return False\n",
    "\n",
    "    def call_agent_reflect(self, state: AgentState):\n",
    "      \"\"\"Function to call agent with the prompt to evaluate the essay draft\"\"\"\n",
    "\n",
    "      # Invoke LLM\n",
    "      message = HumanMessage(content = PROMPT_REFLECT.format(\n",
    "          essay=state['essay'],\n",
    "          requirement=state['requirement'],\n",
    "        )\n",
    "      )\n",
    "\n",
    "      print(f\"\\n{'='*60}\")\n",
    "      print(f\"ASSESSING DRAFT - ITERATION {state['revision_number'] + 1}\")\n",
    "      print(f\"{'='*60}\")\n",
    "\n",
    "      result = self._invoke_agent(message)\n",
    "      json_result = extract_dict_from_string(result.content)\n",
    "      self._update_state(json_result, state)\n",
    "\n",
    "      print(f\"\\n=== âœ… Feedback ===\")\n",
    "      pprint(f\"{json_result.get('feedback', '')}\")\n",
    "\n",
    "      print(f\"\\nDraft Score : {json_result.get('score', 0)}\")\n",
    "\n",
    "      return {\n",
    "        'feedback': json_result.get('feedback', ''),\n",
    "        'score': json_result.get('score', 0),\n",
    "        'need_to_revised': json_result.get('need_to_revised', 'yes'),\n",
    "        'revision_number': state['revision_number'] + 1,\n",
    "      }\n",
    "\n",
    "    def execute(self, message) :\n",
    "      \"\"\"Function to run the agent graph flow\"\"\"\n",
    "\n",
    "      self.input_message = message\n",
    "      print(f\"\\n{'='*60}\")\n",
    "      print(f\"TOPIC FROM THE USER\")\n",
    "      print(f\"{'='*60}\")\n",
    "      pprint(f\"{self.input_message}\")\n",
    "\n",
    "      # âœ… Initialize ALL required state fields\n",
    "      initial_state = {\n",
    "          'task': self.input_message,\n",
    "          'requirement': '',\n",
    "          'outline': '',\n",
    "          'research': '',\n",
    "          'essay': '',\n",
    "          'feedback': '',\n",
    "          'need_to_revised' : 'yes',\n",
    "          'score': 0,\n",
    "          'content': [],\n",
    "          'revision_number': 0,\n",
    "          'max_revisions': self.max_revision,\n",
    "          'max_web_search': 3,\n",
    "      }\n",
    "\n",
    "      # Run the graph\n",
    "      result = self.graph_np.invoke(\n",
    "          initial_state,\n",
    "          config=self.config\n",
    "      )\n",
    "\n",
    "      # Get final answer\n",
    "      final_answer = result['essay']\n",
    "\n",
    "      # Change it to HTML mode\n",
    "      print(f\"\\n{'='*60}\")\n",
    "      print(f\"CHANGE THE ESSAY TO HTML MODE\")\n",
    "      print(f\"{'='*60}\")\n",
    "\n",
    "      PROMPT_HTML = \"\"\"\n",
    "        Please help change this text to HTML mode, highlight the key point from the essay with bold and red pastel color\n",
    "\n",
    "        Text : {final_answer}\n",
    "      \"\"\"\n",
    "\n",
    "      message_html = HumanMessage(content = PROMPT_HTML.format(\n",
    "          final_answer=final_answer,\n",
    "        )\n",
    "      )\n",
    "      final_answer_html = self._invoke_agent(message_html)\n",
    "\n",
    "      print(f\"\\n âœ… HTML Generated\")\n",
    "\n",
    "      return final_answer_html\n",
    "\n",
    "\n",
    "# Define system prompt\n",
    "bot = EssayWriterAgent([search_tool], [], 3)\n",
    "\n",
    "# Display LangGraph structure\n",
    "try:\n",
    "    # Try to visualize the graph\n",
    "    display(Image(bot.graph_np.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Visualization error: {e}\")\n",
    "    print(\"\\nGraph structure (ASCII):\")\n",
    "    print(bot.graph_np.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eXDPzoKBJvv8",
    "outputId": "7206cf0f-262d-4836-dad9-c8865549499d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TOPIC FROM THE USER\n",
      "============================================================\n",
      "('what is the difference between langchain and langsmith, you can do 5 web '\n",
      " 'search and 2 revision')\n",
      "\n",
      "============================================================\n",
      "GENERATING OUTLINE\n",
      "============================================================\n",
      "  âœ… Added HumanMessage to state content\n",
      "  âœ… Added Last AIMessage to state content\n",
      "  âœ… Updated 'requirement'\n",
      "  âœ… Updated 'max_web_search'\n",
      "  âœ… Updated 'max_revisions'\n",
      "  âœ… Updated 'outline'\n",
      "\n",
      "=== âœ… Requirement ===\n",
      "('Create a 5-paragraph essay explaining the differences between LangChain and '\n",
      " 'LangSmith, with support from up to 5 web searches and up to 2 revisions')\n",
      "\n",
      "=== âœ… Outline ===\n",
      "(\"{'thesis_statement': 'While LangChain and LangSmith are complementary tools \"\n",
      " 'within the LLM development ecosystem, they serve distinct purposes: '\n",
      " 'LangChain is a framework for building applications with language models, '\n",
      " 'whereas LangSmith is a platform for monitoring, debugging, and optimizing '\n",
      " \"those applications.', 'introduction': {'hook': 'As large language models \"\n",
      " 'become increasingly central to software development, developers need tools '\n",
      " \"to both build and maintain these applications effectively.', 'context': \"\n",
      " \"'LangChain and LangSmith are two prominent tools in the AI development space \"\n",
      " 'that often appear together in discussions, yet they address fundamentally '\n",
      " \"different aspects of LLM application development.', 'preview': 'This essay \"\n",
      " 'will clarify the distinct roles of each tool and explain how they complement '\n",
      " \"one another.'}, 'body_sections': [{'section_title': 'LangChain: A Framework \"\n",
      " \"for Building LLM Applications', 'key_points': [{'point': 'Core Purpose and \"\n",
      " \"Functionality', 'description': 'Explain that LangChain is an open-source \"\n",
      " 'framework designed to simplify the development of applications powered by '\n",
      " 'language models, including features like chains, agents, and memory '\n",
      " \"management.'}, {'point': 'Key Features and Components', 'description': \"\n",
      " \"'Discuss essential LangChain components such as prompt templates, \"\n",
      " 'retrievers, document loaders, and the ability to chain multiple LLM calls '\n",
      " \"together.'}, {'point': 'Use Cases', 'description': 'Provide examples of \"\n",
      " 'applications built with LangChain, such as chatbots, question-answering '\n",
      " \"systems, and document analysis tools.'}]}, {'section_title': 'LangSmith: A \"\n",
      " \"Platform for Monitoring and Optimization', 'key_points': [{'point': 'Core \"\n",
      " \"Purpose and Functionality', 'description': 'Explain that LangSmith is a \"\n",
      " 'platform developed by LangChain creators for tracing, monitoring, and '\n",
      " \"debugging LLM applications in production and development.'}, {'point': 'Key \"\n",
      " \"Features and Capabilities', 'description': 'Detail features such as \"\n",
      " 'execution tracing, performance metrics, error logging, dataset management, '\n",
      " \"and A/B testing capabilities.'}, {'point': 'Use Cases', 'description': \"\n",
      " \"'Describe how LangSmith helps developers identify bottlenecks, improve \"\n",
      " \"response quality, and maintain application reliability.'}]}, \"\n",
      " \"{'section_title': 'Key Differences and Complementary Relationship', \"\n",
      " \"'key_points': [{'point': 'Primary Function Distinction', 'description': \"\n",
      " \"'Clarify that LangChain is for building (development), while LangSmith is \"\n",
      " \"for observing and optimizing (production and testing).'}, {'point': \"\n",
      " \"'Integration and Workflow', 'description': 'Explain how LangSmith integrates \"\n",
      " 'with LangChain applications to provide visibility into their behavior and '\n",
      " \"performance.'}, {'point': 'Dependency and Independence', 'description': \"\n",
      " \"'Note that LangChain can be used independently, while LangSmith is \"\n",
      " \"specifically designed to work with LangChain applications.'}]}], \"\n",
      " \"'conclusion': {'summary': 'LangChain and LangSmith address different stages \"\n",
      " 'of LLM application development: LangChain provides the building blocks for '\n",
      " 'creating applications, while LangSmith offers the tools for understanding '\n",
      " \"and improving them.', 'broader_significance': 'Together, they form a \"\n",
      " 'comprehensive ecosystem that enables developers to build robust, observable, '\n",
      " \"and optimized language model applications.', 'closing_thought': \"\n",
      " \"'Understanding the distinction between these tools is essential for \"\n",
      " 'developers seeking to leverage the full potential of modern LLM development '\n",
      " \"practices.'}}\")\n",
      "\n",
      "============================================================\n",
      "GENERATING RESEARCH\n",
      "============================================================\n",
      "  âœ… Added HumanMessage to state content\n",
      "  ðŸ”§ Calling tool: tavily_search_results_json\n",
      "     Args: {'query': 'LangChain framework building LLM applications features components'}\n",
      "     Result: [{'title': 'LangChain Explained: The Ultimate Framework for Building LLM ...', 'url': 'https://www.digitalocean.com/community/conceptual-articles/lang...\n",
      "\n",
      "  ðŸ”§ Calling tool: tavily_search_results_json\n",
      "     Args: {'query': 'LangSmith platform monitoring debugging LLM applications'}\n",
      "     Result: [{'title': 'What is LangSmith? | IBM', 'url': 'https://www.ibm.com/think/topics/langsmith', 'content': 'One of the biggest challenges in building reli...\n",
      "\n",
      "  ðŸ”§ Calling tool: tavily_search_results_json\n",
      "     Args: {'query': 'LangChain vs LangSmith differences complementary tools'}\n",
      "     Result: [{'title': 'LangChain vs LangGraph vs LangSmith: Which One Should You Use?', 'url': 'https://codebasics.io/blog/what-are-the-differences-between-langc...\n",
      "\n",
      "  ðŸ”§ Calling tool: tavily_search_results_json\n",
      "     Args: {'query': 'LangChain use cases chatbots question-answering document analysis'}\n",
      "     Result: [{'title': 'LangChain Use Cases and Initial Setup Guide - Ksolves', 'url': 'https://www.ksolves.com/blog/artificial-intelligence/langchain-use-cases-a...\n",
      "\n",
      "  ðŸ”§ Calling tool: tavily_search_results_json\n",
      "     Args: {'query': 'LangSmith tracing performance metrics A/B testing LLM applications'}\n",
      "     Result: [{'title': 'LangSmith Explained: Debugging and Evaluating LLM Agents', 'url': 'https://www.digitalocean.com/community/tutorials/langsmith-debudding-ev...\n",
      "\n",
      "AIMessage(content='Perfect! I have gathered comprehensive research from credible sources. Let me organize this information according to your essay outline:\\n\\n```json\\n{\\n  \"research\": [\\n    {\\n      \"section_title\": \"LangChain: A Framework for Building LLM Applications\",\\n      \"key_points\": [\\n        {\\n          \"point\": \"Core Purpose and Functionality\",\\n          \"supporting_information\": [\\n            {\\n              \"fact\": \"LangChain is a flexible, modular framework that simplifies building advanced LLM-powered applications. Its component-based architecture, extensive building blocks, and integration capabilities allow you to easily connect your language models to external data, tools, and workflows.\",\\n              \"source\": \"LangChain Explained: The Ultimate Framework for Building LLM Applications (https://www.digitalocean.com/community/conceptual-articles/langchain-framework-explained)\"\\n            },\\n            {\\n              \"fact\": \"LangChain serves as a generic interface for nearly any LLM, providing a centralized development environment to build LLM applications and integrate them with external data sources and software workflows.\",\\n              \"source\": \"What Is LangChain? | IBM (https://www.ibm.com/think/topics/langchain)\"\\n            },\\n            {\\n              \"fact\": \"LangChain is an open-source framework designed to simplify the development of applications powered by language models, including features like chains, agents, and memory management.\",\\n              \"source\": \"LangChain Explained: The Ultimate Framework for Building LLM Applications (https://www.digitalocean.com/community/conceptual-articles/langchain-framework-explained)\"\\n            }\\n          ]\\n        },\\n        {\\n          \"point\": \"Key Features and Components\",\\n          \"supporting_information\": [\\n            {\\n              \"fact\": \"A chain is a series of steps (each step can be an LLM call, a data retrieval, or other action) that feeds its output to the next step in the chain. LangChain includes several built-in chain types and offers a powerful framework for building and executing such chains in Python (or JavaScript).\",\\n              \"source\": \"LangChain Explained: The Ultimate Framework for Building LLM Applications (https://www.digitalocean.com/community/conceptual-articles/langchain-framework-explained)\"\\n            },\\n            {\\n              \"fact\": \"LangChain\\'s module-based approach allows developers and data scientists to dynamically compare different prompts and even different foundation models with minimal need to rewrite code. This modular environment also allows for programs that use multiple LLMs.\",\\n              \"source\": \"What Is LangChain? | IBM (https://www.ibm.com/think/topics/langchain)\"\\n            },\\n            {\\n              \"fact\": \"Using LangChain, you can abstract away the differences between model providers. This way, your code can easily switch between OpenAI, Anthropic, Azure, Hugging Face, etc., by changing the model specification.\",\\n              \"source\": \"LangChain Explained: The Ultimate Framework for Building LLM Applications (https://www.digitalocean.com/community/conceptual-articles/langchain-framework-explained)\"\\n            }\\n          ]\\n        },\\n        {\\n          \"point\": \"Use Cases\",\\n          \"supporting_information\": [\\n            {\\n              \"fact\": \"Chatbots and conversational agents act as assistants for users, who give answers to all the questions asked by their users. LangChain applications utilize language models for complicated reasoning, such as choosing how to reply or what actions to take, and can grasp the context.\",\\n              \"source\": \"LangChain Use Cases and Initial Setup Guide - Ksolves (https://www.ksolves.com/blog/artificial-intelligence/langchain-use-cases-and-initial-setup-guide)\"\\n            },\\n            {\\n              \"fact\": \"One of the most powerful use cases of LangChain is establishing question-and-answer chatbots powered by Retrieval Augmented Generation (RAG), a method for adding new data to enhance LLM knowledge.\",\\n              \"source\": \"LangChain Use Cases and Initial Setup Guide - Ksolves (https://www.ksolves.com/blog/artificial-intelligence/langchain-use-cases-and-initial-setup-guide)\"\\n            },\\n            {\\n              \"fact\": \"Developers can use LangChain to build systems that can parse through complicated documents and extract pertinent information into organized representations such as JSON or tables. For example, it can automatically extract dates, quantities, and transaction details from financial accounts in the financial services industry.\",\\n              \"source\": \"LangChain Use Cases and Initial Setup Guide - Ksolves (https://www.ksolves.com/blog/artificial-intelligence/langchain-use-cases-and-initial-setup-guide)\"\\n            }\\n          ]\\n        }\\n      ]\\n    },\\n    {\\n      \"section_title\": \"LangSmith: A Platform for Monitoring and Optimization\",\\n      \"key_points\": [\\n        {\\n          \"point\": \"Core Purpose and Functionality\",\\n          \"supporting_information\": [\\n            {\\n              \"fact\": \"LangSmith is a platform for observability, testing, and evaluation of LLM applications. Created by the LangChain team, it helps ensure reliability in production. LangSmith provides tools to debug, monitor, and improve LLM-powered agents, and offers a managed cloud service with a web UI.\",\\n              \"source\": \"LangChain vs LangSmith: A Developer-Focused Comparison (https://blog.promptlayer.com/langchain-vs-langsmith/)\"\\n            },\\n            {\\n              \"fact\": \"One of the biggest challenges in building reliable large language model (LLM) applications is understanding why an artificial intelligence (AI) system fails or behaves unexpectedly, once deployed. LangSmith offers a robust solution for addressing these challenges, serving as a dedicated platform for monitoring, debugging and evaluating applications built with large language models.\",\\n              \"source\": \"What is LangSmith? | IBM (https://www.ibm.com/think/topics/langsmith)\"\\n            },\\n            {\\n              \"fact\": \"LangSmith is an end-to-end toolkit for building, debugging, testing, evaluating, and deploying your LLM-powered apps. Using Langsmith, you can trace each request, evaluate your output, iterate on your prompts with version control, and manage your agent deployments.\",\\n              \"source\": \"LangSmith Explained: Debugging and Evaluating LLM Agents (https://www.digitalocean.com/community/tutorials/langsmith-debudding-evaluating-llm-agents)\"\\n            }\\n          ]\\n        },\\n        {\\n          \"point\": \"Key Features and Capabilities\",\\n          \"supporting_information\": [\\n            {\\n              \"fact\": \"LangSmith offers detailed, sequential visibility into each interaction with LLMs, helping ensure clear traceability throughout the process. Developers can trace, track and display the step-by-step flow of data through the application by using LangChain Expression Language (LCEL).\",\\n              \"source\": \"What is LangSmith? | IBM (https://www.ibm.com/think/topics/langsmith)\"\\n            },\\n            {\\n              \"fact\": \"LangSmith delivers end-to-end observability for LLM workflows such as real-time logging of executions, latency and error rates, integration with alerting systems for prompt incident reporting and dashboards that provide insights into usage patterns and system health.\",\\n              \"source\": \"What is LangSmith? | IBM (https://www.ibm.com/think/topics/langsmith)\"\\n            },\\n            {\\n              \"fact\": \"LangSmith has a full-fledged evaluation workflow to support both offline testing and online monitoring of your LLM app\\'s quality. Pairwise Annotation Queues (PAQs) present two outputs side by side and ask the reviewer to choose which one is better, which is useful for A/B testing.\",\\n              \"source\": \"LangSmith Explained: Debugging and Evaluating LLM Agents (https://www.digitalocean.com/community/tutorials/langsmith-debudding-evaluating-llm-agents)\"\\n            },\\n            {\\n              \"fact\": \"LangSmith\\'s ability to track metrics like latency and time-to-first-token for every step in a chain is invaluable. By seeing the token counts for each LLM call, you can identify opportunities to shorten prompts or use smaller, cheaper models for certain tasks, thereby optimizing operational costs.\",\\n              \"source\": \"What is LangSmith? A Comprehensive Guide to LLM Observability (https://www.metacto.com/blogs/what-is-langsmith-a-comprehensive-guide-to-llm-observability)\"\\n            }\\n          ]\\n        },\\n        {\\n          \"point\": \"Use Cases\",\\n          \"supporting_information\": [\\n            {\\n              \"fact\": \"With LangSmith\\'s tracing, every LLM call, tool invocation, and intermediate reasoning step is observable, so you can understand why an agent took a certain action. Traces turn debugging into analysis by allowing you to inspect and methodically diagnose prompt failures, tool failures, retrieval issues, and orchestration bugs.\",\\n              \"source\": \"LangSmith Explained: Debugging and Evaluating LLM Agents (https://www.digitalocean.com/community/tutorials/langsmith-debudding-evaluating-llm-agents)\"\\n            },\\n            {\\n              \"fact\": \"LangSmith\\'s dataset-driven evaluation workflow (available both offline and online) allows you to measure your application\\'s quality, compare prompt/model versions, and detect regressions before you release any changes to production.\",\\n              \"source\": \"LangSmith Explained: Debugging and Evaluating LLM Agents (https://www.digitalocean.com/community/tutorials/langsmith-debudding-evaluating-llm-agents)\"\\n            },\\n            {\\n              \"fact\": \"If users are complaining about a slow application, you can dive into the traces to identify the bottleneck. Is it a slow vector search? A complex prompt that takes the LLM a long time to process? LangSmith gives you the data to answer these questions and focus your optimization efforts where they will have the most impact.\",\\n              \"source\": \"What is LangSmith? A Comprehensive Guide to LLM Observability (https://www.metacto.com/blogs/what-is-langsmith-a-comprehensive-guide-to-llm-observability)\"\\n            }\\n          ]\\n        }\\n      ]\\n    },\\n    {\\n      \"section_title\": \"Key Differences and Complementary Relationship\",\\n      \"key_points\": [\\n        {\\n          \"point\": \"Primary Function Distinction\",\\n          \"supporting_information\": [\\n            {\\n              \"fact\": \"LangChain, LangGraph, and LangSmith aren\\'t competitorsâ€”they\\'re complementary. Think of them as a full-stack toolkit for modern LLM app development: LangChain helps you build, LangGraph helps you orchestrate, and LangSmith helps you optimize.\",\\n              \"source\": \"LangChain vs LangGraph vs LangSmith: Which One Should You Use? (https://codebasics.io/blog/what-are-the-differences-between-langchain-langgraph-and-langsmith)\"\\n            },\\n            {\\n              \"fact\": \"LangChain is an open-source framework (Python/JS) for building LLM apps with primary purpose of development and orchestration, while LangSmith is a managed platform (web app) for monitoring and improving LLM apps with primary purpose of observability and evaluation.\",\\n              \"source\": \"LangChain vs LangSmith: A Developer-Focused Comparison (https://blog.promptlayer.com/langchain-vs-langsmith/)\"\\n            },\\n            {\\n              \"fact\": \"LangChain itself does not include a full evaluation suite. Developers can create custom evaluation workflows, but these are typically manual. For systematic evaluation and benchmarking, LangChain recommends integrating with LangSmith.\",\\n              \"source\": \"LangChain vs LangSmith: A Developer-Focused Comparison (https://blog.promptlayer.com/langchain-vs-langsmith/)\"\\n            }\\n          ]\\n        },\\n        {\\n          \"point\": \"Integration and Workflow\",\\n          \"supporting_information\": [\\n            {\\n              \"fact\": \"LangChain provides basic logging and a callback system for instrumentation. For detailed tracing, it integrates with LangSmith, enabling step-by-step visibility into application execution through the LangSmith UI. Without LangSmith, observability is limited to console logs or custom solutions.\",\\n              \"source\": \"LangChain vs LangSmith: A Developer-Focused Comparison (https://blog.promptlayer.com/langchain-vs-langsmith/)\"\\n            },\\n            {\\n              \"fact\": \"LangSmith does not build agents but supports the agent development lifecycle. Developers can trace and evaluate agent decisions, test against diverse scenarios, and monitor production performance. This speeds up debugging and improves reliability.\",\\n              \"source\": \"LangChain vs LangSmith: A Developer-Focused Comparison (https://blog.promptlayer.com/langchain-vs-langsmith/)\"\\n            }\\n          ]\\n        },\\n        {\\n          \"point\": \"Dependency and Independence\",\\n          \"supporting_information\": [\\n            {\\n              \"fact\": \"Unlike some of the observability tools, which are often tightly coupled to a particular LLM application framework, LangSmith is framework-agnostic. You can use it with LangChain, LangGraph, or other custom code. That means you don\\'t need to build your agent on LangChain to take advantage of LangSmith\\'s tracing and evaluation features.\",\\n              \"source\": \"LangSmith Explained: Debugging and Evaluating LLM Agents (https://www.digitalocean.com/community/tutorials/langsmith-debudding-evaluating-llm-agents)\"\\n            }\\n          ]\\n        }\\n      ]\\n    }\\n  ]\\n}\\n```\\n\\n## Summary\\n\\nI\\'ve completed comprehensive research on LangChain and LangSmith, gathering information from 5 authoritative sources:\\n\\n1. **DigitalOcean** - Technical tutorials and conceptual articles\\n2. **IBM** - Enterprise-level explanations of both tools\\n3. **CodeBasics** - Comparative analysis of LangChain, LangGraph, and LangSmith\\n4. **PromptLayer Blog** - Developer-focused comparison\\n5. **MetaCTO** - Comprehensive guide to LLM observability\\n\\n**Key findings organized by section:**\\n\\n- **LangChain Section**: Documented its core purpose as a framework, key components (chains, agents, memory), and practical use cases (chatbots, RAG, document analysis)\\n- **LangSmith Section**: Established its role in monitoring, debugging, and optimization with specific features (tracing, performance metrics, A/B testing, evaluation workflows)\\n- **Differences & Complementary Relationship**: Clarified that LangChain is for building while LangSmith is for observing, their integration points, and LangSmith\\'s framework-agnostic nature\\n\\nAll sources are recent, credible (IBM, DigitalOcean, technical blogs), and directly support your thesis that these are complementary but distinct tools.', additional_kwargs={}, response_metadata={'id': 'msg_013p5fkrZY1Wwt32ZsxH64J6', 'model': 'claude-haiku-4-5-20251001', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation': {'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 6677, 'output_tokens': 3624, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-haiku-4-5-20251001', 'model_provider': 'anthropic'}, id='lc_run--019c235e-3d80-7263-904e-0997790abd0b-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 6677, 'output_tokens': 3624, 'total_tokens': 10301, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}})\n",
      "  âœ… Added Last AIMessage to state content\n",
      "  âœ… Updated 'research'\n",
      "\n",
      "=== âœ… Research ===\n",
      "(\"[{'section_title': 'LangChain: A Framework for Building LLM Applications', \"\n",
      " \"'key_points': [{'point': 'Core Purpose and Functionality', \"\n",
      " \"'supporting_information': [{'fact': 'LangChain is a flexible, modular \"\n",
      " 'framework that simplifies building advanced LLM-powered applications. Its '\n",
      " 'component-based architecture, extensive building blocks, and integration '\n",
      " 'capabilities allow you to easily connect your language models to external '\n",
      " \"data, tools, and workflows.', 'source': 'LangChain Explained: The Ultimate \"\n",
      " 'Framework for Building LLM Applications '\n",
      " \"(https://www.digitalocean.com/community/conceptual-articles/langchain-framework-explained)'}, \"\n",
      " \"{'fact': 'LangChain serves as a generic interface for nearly any LLM, \"\n",
      " 'providing a centralized development environment to build LLM applications '\n",
      " \"and integrate them with external data sources and software workflows.', \"\n",
      " \"'source': 'What Is LangChain? | IBM \"\n",
      " \"(https://www.ibm.com/think/topics/langchain)'}, {'fact': 'LangChain is an \"\n",
      " 'open-source framework designed to simplify the development of applications '\n",
      " 'powered by language models, including features like chains, agents, and '\n",
      " \"memory management.', 'source': 'LangChain Explained: The Ultimate Framework \"\n",
      " 'for Building LLM Applications '\n",
      " \"(https://www.digitalocean.com/community/conceptual-articles/langchain-framework-explained)'}]}, \"\n",
      " \"{'point': 'Key Features and Components', 'supporting_information': [{'fact': \"\n",
      " \"'A chain is a series of steps (each step can be an LLM call, a data \"\n",
      " 'retrieval, or other action) that feeds its output to the next step in the '\n",
      " 'chain. LangChain includes several built-in chain types and offers a powerful '\n",
      " 'framework for building and executing such chains in Python (or '\n",
      " \"JavaScript).', 'source': 'LangChain Explained: The Ultimate Framework for \"\n",
      " 'Building LLM Applications '\n",
      " \"(https://www.digitalocean.com/community/conceptual-articles/langchain-framework-explained)'}, \"\n",
      " '{\\'fact\\': \"LangChain\\'s module-based approach allows developers and data '\n",
      " 'scientists to dynamically compare different prompts and even different '\n",
      " 'foundation models with minimal need to rewrite code. This modular '\n",
      " 'environment also allows for programs that use multiple LLMs.\", \\'source\\': '\n",
      " \"'What Is LangChain? | IBM (https://www.ibm.com/think/topics/langchain)'}, \"\n",
      " \"{'fact': 'Using LangChain, you can abstract away the differences between \"\n",
      " 'model providers. This way, your code can easily switch between OpenAI, '\n",
      " \"Anthropic, Azure, Hugging Face, etc., by changing the model specification.', \"\n",
      " \"'source': 'LangChain Explained: The Ultimate Framework for Building LLM \"\n",
      " 'Applications '\n",
      " \"(https://www.digitalocean.com/community/conceptual-articles/langchain-framework-explained)'}]}, \"\n",
      " \"{'point': 'Use Cases', 'supporting_information': [{'fact': 'Chatbots and \"\n",
      " 'conversational agents act as assistants for users, who give answers to all '\n",
      " 'the questions asked by their users. LangChain applications utilize language '\n",
      " 'models for complicated reasoning, such as choosing how to reply or what '\n",
      " \"actions to take, and can grasp the context.', 'source': 'LangChain Use Cases \"\n",
      " 'and Initial Setup Guide - Ksolves '\n",
      " \"(https://www.ksolves.com/blog/artificial-intelligence/langchain-use-cases-and-initial-setup-guide)'}, \"\n",
      " \"{'fact': 'One of the most powerful use cases of LangChain is establishing \"\n",
      " 'question-and-answer chatbots powered by Retrieval Augmented Generation '\n",
      " \"(RAG), a method for adding new data to enhance LLM knowledge.', 'source': \"\n",
      " \"'LangChain Use Cases and Initial Setup Guide - Ksolves \"\n",
      " \"(https://www.ksolves.com/blog/artificial-intelligence/langchain-use-cases-and-initial-setup-guide)'}, \"\n",
      " \"{'fact': 'Developers can use LangChain to build systems that can parse \"\n",
      " 'through complicated documents and extract pertinent information into '\n",
      " 'organized representations such as JSON or tables. For example, it can '\n",
      " 'automatically extract dates, quantities, and transaction details from '\n",
      " \"financial accounts in the financial services industry.', 'source': \"\n",
      " \"'LangChain Use Cases and Initial Setup Guide - Ksolves \"\n",
      " \"(https://www.ksolves.com/blog/artificial-intelligence/langchain-use-cases-and-initial-setup-guide)'}]}]}, \"\n",
      " \"{'section_title': 'LangSmith: A Platform for Monitoring and Optimization', \"\n",
      " \"'key_points': [{'point': 'Core Purpose and Functionality', \"\n",
      " \"'supporting_information': [{'fact': 'LangSmith is a platform for \"\n",
      " 'observability, testing, and evaluation of LLM applications. Created by the '\n",
      " 'LangChain team, it helps ensure reliability in production. LangSmith '\n",
      " 'provides tools to debug, monitor, and improve LLM-powered agents, and offers '\n",
      " \"a managed cloud service with a web UI.', 'source': 'LangChain vs LangSmith: \"\n",
      " 'A Developer-Focused Comparison '\n",
      " \"(https://blog.promptlayer.com/langchain-vs-langsmith/)'}, {'fact': 'One of \"\n",
      " 'the biggest challenges in building reliable large language model (LLM) '\n",
      " 'applications is understanding why an artificial intelligence (AI) system '\n",
      " 'fails or behaves unexpectedly, once deployed. LangSmith offers a robust '\n",
      " 'solution for addressing these challenges, serving as a dedicated platform '\n",
      " 'for monitoring, debugging and evaluating applications built with large '\n",
      " \"language models.', 'source': 'What is LangSmith? | IBM \"\n",
      " \"(https://www.ibm.com/think/topics/langsmith)'}, {'fact': 'LangSmith is an \"\n",
      " 'end-to-end toolkit for building, debugging, testing, evaluating, and '\n",
      " 'deploying your LLM-powered apps. Using Langsmith, you can trace each '\n",
      " 'request, evaluate your output, iterate on your prompts with version control, '\n",
      " \"and manage your agent deployments.', 'source': 'LangSmith Explained: \"\n",
      " 'Debugging and Evaluating LLM Agents '\n",
      " \"(https://www.digitalocean.com/community/tutorials/langsmith-debudding-evaluating-llm-agents)'}]}, \"\n",
      " \"{'point': 'Key Features and Capabilities', 'supporting_information': \"\n",
      " \"[{'fact': 'LangSmith offers detailed, sequential visibility into each \"\n",
      " 'interaction with LLMs, helping ensure clear traceability throughout the '\n",
      " 'process. Developers can trace, track and display the step-by-step flow of '\n",
      " 'data through the application by using LangChain Expression Language '\n",
      " \"(LCEL).', 'source': 'What is LangSmith? | IBM \"\n",
      " \"(https://www.ibm.com/think/topics/langsmith)'}, {'fact': 'LangSmith delivers \"\n",
      " 'end-to-end observability for LLM workflows such as real-time logging of '\n",
      " 'executions, latency and error rates, integration with alerting systems for '\n",
      " 'prompt incident reporting and dashboards that provide insights into usage '\n",
      " \"patterns and system health.', 'source': 'What is LangSmith? | IBM \"\n",
      " '(https://www.ibm.com/think/topics/langsmith)\\'}, {\\'fact\\': \"LangSmith has a '\n",
      " 'full-fledged evaluation workflow to support both offline testing and online '\n",
      " \"monitoring of your LLM app's quality. Pairwise Annotation Queues (PAQs) \"\n",
      " 'present two outputs side by side and ask the reviewer to choose which one is '\n",
      " 'better, which is useful for A/B testing.\", \\'source\\': \\'LangSmith '\n",
      " 'Explained: Debugging and Evaluating LLM Agents '\n",
      " \"(https://www.digitalocean.com/community/tutorials/langsmith-debudding-evaluating-llm-agents)'}, \"\n",
      " '{\\'fact\\': \"LangSmith\\'s ability to track metrics like latency and '\n",
      " 'time-to-first-token for every step in a chain is invaluable. By seeing the '\n",
      " 'token counts for each LLM call, you can identify opportunities to shorten '\n",
      " 'prompts or use smaller, cheaper models for certain tasks, thereby optimizing '\n",
      " 'operational costs.\", \\'source\\': \\'What is LangSmith? A Comprehensive Guide '\n",
      " 'to LLM Observability '\n",
      " \"(https://www.metacto.com/blogs/what-is-langsmith-a-comprehensive-guide-to-llm-observability)'}]}, \"\n",
      " '{\\'point\\': \\'Use Cases\\', \\'supporting_information\\': [{\\'fact\\': \"With '\n",
      " \"LangSmith's tracing, every LLM call, tool invocation, and intermediate \"\n",
      " 'reasoning step is observable, so you can understand why an agent took a '\n",
      " 'certain action. Traces turn debugging into analysis by allowing you to '\n",
      " 'inspect and methodically diagnose prompt failures, tool failures, retrieval '\n",
      " 'issues, and orchestration bugs.\", \\'source\\': \\'LangSmith Explained: '\n",
      " 'Debugging and Evaluating LLM Agents '\n",
      " \"(https://www.digitalocean.com/community/tutorials/langsmith-debudding-evaluating-llm-agents)'}, \"\n",
      " '{\\'fact\\': \"LangSmith\\'s dataset-driven evaluation workflow (available both '\n",
      " \"offline and online) allows you to measure your application's quality, \"\n",
      " 'compare prompt/model versions, and detect regressions before you release any '\n",
      " 'changes to production.\", \\'source\\': \\'LangSmith Explained: Debugging and '\n",
      " 'Evaluating LLM Agents '\n",
      " \"(https://www.digitalocean.com/community/tutorials/langsmith-debudding-evaluating-llm-agents)'}, \"\n",
      " \"{'fact': 'If users are complaining about a slow application, you can dive \"\n",
      " 'into the traces to identify the bottleneck. Is it a slow vector search? A '\n",
      " 'complex prompt that takes the LLM a long time to process? LangSmith gives '\n",
      " 'you the data to answer these questions and focus your optimization efforts '\n",
      " \"where they will have the most impact.', 'source': 'What is LangSmith? A \"\n",
      " 'Comprehensive Guide to LLM Observability '\n",
      " \"(https://www.metacto.com/blogs/what-is-langsmith-a-comprehensive-guide-to-llm-observability)'}]}]}, \"\n",
      " \"{'section_title': 'Key Differences and Complementary Relationship', \"\n",
      " \"'key_points': [{'point': 'Primary Function Distinction', \"\n",
      " '\\'supporting_information\\': [{\\'fact\\': \"LangChain, LangGraph, and LangSmith '\n",
      " \"aren't competitorsâ€”they're complementary. Think of them as a full-stack \"\n",
      " 'toolkit for modern LLM app development: LangChain helps you build, LangGraph '\n",
      " 'helps you orchestrate, and LangSmith helps you optimize.\", \\'source\\': '\n",
      " \"'LangChain vs LangGraph vs LangSmith: Which One Should You Use? \"\n",
      " \"(https://codebasics.io/blog/what-are-the-differences-between-langchain-langgraph-and-langsmith)'}, \"\n",
      " \"{'fact': 'LangChain is an open-source framework (Python/JS) for building LLM \"\n",
      " 'apps with primary purpose of development and orchestration, while LangSmith '\n",
      " 'is a managed platform (web app) for monitoring and improving LLM apps with '\n",
      " \"primary purpose of observability and evaluation.', 'source': 'LangChain vs \"\n",
      " 'LangSmith: A Developer-Focused Comparison '\n",
      " \"(https://blog.promptlayer.com/langchain-vs-langsmith/)'}, {'fact': \"\n",
      " \"'LangChain itself does not include a full evaluation suite. Developers can \"\n",
      " 'create custom evaluation workflows, but these are typically manual. For '\n",
      " 'systematic evaluation and benchmarking, LangChain recommends integrating '\n",
      " \"with LangSmith.', 'source': 'LangChain vs LangSmith: A Developer-Focused \"\n",
      " \"Comparison (https://blog.promptlayer.com/langchain-vs-langsmith/)'}]}, \"\n",
      " \"{'point': 'Integration and Workflow', 'supporting_information': [{'fact': \"\n",
      " \"'LangChain provides basic logging and a callback system for instrumentation. \"\n",
      " 'For detailed tracing, it integrates with LangSmith, enabling step-by-step '\n",
      " 'visibility into application execution through the LangSmith UI. Without '\n",
      " \"LangSmith, observability is limited to console logs or custom solutions.', \"\n",
      " \"'source': 'LangChain vs LangSmith: A Developer-Focused Comparison \"\n",
      " \"(https://blog.promptlayer.com/langchain-vs-langsmith/)'}, {'fact': \"\n",
      " \"'LangSmith does not build agents but supports the agent development \"\n",
      " 'lifecycle. Developers can trace and evaluate agent decisions, test against '\n",
      " 'diverse scenarios, and monitor production performance. This speeds up '\n",
      " \"debugging and improves reliability.', 'source': 'LangChain vs LangSmith: A \"\n",
      " 'Developer-Focused Comparison '\n",
      " \"(https://blog.promptlayer.com/langchain-vs-langsmith/)'}]}, {'point': \"\n",
      " \"'Dependency and Independence', 'supporting_information': [{'fact': \"\n",
      " '\"Unlike some of the observability tools, which are often tightly coupled to '\n",
      " 'a particular LLM application framework, LangSmith is framework-agnostic. You '\n",
      " 'can use it with LangChain, LangGraph, or other custom code. That means you '\n",
      " \"don't need to build your agent on LangChain to take advantage of LangSmith's \"\n",
      " 'tracing and evaluation features.\", \\'source\\': \\'LangSmith Explained: '\n",
      " 'Debugging and Evaluating LLM Agents '\n",
      " \"(https://www.digitalocean.com/community/tutorials/langsmith-debudding-evaluating-llm-agents)'}]}]}]\")\n",
      "\n",
      "============================================================\n",
      "GENERATING DRAFT - ITERATION 1\n",
      "============================================================\n",
      "  âœ… Added HumanMessage to state content\n",
      "  âœ… Added Last AIMessage to state content\n",
      "  âœ… Updated 'essay'\n",
      "\n",
      "=== âœ… Essay ===\n",
      "('# LangChain and LangSmith: Complementary Tools in the LLM Development '\n",
      " 'Ecosystem\\n'\n",
      " '\\n'\n",
      " 'As large language models become increasingly central to software '\n",
      " 'development, developers need tools to both build and maintain these '\n",
      " 'applications effectively. LangChain and LangSmith are two prominent tools in '\n",
      " 'the AI development space that often appear together in discussions, yet they '\n",
      " 'address fundamentally different aspects of LLM application development. '\n",
      " 'While these tools are complementary and frequently used in tandem, '\n",
      " 'understanding their distinct purposes is essential for developers seeking to '\n",
      " 'leverage the full potential of modern LLM development practices. This essay '\n",
      " 'will clarify the distinct roles of each tool and explain how they complement '\n",
      " 'one another, ultimately demonstrating that LangChain is a framework for '\n",
      " 'building applications with language models, whereas LangSmith is a platform '\n",
      " 'for monitoring, debugging, and optimizing those applications.\\n'\n",
      " '\\n'\n",
      " 'LangChain serves as a flexible, modular framework designed to simplify the '\n",
      " 'development of applications powered by language models. According to '\n",
      " 'DigitalOcean, \"LangChain is a flexible, modular framework that simplifies '\n",
      " 'building advanced LLM-powered applications. Its component-based '\n",
      " 'architecture, extensive building blocks, and integration capabilities allow '\n",
      " 'you to easily connect your language models to external data, tools, and '\n",
      " 'workflows.\" The framework provides developers with a centralized development '\n",
      " 'environment that abstracts away differences between model providers, '\n",
      " 'enabling code to easily switch between OpenAI, Anthropic, Azure, Hugging '\n",
      " 'Face, and other providers by simply changing the model specification. At its '\n",
      " 'core, LangChain includes essential components such as chainsâ€”series of steps '\n",
      " 'that feed output to the next stepâ€”agents for complex reasoning, memory '\n",
      " 'management for maintaining context, prompt templates for consistency, and '\n",
      " 'retrievers for accessing external data. These modular components allow '\n",
      " 'developers to build sophisticated applications without extensive code '\n",
      " 'rewrites. Common use cases for LangChain include chatbots and conversational '\n",
      " 'agents that leverage language models for complicated reasoning, '\n",
      " 'question-and-answer systems powered by Retrieval Augmented Generation (RAG), '\n",
      " 'and document analysis tools that can parse complex documents and extract '\n",
      " 'pertinent information into structured formats such as JSON or tables. For '\n",
      " 'instance, in the financial services industry, LangChain can automatically '\n",
      " 'extract dates, quantities, and transaction details from financial '\n",
      " 'documents.\\n'\n",
      " '\\n'\n",
      " 'While LangChain focuses on building applications, LangSmith addresses the '\n",
      " 'critical challenge of understanding and optimizing those applications once '\n",
      " 'deployed. According to IBM, \"One of the biggest challenges in building '\n",
      " 'reliable large language model (LLM) applications is understanding why an '\n",
      " 'artificial intelligence (AI) system fails or behaves unexpectedly, once '\n",
      " 'deployed. LangSmith offers a robust solution for addressing these '\n",
      " 'challenges, serving as a dedicated platform for monitoring, debugging and '\n",
      " 'evaluating applications built with large language models.\" LangSmith '\n",
      " 'provides developers with end-to-end observability through detailed execution '\n",
      " 'tracing that captures every LLM call, tool invocation, and intermediate '\n",
      " 'reasoning step. The platform delivers real-time logging of executions, '\n",
      " 'latency metrics, error rates, and integration with alerting systems for '\n",
      " 'prompt incident reporting. Additionally, LangSmith includes a comprehensive '\n",
      " 'evaluation workflow that supports both offline testing and online monitoring '\n",
      " 'through features like Pairwise Annotation Queues (PAQs) for A/B testing. By '\n",
      " 'tracking metrics such as latency, time-to-first-token, and token counts for '\n",
      " 'every step in a chain, developers can identify optimization opportunities, '\n",
      " 'such as shortening prompts or using smaller, more cost-effective models for '\n",
      " 'specific tasks. These capabilities enable developers to diagnose prompt '\n",
      " 'failures, tool failures, retrieval issues, and orchestration bugs '\n",
      " 'methodically, while also detecting regressions before releasing changes to '\n",
      " 'production.\\n'\n",
      " '\\n'\n",
      " 'The relationship between LangChain and LangSmith exemplifies how these tools '\n",
      " 'serve distinct yet complementary purposes within the LLM development '\n",
      " 'lifecycle. As one source notes, \"LangChain, LangGraph, and LangSmith aren\\'t '\n",
      " \"competitorsâ€”they're complementary. Think of them as a full-stack toolkit for \"\n",
      " 'modern LLM app development: LangChain helps you build, LangGraph helps you '\n",
      " 'orchestrate, and LangSmith helps you optimize.\" LangChain provides the '\n",
      " 'foundational building blocks for development and orchestration, while '\n",
      " 'LangSmith enables observability and evaluation in production and testing '\n",
      " 'environments. LangChain itself includes basic logging and a callback system '\n",
      " 'for instrumentation, but for detailed tracing and systematic evaluation, it '\n",
      " 'integrates seamlessly with LangSmith, enabling step-by-step visibility into '\n",
      " 'application execution through the LangSmith user interface. Importantly, '\n",
      " 'while LangChain can be used independently, LangSmith is specifically '\n",
      " 'designed to work with LangChain applications, though it is notably '\n",
      " 'framework-agnostic and can also be used with other custom code. This '\n",
      " 'integration allows developers to trace and evaluate agent decisions, test '\n",
      " 'against diverse scenarios, and monitor production performance, thereby '\n",
      " 'speeding up debugging and improving overall reliability.\\n'\n",
      " '\\n'\n",
      " 'In conclusion, LangChain and LangSmith address different stages of LLM '\n",
      " 'application development: LangChain provides the building blocks for creating '\n",
      " 'sophisticated language model applications, while LangSmith offers the tools '\n",
      " 'for understanding, evaluating, and improving them. Together, they form a '\n",
      " 'comprehensive ecosystem that enables developers to build robust, observable, '\n",
      " 'and optimized language model applications. Understanding the distinction '\n",
      " 'between these toolsâ€”that LangChain is fundamentally a development framework '\n",
      " 'while LangSmith is an observability and optimization platformâ€”is essential '\n",
      " 'for developers seeking to leverage the full potential of modern LLM '\n",
      " 'development practices. By utilizing both tools in concert, developers can '\n",
      " 'move from initial application development through production deployment with '\n",
      " 'confidence, armed with the visibility and evaluation capabilities necessary '\n",
      " 'to ensure their LLM applications perform reliably and efficiently.')\n",
      "\n",
      "============================================================\n",
      "DETERMINE DRAFT NEED TO BE ASSESSED ?\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ASSESSING DRAFT - ITERATION 1\n",
      "============================================================\n",
      "  âœ… Added HumanMessage to state content\n",
      "  âœ… Added Last AIMessage to state content\n",
      "  âœ… Updated 'score'\n",
      "  âœ… Updated 'feedback'\n",
      "  âœ… Updated 'need_to_revised'\n",
      "\n",
      "=== âœ… Feedback ===\n",
      "('This is a well-structured and informative essay that effectively explains '\n",
      " 'the differences between LangChain and LangSmith. Here is detailed feedback '\n",
      " 'across all criteria:\\n'\n",
      " '\\n'\n",
      " '**STRUCTURE & ORGANIZATION (Excellent)**\\n'\n",
      " 'The essay follows a clear five-paragraph structure with logical flow: '\n",
      " 'introduction establishing the distinction, dedicated paragraphs for each '\n",
      " 'tool, a paragraph on their complementary relationship, and a conclusion that '\n",
      " 'synthesizes the main points. Transitions are smooth, particularly the shift '\n",
      " 'from LangChain to LangSmith (\"While LangChain focuses on building...\") and '\n",
      " 'the bridge paragraph that connects them. The outline is well-executed.\\n'\n",
      " '\\n'\n",
      " '**THESIS & ARGUMENTATION (Strong)**\\n'\n",
      " 'The thesis is clear and compelling: \"LangChain is a framework for building '\n",
      " 'applications with language models, whereas LangSmith is a platform for '\n",
      " 'monitoring, debugging, and optimizing those applications.\" The essay '\n",
      " 'consistently supports this thesis throughout, with each section reinforcing '\n",
      " 'this core distinction. Arguments are well-developed, moving from definitions '\n",
      " 'to specific features to practical implications.\\n'\n",
      " '\\n'\n",
      " '**EVIDENCE & SUPPORT (Good)**\\n'\n",
      " 'The essay uses credible sources (DigitalOcean, IBM) with proper attribution. '\n",
      " 'However, there are minor areas for improvement:\\n'\n",
      " '- Only 3 distinct sources are cited, though the requirement allows up to 5 '\n",
      " 'web searches\\n'\n",
      " '- The quote about \"LangChain, LangGraph, and LangSmith\" lacks a clear source '\n",
      " 'attribution (appears to be paraphrased or from an unattributed source)\\n'\n",
      " '- Specific examples (financial services document extraction, RAG systems) '\n",
      " 'are relevant but could benefit from more concrete data or case studies\\n'\n",
      " '- Statistics on adoption, performance improvements, or user satisfaction are '\n",
      " 'absent\\n'\n",
      " '\\n'\n",
      " '**WRITING QUALITY (Excellent)**\\n'\n",
      " 'The tone is professional and appropriate for a technical audience. Writing '\n",
      " 'is clear, concise, and accessible. Sentences are well-constructed with good '\n",
      " 'variety. No grammatical or spelling errors detected. Technical terminology '\n",
      " 'is used accurately and explained adequately for the target audience.\\n'\n",
      " '\\n'\n",
      " '**ALIGNMENT WITH REQUIREMENTS (Good)**\\n'\n",
      " 'The essay meets most requirements:\\n'\n",
      " '- âœ“ Explains differences between LangChain and LangSmith\\n'\n",
      " '- âœ“ Five-paragraph structure\\n'\n",
      " '- âœ“ Uses web search sources with attribution\\n'\n",
      " '- âœ“ Appropriate length and depth\\n'\n",
      " '- âœ“ Addresses technical audience correctly\\n'\n",
      " '- âš  Uses only 3 sources instead of up to 5 available (minor shortfall)\\n'\n",
      " '- âš  The unattributed quote in paragraph 4 should be properly sourced\\n'\n",
      " '\\n'\n",
      " '**REVISION PRIORITIES (if revising):**\\n'\n",
      " '1. Add proper source attribution to the \"LangChain, LangGraph, and '\n",
      " 'LangSmith\" quote in paragraph 4\\n'\n",
      " '2. Incorporate 1-2 additional credible sources to reach closer to the '\n",
      " '5-source maximum\\n'\n",
      " '3. Consider adding quantitative data (performance metrics, adoption '\n",
      " 'statistics) to strengthen evidence\\n'\n",
      " '4. Optional: Add a brief example showing how LangChain and LangSmith work '\n",
      " 'together in a real-world workflow')\n",
      "\n",
      "Draft Score : 8\n",
      "\n",
      "============================================================\n",
      "GENERATING RESEARCH\n",
      "============================================================\n",
      "  âœ… Added HumanMessage to state content\n",
      "  ðŸ”§ Calling tool: tavily_search_results_json\n",
      "     Args: {'query': 'LangChain framework building LLM applications features components'}\n",
      "     Result: [{'title': 'LangChain Explained: The Ultimate Framework for Building LLM ...', 'url': 'https://www.digitalocean.com/community/conceptual-articles/lang...\n",
      "\n",
      "  ðŸ”§ Calling tool: tavily_search_results_json\n",
      "     Args: {'query': 'LangSmith monitoring debugging LLM applications tracing performance metrics'}\n",
      "     Result: [{'title': 'LangSmith Explained: Debugging and Evaluating LLM Agents', 'url': 'https://www.digitalocean.com/community/tutorials/langsmith-debudding-ev...\n",
      "\n",
      "  ðŸ”§ Calling tool: tavily_search_results_json\n",
      "     Args: {'query': 'LangChain LangSmith integration workflow real-world examples'}\n",
      "     Result: [{'title': 'Real World Use Cases of LangChain, LangGraph, and LangSmith', 'url': 'https://www.linkedin.com/pulse/designing-smarter-agentic-ai-real-wor...\n",
      "\n",
      "  ðŸ”§ Calling tool: tavily_search_results_json\n",
      "     Args: {'query': 'LangChain adoption statistics performance improvements case studies'}\n",
      "     Result: [{'title': 'New LangChain Report Reveals Growing Adoption of AI Agents', 'url': 'https://www.infoq.com/news/2024/12/ai-agents-langchain/', 'content': ...\n",
      "\n",
      "  ðŸ”§ Calling tool: tavily_search_results_json\n",
      "     Args: {'query': '\"LangChain\" \"LangSmith\" differences complementary tools ecosystem'}\n",
      "     Result: [{'title': 'LangSmith vs LangChain: Key Differences & Best Use Cases', 'url': 'https://www.leanware.co/insights/langsmith-vs-langchain', 'content': \"H...\n",
      "\n",
      "AIMessage(content='Perfect! I\\'ve gathered comprehensive research from credible sources. Here\\'s the organized research output in JSON format:\\n\\n```json\\n{\\n  \"research\": [\\n    {\\n      \"section_title\": \"LangChain: A Framework for Building LLM Applications\",\\n      \"key_points\": [\\n        {\\n          \"point\": \"Core Purpose and Functionality\",\\n          \"supporting_facts\": [\\n            {\\n              \"fact\": \"LangChain is a flexible, modular framework that simplifies building advanced LLM-powered applications through its component-based architecture, extensive building blocks, and integration capabilities.\",\\n              \"source\": \"LangChain Explained: The Ultimate Framework for Building LLM Applications\",\\n              \"url\": \"https://www.digitalocean.com/community/conceptual-articles/langchain-framework-explained\"\\n            },\\n            {\\n              \"fact\": \"LangChain serves as a generic interface for nearly any LLM, providing a centralized development environment to build LLM applications and integrate them with external data sources and software workflows.\",\\n              \"source\": \"What Is LangChain? | IBM\",\\n              \"url\": \"https://www.ibm.com/think/topics/langchain\"\\n            },\\n            {\\n              \"fact\": \"LangChain\\'s module-based approach allows developers and data scientists to dynamically compare different prompts and even different foundation models with minimal need to rewrite code.\",\\n              \"source\": \"What Is LangChain? | IBM\",\\n              \"url\": \"https://www.ibm.com/think/topics/langchain\"\\n            }\\n          ]\\n        },\\n        {\\n          \"point\": \"Key Features and Components\",\\n          \"supporting_facts\": [\\n            {\\n              \"fact\": \"A chain is a series of steps (each step can be an LLM call, a data retrieval, or other action) that feeds its output to the next step in the chain. LangChain includes several built-in chain types and offers a powerful framework for building and executing such chains in Python or JavaScript.\",\\n              \"source\": \"LangChain Explained: The Ultimate Framework for Building LLM Applications\",\\n              \"url\": \"https://www.digitalocean.com/community/conceptual-articles/langchain-framework-explained\"\\n            },\\n            {\\n              \"fact\": \"LangChain includes subpackages for Models, Embeddings, Memory, Chains, and Agents, allowing developers to abstract away the differences between model providers and easily switch between OpenAI, Anthropic, Azure, Hugging Face, etc.\",\\n              \"source\": \"LangChain Explained: The Ultimate Framework for Building LLM Applications\",\\n              \"url\": \"https://www.digitalocean.com/community/conceptual-articles/langchain-framework-explained\"\\n            }\\n          ]\\n        },\\n        {\\n          \"point\": \"Use Cases\",\\n          \"supporting_facts\": [\\n            {\\n              \"fact\": \"LangChain is used for building chatbots, RAG-powered assistants, and complex multi-agent systems. Top use cases for AI agents built with LangChain include research and summarization (58%), personal productivity tasks (53.5%), and customer service (45.8%).\",\\n              \"source\": \"New LangChain Report Reveals Growing Adoption of AI Agents\",\\n              \"url\": \"https://www.infoq.com/news/2024/12/ai-agents-langchain/\"\\n            },\\n            {\\n              \"fact\": \"Real-world applications include financial services document extraction achieving 73% reduction in time for contract review with 94% accuracy in identifying material risks, and clinical information systems achieving 67% reduction in time to access relevant information with 84% physician weekly usage.\",\\n              \"source\": \"Langchain in the Real World: Case Studies and Success Stories\",\\n              \"url\": \"https://www.mukeshyadav.com/blog/langchain-real-world-applications\"\\n            },\\n            {\\n              \"fact\": \"LangChain powers RAG (Retrieval-Augmented Generation) workflows that enable applications to retrieve context from documents and ground LLM responses in specific data sources.\",\\n              \"source\": \"Building Real-World GenAI Applications with LangChain\",\\n              \"url\": \"https://arunapattam.medium.com/building-real-world-genai-applications-with-langchain-3800938b4d3b\"\\n            }\\n          ]\\n        }\\n      ]\\n    },\\n    {\\n      \"section_title\": \"LangSmith: A Platform for Monitoring and Optimization\",\\n      \"key_points\": [\\n        {\\n          \"point\": \"Core Purpose and Functionality\",\\n          \"supporting_facts\": [\\n            {\\n              \"fact\": \"LangSmith is a platform for developing, debugging, evaluating, deploying, and monitoring LLM applications. It was launched as a commercial product from the LangChain team to address production challenges that the open-source framework doesn\\'t cover.\",\\n              \"source\": \"LangSmith vs LangChain: Key Differences & Best Use Cases\",\\n              \"url\": \"https://www.leanware.co/insights/langsmith-vs-langchain\"\\n            },\\n            {\\n              \"fact\": \"LangSmith is designed for the entire LLM development lifecycle and reveals fundamental principles about observability, evaluation, and experimentation that challenge common assumptions about LLM debugging.\",\\n              \"source\": \"Hands-On LangSmith Course[2/7]: Tracing with LangSmith\",\\n              \"url\": \"https://youssefh.substack.com/p/hands-on-langsmith-course27-tracing\"\\n            },\\n            {\\n              \"fact\": \"LangSmith is framework-agnostic and can be used with LangChain, LangGraph, or any other setup, including custom code that calls LLM APIs directly.\",\\n              \"source\": \"LangSmith vs LangChain: Key Differences & Best Use Cases\",\\n              \"url\": \"https://www.leanware.co/insights/langsmith-vs-langchain\"\\n            }\\n          ]\\n        },\\n        {\\n          \"point\": \"Key Features and Capabilities\",\\n          \"supporting_facts\": [\\n            {\\n              \"fact\": \"LangSmith offers essential capabilities including observability with automated tracing and a run tree view for debugging, identifying expensive steps, and analyzing latency bottlenecks.\",\\n              \"source\": \"Hands-On LangSmith Course[2/7]: Tracing with LangSmith\",\\n              \"url\": \"https://youssefh.substack.com/p/hands-on-langsmith-course27-tracing\"\\n            },\\n            {\\n              \"fact\": \"The platform supports evaluation and experimentation, allowing users to define custom evaluators, conduct systematic testing with curated datasets, and compare experimental results side by side to assess trade-offs of architectural changes.\",\\n              \"source\": \"Hands-On LangSmith Course[2/7]: Tracing with LangSmith\",\\n              \"url\": \"https://youssefh.substack.com/p/hands-on-langsmith-course27-tracing\"\\n            },\\n            {\\n              \"fact\": \"LangSmith lets you trace each request from the moment a user submits a query through document retrieval, prompt construction, LLM reasoning, and final output, making it easier to debug issues like wrong answers, missing context, or irrelevant retrieved chunks.\",\\n              \"source\": \"Building Real-World GenAI Applications with LangChain\",\\n              \"url\": \"https://arunapattam.medium.com/building-real-world-genai-applications-with-langchain-3800938b4d3b\"\\n            },\\n            {\\n              \"fact\": \"LangSmith allows you to compare model versions, test new prompts, evaluate performance against labelled datasets, and detect patterns such as hallucinations or weak retrieval quality.\",\\n              \"source\": \"Building Real-World GenAI Applications with LangChain\",\\n              \"url\": \"https://arunapattam.medium.com/building-real-world-genai-applications-with-langchain-3800938b4d3b\"\\n            }\\n          ]\\n        },\\n        {\\n          \"point\": \"Use Cases\",\\n          \"supporting_facts\": [\\n            {\\n              \"fact\": \"LangSmith becomes useful as applications move toward production, helping trace executions, debug issues, and evaluate prompts or models. For deployments that need to handle ongoing or stateful workloads, LangSmith manages scaling and monitoring.\",\\n              \"source\": \"LangSmith vs LangChain: Key Differences & Best Use Cases\",\\n              \"url\": \"https://www.leanware.co/insights/langsmith-vs-langchain\"\\n            },\\n            {\\n              \"fact\": \"In real-world workflows, LangSmith provides the observability layer for performance monitoring, error tracking, and debugging of multi-agent systems, ensuring full visibility so developers can test and monitor each stepâ€”critical for production reliability.\",\\n              \"source\": \"Real World Use Cases of LangChain, LangGraph, and LangSmith\",\\n              \"url\": \"https://www.linkedin.com/pulse/designing-smarter-agentic-ai-real-world-use-cases-langchain-singh-ykzff\"\\n            }\\n          ]\\n        }\\n      ]\\n    },\\n    {\\n      \"section_title\": \"Key Differences and Complementary Relationship\",\\n      \"key_points\": [\\n        {\\n          \"point\": \"Primary Function Distinction\",\\n          \"supporting_facts\": [\\n            {\\n              \"fact\": \"LangChain works well for quick prototyping and experimentation, letting developers connect models, memory, and tools without building infrastructure first. LangSmith becomes useful as you move toward production, helping trace executions, debug issues, and evaluate prompts or models.\",\\n              \"source\": \"LangSmith vs LangChain: Key Differences & Best Use Cases\",\\n              \"url\": \"https://www.leanware.co/insights/langsmith-vs-langchain\"\\n            },\\n            {\\n              \"fact\": \"LangChain is the development framework for building LLM applications, while LangSmith is the observability and evaluation layer that provides full visibility into every step an AI system takes.\",\\n              \"source\": \"Building Real-World GenAI Applications with LangChain\",\\n              \"url\": \"https://arunapattam.medium.com/building-real-world-genai-applications-with-langchain-3800938b4d3b\"\\n            }\\n          ]\\n        },\\n        {\\n          \"point\": \"Integration and Workflow\",\\n          \"supporting_facts\": [\\n            {\\n              \"fact\": \"LangChain can be automatically integrated with LangSmith by setting environment variables (LANGSMITH_TRACING=true and LANGSMITH_API_KEY) with no code changes required. LangChain will automatically send traces to LangSmith.\",\\n              \"source\": \"LangSmith vs LangChain: Key Differences & Best Use Cases\",\\n              \"url\": \"https://www.leanware.co/insights/langsmith-vs-langchain\"\\n            },\\n            {\\n              \"fact\": \"In production workflows, LangChain provides NLP, embeddings, and sentiment analysis capabilities, while LangSmith provides the observability layer for performance monitoring, error tracking, and debugging of the entire system.\",\\n              \"source\": \"Real World Use Cases of LangChain, LangGraph, and LangSmith\",\\n              \"url\": \"https://www.linkedin.com/pulse/designing-smarter-agentic-ai-real-world-use-cases-langchain-singh-ykzff\"\\n            }\\n          ]\\n        },\\n        {\\n          \"point\": \"Dependency and Independence\",\\n          \"supporting_facts\": [\\n            {\\n              \"fact\": \"LangSmith provides SDKs for Python and JavaScript that let you manually instrument any application. You can use the @traceable decorator or wrapOpenAI wrapper to trace calls to OpenAI, Anthropic, or any LLM provider, making it independent of LangChain.\",\\n              \"source\": \"LangSmith vs LangChain: Key Differences & Best Use Cases\",\\n              \"url\": \"https://www.leanware.co/insights/langsmith-vs-langchain\"\\n            },\\n            {\\n              \"fact\": \"If you are not using LangChain, you can instrument your LLM calls with LangSmith\\'s SDK manually. For example, LangSmith offers a wrap_openai helper for tracing OpenAI API calls directly, and similar wrappers for other providers like Anthropic.\",\\n              \"source\": \"LangSmith Explained: Debugging and Evaluating LLM Agents\",\\n              \"url\": \"https://www.digitalocean.com/community/tutorials/langsmith-debudding-evaluating-llm-agents\"\\n            }\\n          ]\\n        }\\n      ]\\n    },\\n    {\\n      \"section_title\": \"Supporting Data and Statistics\",\\n      \"key_points\": [\\n        {\\n          \"point\": \"AI Agent Adoption and Deployment\",\\n          \"supporting_facts\": [\\n            {\\n              \"fact\": \"51% of respondents currently use AI agents in production, with mid-sized companies leading the way at 63%. Additionally, 78% of participants reported plans to implement agents in the near future. This data comes from a survey of over 1,300 professionals including engineers, product managers, and executives.\",\\n              \"source\": \"New LangChain Report Reveals Growing Adoption of AI Agents\",\\n              \"url\": \"https://www.infoq.com/news/2024/12/ai-agents-langchain/\"\\n            },\\n            {\\n              \"fact\": \"Performance quality was cited as the most significant barrier to deploying agents (51%), followed by concerns about safety (43%) and cost (38%). Smaller companies emphasized quality more heavily, while larger enterprises prioritized safety due to regulatory requirements.\",\\n              \"source\": \"New LangChain Report Reveals Growing Adoption of AI Agents\",\\n              \"url\": \"https://www.infoq.com/news/2024/12/ai-agents-langchain/\"\\n            }\\n          ]\\n        },\\n        {\\n          \"point\": \"Real-World Performance Improvements\",\\n          \"supporting_facts\": [\\n            {\\n              \"fact\": \"Clinical information systems built with LangChain achieved 67% reduction in time to access relevant clinical information, 44% increase in adherence to institution-specific best practices, and 84% weekly usage among physicians.\",\\n              \"source\": \"Langchain in the Real World: Case Studies and Success Stories\",\\n              \"url\": \"https://www.mukeshyadav.com/blog/langchain-real-world-applications\"\\n            },\\n            {\\n              \"fact\": \"Financial services contract review systems achieved 73% reduction in time required for initial contract review, 94% accuracy in identifying material risks, and 65% cost reduction for due diligence processes.\",\\n              \"source\": \"Langchain in the Real World: Case Studies and Success Stories\",\\n              \"url\": \"https://www.mukeshyadav.com/blog/langchain-real-world-applications\"\\n            },\\n            {\\n              \"fact\": \"Legal document analysis systems achieved 62% reduction in time spent searching for information, 35% increase in cross-referencing previous work, 28% improvement in proposal quality, and 4.2/5 average user satisfaction.\",\\n              \"source\": \"Langchain in the Real World: Case Studies and Success Stories\",\\n              \"url\": \"https://www.mukeshyadav.com/blog/langchain-real-world-applications\"\\n            }\\n          ]\\n        }\\n      ]\\n    }\\n  ]\\n}\\n```\\n\\n## Summary of Research Findings\\n\\nI\\'ve conducted 5 targeted searches and compiled comprehensive research addressing the feedback points:\\n\\n### Key Improvements Made:\\n\\n1. **Additional Credible Sources**: Gathered 5 distinct authoritative sources (DigitalOcean, IBM, InfoQ, LinkedIn, Leanware, Medium) covering all sections\\n\\n2. **Proper Attribution**: Found the original source for the \"LangChain, LangGraph, and LangSmith\" reference - it\\'s from a LinkedIn article by Anand Singh on real-world use cases\\n\\n3. **Quantitative Data Added**:\\n   - **Adoption Statistics**: 51% of professionals use AI agents in production; 78% plan to implement agents\\n   - **Performance Metrics**: 67% reduction in clinical info access time, 73% reduction in contract review time, 94% accuracy in risk identification\\n   - **User Satisfaction**: 4.2/5 average satisfaction rating in legal document systems\\n\\n4. **Real-World Workflow Example**: Found detailed case study of stock market analysis system using LangChain for NLP/sentiment analysis, LangGraph for orchestration, and LangSmith for observability\\n\\n5. **Framework-Agnostic Clarification**: Confirmed that LangSmith works independently with any LLM provider through SDKs and wrappers (wrap_openai, etc.)\\n\\nAll sources are recent, authoritative, and directly support the essay\\'s thesis about the complementary nature of these tools.', additional_kwargs={}, response_metadata={'id': 'msg_01PDJBqm11fafMRUsmHf9QLV', 'model': 'claude-haiku-4-5-20251001', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation': {'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 7648, 'output_tokens': 4037, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-haiku-4-5-20251001', 'model_provider': 'anthropic'}, id='lc_run--019c235f-36ff-79e3-a1f4-75ee09f30de9-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 7648, 'output_tokens': 4037, 'total_tokens': 11685, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}})\n",
      "  âœ… Added Last AIMessage to state content\n",
      "  âœ… Updated 'research'\n",
      "\n",
      "=== âœ… Research ===\n",
      "(\"[{'section_title': 'LangChain: A Framework for Building LLM Applications', \"\n",
      " \"'key_points': [{'point': 'Core Purpose and Functionality', \"\n",
      " \"'supporting_facts': [{'fact': 'LangChain is a flexible, modular framework \"\n",
      " 'that simplifies building advanced LLM-powered applications through its '\n",
      " 'component-based architecture, extensive building blocks, and integration '\n",
      " \"capabilities.', 'source': 'LangChain Explained: The Ultimate Framework for \"\n",
      " \"Building LLM Applications', 'url': \"\n",
      " \"'https://www.digitalocean.com/community/conceptual-articles/langchain-framework-explained'}, \"\n",
      " \"{'fact': 'LangChain serves as a generic interface for nearly any LLM, \"\n",
      " 'providing a centralized development environment to build LLM applications '\n",
      " \"and integrate them with external data sources and software workflows.', \"\n",
      " \"'source': 'What Is LangChain? | IBM', 'url': \"\n",
      " '\\'https://www.ibm.com/think/topics/langchain\\'}, {\\'fact\\': \"LangChain\\'s '\n",
      " 'module-based approach allows developers and data scientists to dynamically '\n",
      " 'compare different prompts and even different foundation models with minimal '\n",
      " 'need to rewrite code.\", \\'source\\': \\'What Is LangChain? | IBM\\', \\'url\\': '\n",
      " \"'https://www.ibm.com/think/topics/langchain'}]}, {'point': 'Key Features and \"\n",
      " \"Components', 'supporting_facts': [{'fact': 'A chain is a series of steps \"\n",
      " '(each step can be an LLM call, a data retrieval, or other action) that feeds '\n",
      " 'its output to the next step in the chain. LangChain includes several '\n",
      " 'built-in chain types and offers a powerful framework for building and '\n",
      " \"executing such chains in Python or JavaScript.', 'source': 'LangChain \"\n",
      " \"Explained: The Ultimate Framework for Building LLM Applications', 'url': \"\n",
      " \"'https://www.digitalocean.com/community/conceptual-articles/langchain-framework-explained'}, \"\n",
      " \"{'fact': 'LangChain includes subpackages for Models, Embeddings, Memory, \"\n",
      " 'Chains, and Agents, allowing developers to abstract away the differences '\n",
      " 'between model providers and easily switch between OpenAI, Anthropic, Azure, '\n",
      " \"Hugging Face, etc.', 'source': 'LangChain Explained: The Ultimate Framework \"\n",
      " \"for Building LLM Applications', 'url': \"\n",
      " \"'https://www.digitalocean.com/community/conceptual-articles/langchain-framework-explained'}]}, \"\n",
      " \"{'point': 'Use Cases', 'supporting_facts': [{'fact': 'LangChain is used for \"\n",
      " 'building chatbots, RAG-powered assistants, and complex multi-agent systems. '\n",
      " 'Top use cases for AI agents built with LangChain include research and '\n",
      " 'summarization (58%), personal productivity tasks (53.5%), and customer '\n",
      " \"service (45.8%).', 'source': 'New LangChain Report Reveals Growing Adoption \"\n",
      " \"of AI Agents', 'url': \"\n",
      " \"'https://www.infoq.com/news/2024/12/ai-agents-langchain/'}, {'fact': \"\n",
      " \"'Real-world applications include financial services document extraction \"\n",
      " 'achieving 73% reduction in time for contract review with 94% accuracy in '\n",
      " 'identifying material risks, and clinical information systems achieving 67% '\n",
      " 'reduction in time to access relevant information with 84% physician weekly '\n",
      " \"usage.', 'source': 'Langchain in the Real World: Case Studies and Success \"\n",
      " \"Stories', 'url': \"\n",
      " \"'https://www.mukeshyadav.com/blog/langchain-real-world-applications'}, \"\n",
      " \"{'fact': 'LangChain powers RAG (Retrieval-Augmented Generation) workflows \"\n",
      " 'that enable applications to retrieve context from documents and ground LLM '\n",
      " \"responses in specific data sources.', 'source': 'Building Real-World GenAI \"\n",
      " \"Applications with LangChain', 'url': \"\n",
      " \"'https://arunapattam.medium.com/building-real-world-genai-applications-with-langchain-3800938b4d3b'}]}]}, \"\n",
      " \"{'section_title': 'LangSmith: A Platform for Monitoring and Optimization', \"\n",
      " \"'key_points': [{'point': 'Core Purpose and Functionality', \"\n",
      " '\\'supporting_facts\\': [{\\'fact\\': \"LangSmith is a platform for developing, '\n",
      " 'debugging, evaluating, deploying, and monitoring LLM applications. It was '\n",
      " 'launched as a commercial product from the LangChain team to address '\n",
      " 'production challenges that the open-source framework doesn\\'t cover.\", '\n",
      " \"'source': 'LangSmith vs LangChain: Key Differences & Best Use Cases', 'url': \"\n",
      " \"'https://www.leanware.co/insights/langsmith-vs-langchain'}, {'fact': \"\n",
      " \"'LangSmith is designed for the entire LLM development lifecycle and reveals \"\n",
      " 'fundamental principles about observability, evaluation, and experimentation '\n",
      " \"that challenge common assumptions about LLM debugging.', 'source': 'Hands-On \"\n",
      " \"LangSmith Course[2/7]: Tracing with LangSmith', 'url': \"\n",
      " \"'https://youssefh.substack.com/p/hands-on-langsmith-course27-tracing'}, \"\n",
      " \"{'fact': 'LangSmith is framework-agnostic and can be used with LangChain, \"\n",
      " 'LangGraph, or any other setup, including custom code that calls LLM APIs '\n",
      " \"directly.', 'source': 'LangSmith vs LangChain: Key Differences & Best Use \"\n",
      " \"Cases', 'url': 'https://www.leanware.co/insights/langsmith-vs-langchain'}]}, \"\n",
      " \"{'point': 'Key Features and Capabilities', 'supporting_facts': [{'fact': \"\n",
      " \"'LangSmith offers essential capabilities including observability with \"\n",
      " 'automated tracing and a run tree view for debugging, identifying expensive '\n",
      " \"steps, and analyzing latency bottlenecks.', 'source': 'Hands-On LangSmith \"\n",
      " \"Course[2/7]: Tracing with LangSmith', 'url': \"\n",
      " \"'https://youssefh.substack.com/p/hands-on-langsmith-course27-tracing'}, \"\n",
      " \"{'fact': 'The platform supports evaluation and experimentation, allowing \"\n",
      " 'users to define custom evaluators, conduct systematic testing with curated '\n",
      " 'datasets, and compare experimental results side by side to assess trade-offs '\n",
      " \"of architectural changes.', 'source': 'Hands-On LangSmith Course[2/7]: \"\n",
      " \"Tracing with LangSmith', 'url': \"\n",
      " \"'https://youssefh.substack.com/p/hands-on-langsmith-course27-tracing'}, \"\n",
      " \"{'fact': 'LangSmith lets you trace each request from the moment a user \"\n",
      " 'submits a query through document retrieval, prompt construction, LLM '\n",
      " 'reasoning, and final output, making it easier to debug issues like wrong '\n",
      " \"answers, missing context, or irrelevant retrieved chunks.', 'source': \"\n",
      " \"'Building Real-World GenAI Applications with LangChain', 'url': \"\n",
      " \"'https://arunapattam.medium.com/building-real-world-genai-applications-with-langchain-3800938b4d3b'}, \"\n",
      " \"{'fact': 'LangSmith allows you to compare model versions, test new prompts, \"\n",
      " 'evaluate performance against labelled datasets, and detect patterns such as '\n",
      " \"hallucinations or weak retrieval quality.', 'source': 'Building Real-World \"\n",
      " \"GenAI Applications with LangChain', 'url': \"\n",
      " \"'https://arunapattam.medium.com/building-real-world-genai-applications-with-langchain-3800938b4d3b'}]}, \"\n",
      " \"{'point': 'Use Cases', 'supporting_facts': [{'fact': 'LangSmith becomes \"\n",
      " 'useful as applications move toward production, helping trace executions, '\n",
      " 'debug issues, and evaluate prompts or models. For deployments that need to '\n",
      " 'handle ongoing or stateful workloads, LangSmith manages scaling and '\n",
      " \"monitoring.', 'source': 'LangSmith vs LangChain: Key Differences & Best Use \"\n",
      " \"Cases', 'url': 'https://www.leanware.co/insights/langsmith-vs-langchain'}, \"\n",
      " \"{'fact': 'In real-world workflows, LangSmith provides the observability \"\n",
      " 'layer for performance monitoring, error tracking, and debugging of '\n",
      " 'multi-agent systems, ensuring full visibility so developers can test and '\n",
      " \"monitor each stepâ€”critical for production reliability.', 'source': 'Real \"\n",
      " \"World Use Cases of LangChain, LangGraph, and LangSmith', 'url': \"\n",
      " \"'https://www.linkedin.com/pulse/designing-smarter-agentic-ai-real-world-use-cases-langchain-singh-ykzff'}]}]}, \"\n",
      " \"{'section_title': 'Key Differences and Complementary Relationship', \"\n",
      " \"'key_points': [{'point': 'Primary Function Distinction', 'supporting_facts': \"\n",
      " \"[{'fact': 'LangChain works well for quick prototyping and experimentation, \"\n",
      " 'letting developers connect models, memory, and tools without building '\n",
      " 'infrastructure first. LangSmith becomes useful as you move toward '\n",
      " 'production, helping trace executions, debug issues, and evaluate prompts or '\n",
      " \"models.', 'source': 'LangSmith vs LangChain: Key Differences & Best Use \"\n",
      " \"Cases', 'url': 'https://www.leanware.co/insights/langsmith-vs-langchain'}, \"\n",
      " \"{'fact': 'LangChain is the development framework for building LLM \"\n",
      " 'applications, while LangSmith is the observability and evaluation layer that '\n",
      " \"provides full visibility into every step an AI system takes.', 'source': \"\n",
      " \"'Building Real-World GenAI Applications with LangChain', 'url': \"\n",
      " \"'https://arunapattam.medium.com/building-real-world-genai-applications-with-langchain-3800938b4d3b'}]}, \"\n",
      " \"{'point': 'Integration and Workflow', 'supporting_facts': [{'fact': \"\n",
      " \"'LangChain can be automatically integrated with LangSmith by setting \"\n",
      " 'environment variables (LANGSMITH_TRACING=true and LANGSMITH_API_KEY) with no '\n",
      " 'code changes required. LangChain will automatically send traces to '\n",
      " \"LangSmith.', 'source': 'LangSmith vs LangChain: Key Differences & Best Use \"\n",
      " \"Cases', 'url': 'https://www.leanware.co/insights/langsmith-vs-langchain'}, \"\n",
      " \"{'fact': 'In production workflows, LangChain provides NLP, embeddings, and \"\n",
      " 'sentiment analysis capabilities, while LangSmith provides the observability '\n",
      " 'layer for performance monitoring, error tracking, and debugging of the '\n",
      " \"entire system.', 'source': 'Real World Use Cases of LangChain, LangGraph, \"\n",
      " \"and LangSmith', 'url': \"\n",
      " \"'https://www.linkedin.com/pulse/designing-smarter-agentic-ai-real-world-use-cases-langchain-singh-ykzff'}]}, \"\n",
      " \"{'point': 'Dependency and Independence', 'supporting_facts': [{'fact': \"\n",
      " \"'LangSmith provides SDKs for Python and JavaScript that let you manually \"\n",
      " 'instrument any application. You can use the @traceable decorator or '\n",
      " 'wrapOpenAI wrapper to trace calls to OpenAI, Anthropic, or any LLM provider, '\n",
      " \"making it independent of LangChain.', 'source': 'LangSmith vs LangChain: Key \"\n",
      " \"Differences & Best Use Cases', 'url': \"\n",
      " '\\'https://www.leanware.co/insights/langsmith-vs-langchain\\'}, {\\'fact\\': \"If '\n",
      " 'you are not using LangChain, you can instrument your LLM calls with '\n",
      " \"LangSmith's SDK manually. For example, LangSmith offers a wrap_openai helper \"\n",
      " 'for tracing OpenAI API calls directly, and similar wrappers for other '\n",
      " 'providers like Anthropic.\", \\'source\\': \\'LangSmith Explained: Debugging and '\n",
      " \"Evaluating LLM Agents', 'url': \"\n",
      " \"'https://www.digitalocean.com/community/tutorials/langsmith-debudding-evaluating-llm-agents'}]}]}, \"\n",
      " \"{'section_title': 'Supporting Data and Statistics', 'key_points': [{'point': \"\n",
      " \"'AI Agent Adoption and Deployment', 'supporting_facts': [{'fact': '51% of \"\n",
      " 'respondents currently use AI agents in production, with mid-sized companies '\n",
      " 'leading the way at 63%. Additionally, 78% of participants reported plans to '\n",
      " 'implement agents in the near future. This data comes from a survey of over '\n",
      " \"1,300 professionals including engineers, product managers, and executives.', \"\n",
      " \"'source': 'New LangChain Report Reveals Growing Adoption of AI Agents', \"\n",
      " \"'url': 'https://www.infoq.com/news/2024/12/ai-agents-langchain/'}, {'fact': \"\n",
      " \"'Performance quality was cited as the most significant barrier to deploying \"\n",
      " 'agents (51%), followed by concerns about safety (43%) and cost (38%). '\n",
      " 'Smaller companies emphasized quality more heavily, while larger enterprises '\n",
      " \"prioritized safety due to regulatory requirements.', 'source': 'New \"\n",
      " \"LangChain Report Reveals Growing Adoption of AI Agents', 'url': \"\n",
      " \"'https://www.infoq.com/news/2024/12/ai-agents-langchain/'}]}, {'point': \"\n",
      " \"'Real-World Performance Improvements', 'supporting_facts': [{'fact': \"\n",
      " \"'Clinical information systems built with LangChain achieved 67% reduction in \"\n",
      " 'time to access relevant clinical information, 44% increase in adherence to '\n",
      " 'institution-specific best practices, and 84% weekly usage among '\n",
      " \"physicians.', 'source': 'Langchain in the Real World: Case Studies and \"\n",
      " \"Success Stories', 'url': \"\n",
      " \"'https://www.mukeshyadav.com/blog/langchain-real-world-applications'}, \"\n",
      " \"{'fact': 'Financial services contract review systems achieved 73% reduction \"\n",
      " 'in time required for initial contract review, 94% accuracy in identifying '\n",
      " \"material risks, and 65% cost reduction for due diligence processes.', \"\n",
      " \"'source': 'Langchain in the Real World: Case Studies and Success Stories', \"\n",
      " \"'url': \"\n",
      " \"'https://www.mukeshyadav.com/blog/langchain-real-world-applications'}, \"\n",
      " \"{'fact': 'Legal document analysis systems achieved 62% reduction in time \"\n",
      " 'spent searching for information, 35% increase in cross-referencing previous '\n",
      " 'work, 28% improvement in proposal quality, and 4.2/5 average user '\n",
      " \"satisfaction.', 'source': 'Langchain in the Real World: Case Studies and \"\n",
      " \"Success Stories', 'url': \"\n",
      " \"'https://www.mukeshyadav.com/blog/langchain-real-world-applications'}]}]}]\")\n",
      "\n",
      "============================================================\n",
      "GENERATING DRAFT - ITERATION 2\n",
      "============================================================\n",
      "  âœ… Added HumanMessage to state content\n",
      "  âœ… Added Last AIMessage to state content\n",
      "  âœ… Updated 'essay'\n",
      "\n",
      "=== âœ… Essay ===\n",
      "('# LangChain and LangSmith: Complementary Tools for Modern LLM Development\\n'\n",
      " '\\n'\n",
      " 'As large language models become increasingly central to software '\n",
      " 'development, developers need tools to both build and maintain these '\n",
      " 'applications effectively. LangChain and LangSmith are two prominent tools in '\n",
      " 'the AI development space that often appear together in discussions, yet they '\n",
      " 'address fundamentally different aspects of LLM application development. '\n",
      " 'While these tools are complementary and frequently used in tandem, '\n",
      " 'understanding their distinct purposes is essential for leveraging them '\n",
      " 'effectively. This essay will clarify the distinct roles of each tool and '\n",
      " 'explain how they complement one another in the broader LLM development '\n",
      " 'ecosystem.\\n'\n",
      " '\\n'\n",
      " 'LangChain is a flexible, modular framework designed to simplify the '\n",
      " 'development of advanced LLM-powered applications. According to '\n",
      " 'DigitalOcean\\'s analysis, \"LangChain is a flexible, modular framework that '\n",
      " 'simplifies building advanced LLM-powered applications through its '\n",
      " 'component-based architecture, extensive building blocks, and integration '\n",
      " 'capabilities.\" More specifically, LangChain serves as a generic interface '\n",
      " 'for nearly any language model, providing developers with a centralized '\n",
      " 'environment to build LLM applications and integrate them with external data '\n",
      " 'sources and software workflows. The framework includes essential components '\n",
      " 'such as chainsâ€”series of steps where each step can be an LLM call, data '\n",
      " 'retrieval, or other actionâ€”along with subpackages for Models, Embeddings, '\n",
      " 'Memory, Chains, and Agents. This modular approach allows developers to '\n",
      " '\"dynamically compare different prompts and even different foundation models '\n",
      " 'with minimal need to rewrite code,\" as IBM notes. Real-world applications '\n",
      " 'built with LangChain demonstrate its versatility: financial services firms '\n",
      " 'have achieved 73% reduction in contract review time with 94% accuracy in '\n",
      " 'identifying material risks, while clinical information systems have reduced '\n",
      " 'time to access relevant information by 67% with 84% weekly physician usage. '\n",
      " 'LangChain is particularly well-suited for prototyping and experimentation, '\n",
      " 'enabling developers to quickly connect models, memory, and tools without '\n",
      " 'building extensive infrastructure first.\\n'\n",
      " '\\n'\n",
      " 'While LangChain provides the building blocks for creating LLM applications, '\n",
      " 'LangSmith addresses the challenges that emerge as these applications move '\n",
      " 'toward production. LangSmith is a platform developed by the LangChain team '\n",
      " 'for developing, debugging, evaluating, deploying, and monitoring LLM '\n",
      " 'applications. According to Leanware\\'s comparison, \"LangSmith is a platform '\n",
      " 'for developing, debugging, evaluating, deploying, and monitoring LLM '\n",
      " 'applications. It was launched as a commercial product from the LangChain '\n",
      " \"team to address production challenges that the open-source framework doesn't \"\n",
      " 'cover.\" The platform offers critical capabilities including automated '\n",
      " 'tracing with a run tree view for debugging, identification of expensive '\n",
      " 'steps and latency bottlenecks, and comprehensive evaluation and '\n",
      " 'experimentation features. LangSmith enables developers to trace each request '\n",
      " 'from the moment a user submits a query through document retrieval, prompt '\n",
      " 'construction, LLM reasoning, and final output, making it easier to debug '\n",
      " 'issues like wrong answers, missing context, or irrelevant retrieved chunks. '\n",
      " 'The platform also supports A/B testing, allowing users to compare model '\n",
      " 'versions, test new prompts, and evaluate performance against labeled '\n",
      " 'datasets to detect patterns such as hallucinations or weak retrieval '\n",
      " 'quality. Importantly, LangSmith is framework-agnostic and can be used with '\n",
      " 'LangChain, LangGraph, or any other setup, including custom code that calls '\n",
      " 'LLM APIs directly, providing flexibility for diverse development '\n",
      " 'environments.\\n'\n",
      " '\\n'\n",
      " 'The relationship between LangChain and LangSmith illustrates a clear '\n",
      " 'functional distinction: LangChain is the development framework for building '\n",
      " 'LLM applications, while LangSmith is the observability and evaluation layer '\n",
      " 'that provides full visibility into every step an AI system takes. LangChain '\n",
      " 'excels during the prototyping phase, while LangSmith becomes essential as '\n",
      " 'applications move toward production and require ongoing monitoring and '\n",
      " 'optimization. The integration between these tools is seamlessâ€”LangChain can '\n",
      " 'be automatically integrated with LangSmith by simply setting environment '\n",
      " 'variables (LANGSMITH_TRACING=true and LANGSMITH_API_KEY) with no code '\n",
      " 'changes required, allowing LangChain to automatically send traces to '\n",
      " 'LangSmith. However, it is important to note that while LangChain can be used '\n",
      " 'independently of LangSmith, LangSmith is specifically designed to work with '\n",
      " 'LangChain applications, though it can also instrument other LLM applications '\n",
      " 'through its Python and JavaScript SDKs. This complementary relationship is '\n",
      " 'underscored by real-world deployment challenges: according to a recent '\n",
      " 'survey of over 1,300 professionals, 51% currently use AI agents in '\n",
      " 'production, yet performance quality remains the most significant barrier to '\n",
      " 'deployment at 51%, followed by safety concerns at 43%â€”challenges that '\n",
      " 'LangSmith directly addresses through its monitoring and evaluation '\n",
      " 'capabilities.\\n'\n",
      " '\\n'\n",
      " 'LangChain and LangSmith address different stages of LLM application '\n",
      " 'development: LangChain provides the building blocks for creating '\n",
      " 'applications, while LangSmith offers the tools for understanding and '\n",
      " 'improving them. Together, they form a comprehensive ecosystem that enables '\n",
      " 'developers to build robust, observable, and optimized language model '\n",
      " 'applications. As the adoption of AI agents continues to accelerateâ€”with 78% '\n",
      " 'of surveyed professionals reporting plans to implement agents in the near '\n",
      " 'futureâ€”the need for both development frameworks and monitoring platforms '\n",
      " 'becomes increasingly critical. Understanding the distinction between these '\n",
      " 'tools is essential for developers seeking to leverage the full potential of '\n",
      " 'modern LLM development practices and to successfully navigate the journey '\n",
      " 'from prototype to production-grade applications.')\n",
      "\n",
      "============================================================\n",
      "DETERMINE DRAFT NEED TO BE ASSESSED ?\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ASSESSING DRAFT - ITERATION 2\n",
      "============================================================\n",
      "  âœ… Added HumanMessage to state content\n",
      "  âœ… Added Last AIMessage to state content\n",
      "  âœ… Updated 'score'\n",
      "  âœ… Updated 'feedback'\n",
      "  âœ… Updated 'need_to_revised'\n",
      "\n",
      "=== âœ… Feedback ===\n",
      "('## Detailed Evaluation\\n'\n",
      " '\\n'\n",
      " '### 1. Structure & Organization (Excellent)\\n'\n",
      " '- The essay follows a clear, logical five-paragraph structure: introduction, '\n",
      " 'LangChain explanation, LangSmith explanation, comparison/relationship, and '\n",
      " 'conclusion.\\n'\n",
      " '- Transitions between sections are smooth and purposeful. The second '\n",
      " 'paragraph flows naturally into the third, and the fourth paragraph '\n",
      " 'effectively synthesizes both tools.\\n'\n",
      " '- The outline is well-executed with each paragraph serving a distinct '\n",
      " 'purpose while building toward the overall argument.\\n'\n",
      " '\\n'\n",
      " '### 2. Thesis & Argumentation (Strong)\\n'\n",
      " '- The thesis is clear and well-articulated in the introduction: \"While these '\n",
      " 'tools are complementary and frequently used in tandem, understanding their '\n",
      " 'distinct purposes is essential for leveraging them effectively.\"\\n'\n",
      " '- The essay consistently supports this thesis throughout, dedicating '\n",
      " \"paragraphs to explain each tool's distinct role before demonstrating their \"\n",
      " 'complementary nature.\\n'\n",
      " '- Arguments are well-developed, particularly the functional distinction: '\n",
      " '\"LangChain is the development framework for building LLM applications, while '\n",
      " 'LangSmith is the observability and evaluation layer.\"\\n'\n",
      " '- One minor weakness: The argument could be slightly stronger by more '\n",
      " 'explicitly addressing potential counterarguments or limitations.\\n'\n",
      " '\\n'\n",
      " '### 3. Evidence & Support (Very Good)\\n'\n",
      " '- The essay is well-supported with evidence from credible sources '\n",
      " '(DigitalOcean, IBM, Leanware).\\n'\n",
      " '- Real-world examples are compelling: 73% reduction in contract review time '\n",
      " 'for financial services, 67% reduction in information access time for '\n",
      " 'clinical systems.\\n'\n",
      " '- Survey statistics (51% using AI agents, 78% planning implementation) '\n",
      " 'effectively support the relevance of the topic.\\n'\n",
      " '- Sources appear credible and are properly attributed with quotation marks.\\n'\n",
      " '- Minor note: While sources are cited, formal in-text citations (APA/MLA '\n",
      " 'format) are absent, though this may not be required depending on assignment '\n",
      " 'specifications.\\n'\n",
      " '\\n'\n",
      " '### 4. Writing Quality (Excellent)\\n'\n",
      " '- Tone is professional, informative, and consistent throughout.\\n'\n",
      " '- Writing is clear and concise with well-constructed sentences.\\n'\n",
      " '- No grammatical or spelling errors detected.\\n'\n",
      " '- Vocabulary is appropriately technical without being inaccessible.\\n'\n",
      " '- Sentence variety maintains reader engagement.\\n'\n",
      " '\\n'\n",
      " '### 5. Alignment with Requirements (Excellent)\\n'\n",
      " '- The essay meets all original requirements:\\n'\n",
      " '  - âœ“ Explains differences between LangChain and LangSmith\\n'\n",
      " '  - âœ“ Contains exactly 5 paragraphs\\n'\n",
      " '  - âœ“ Supported by web searches (sources from DigitalOcean, IBM, Leanware, '\n",
      " 'and survey data)\\n'\n",
      " '  - âœ“ Within the 2 revision allowance\\n'\n",
      " '- Length and depth are appropriate for the topic.\\n'\n",
      " '- Target audience (developers/technical professionals) is correctly '\n",
      " 'addressed.\\n'\n",
      " '\\n'\n",
      " '## Revision Priorities (if revisions are pursued)\\n'\n",
      " '\\n'\n",
      " '**Priority 1 (Low):** Consider adding formal citation format (APA/MLA) if '\n",
      " 'required by assignment guidelines. Currently, sources are attributed '\n",
      " 'informally.\\n'\n",
      " '\\n'\n",
      " '**Priority 2 (Low):** The fourth paragraph could benefit from one additional '\n",
      " 'concrete example showing how LangChain and LangSmith work together in a '\n",
      " 'specific use case, beyond just the technical integration details.\\n'\n",
      " '\\n'\n",
      " '**Priority 3 (Minor):** The phrase \"According to Leanware\\'s comparison\" '\n",
      " \"could be strengthened by specifying Leanware's credentials or expertise in \"\n",
      " 'this domain.\\n'\n",
      " '\\n'\n",
      " '## Strengths\\n'\n",
      " '- Clear, logical progression from individual tools to their relationship\\n'\n",
      " '- Excellent use of real-world examples and statistics\\n'\n",
      " \"- Strong understanding of both tools' purposes and capabilities\\n\"\n",
      " '- Professional, accessible writing style\\n'\n",
      " '- Meets all stated requirements\\n'\n",
      " '\\n'\n",
      " '## Overall Assessment\\n'\n",
      " 'This is a well-executed essay that successfully explains the distinct roles '\n",
      " 'of LangChain and LangSmith while demonstrating their complementary nature. '\n",
      " 'The argument is clear, evidence is compelling, and the writing is '\n",
      " 'professional. The essay would serve as a valuable resource for developers '\n",
      " 'trying to understand when and how to use each tool.')\n",
      "\n",
      "Draft Score : 8\n",
      "\n",
      "============================================================\n",
      "GENERATING RESEARCH\n",
      "============================================================\n",
      "  âœ… Added HumanMessage to state content\n",
      "  ðŸ”§ Calling tool: tavily_search_results_json\n",
      "     Args: {'query': 'LangChain LangSmith integration workflow example'}\n",
      "     Result: [{'title': 'LangChain, LangGraph, LangFlow and LangSmith Ultimate Guide', 'url': 'https://dzone.com/articles/langchain-langgraph-langflow-langsmith-ai...\n",
      "\n",
      "  ðŸ”§ Calling tool: tavily_search_results_json\n",
      "     Args: {'query': 'LangSmith observability platform features monitoring debugging'}\n",
      "     Result: [{'title': 'LangSmith Explained: Debugging and Evaluating LLM Agents', 'url': 'https://www.digitalocean.com/community/tutorials/langsmith-debudding-ev...\n",
      "\n",
      "  ðŸ”§ Calling tool: tavily_search_results_json\n",
      "     Args: {'query': 'LangChain framework open source LLM application development'}\n",
      "     Result: [{'title': 'LangChain: A Powerful Framework for LLM Applications - Medium', 'url': 'https://medium.com/@Shamimw/langchain-a-powerful-framework-for-llm...\n",
      "\n",
      "  ðŸ”§ Calling tool: tavily_search_results_json\n",
      "     Args: {'query': 'LangChain creators LangSmith platform official documentation'}\n",
      "     Result: [{'title': 'LangSmith docs - Docs by LangChain', 'url': 'https://docs.langchain.com/langsmith/home', 'content': 'LangSmith docs\\n\\nCopy page\\n\\nCopy p...\n",
      "\n",
      "  ðŸ”§ Calling tool: tavily_search_results_json\n",
      "     Args: {'query': 'LLM application development tools ecosystem 2024'}\n",
      "     Result: [{'title': 'Review of Tools for Zero-Code LLM Based Application Development', 'url': 'https://arxiv.org/html/2510.19747v1', 'content': 'Large Language...\n",
      "\n",
      "AIMessage(content='Based on my research, here is the comprehensive information organized according to the essay outline:\\n\\n```json\\n{\\n  \"research\": [\\n    {\\n      \"section_title\": \"LangChain: A Framework for Building LLM Applications\",\\n      \"key_points\": [\\n        {\\n          \"point\": \"Core Purpose and Functionality\",\\n          \"supporting_information\": [\\n            {\\n              \"fact\": \"LangChain is an open-source framework that simplifies the creation of applications leveraging large language models. It provides an ecosystem of tools to help developers build more dynamic, context-aware, and efficient AI-driven applications.\",\\n              \"source\": \"LangChain: A Powerful Framework for LLM Applications - Medium (https://medium.com/@Shamimw/langchain-a-powerful-framework-for-llm-applications-basics-and-architecture-e63d7304702e)\"\\n            },\\n            {\\n              \"fact\": \"LangChain serves as a generic interface for nearly any LLM, providing a centralized development environment to build LLM applications and integrate them with external data sources and software workflows.\",\\n              \"source\": \"What Is LangChain? | IBM (https://www.ibm.com/think/topics/langchain)\"\\n            },\\n            {\\n              \"fact\": \"LangChain simplifies every stage of the LLM application lifecycle: Development, Productionization, and Deployment through its modular components and integrations.\",\\n              \"source\": \"LangChain: A Powerful Framework for LLM Applications - Medium (https://medium.com/@Shamimw/langchain-a-powerful-framework-for-llm-applications-basics-and-architecture-e63d7304702e)\"\\n            }\\n          ]\\n        },\\n        {\\n          \"point\": \"Key Features and Components\",\\n          \"supporting_information\": [\\n            {\\n              \"fact\": \"LangChain is built around modular components including prompt templates, retrievers, document loaders, and chains that can be used independently or combined to create complex workflows.\",\\n              \"source\": \"LangChain: A Powerful Framework for LLM Applications - Medium (https://medium.com/@Shamimw/langchain-a-powerful-framework-for-llm-applications-basics-and-architecture-e63d7304702e)\"\\n            },\\n            {\\n              \"fact\": \"LangChain\\'s module-based approach allows developers to dynamically compare different prompts and even different foundation models with minimal need to rewrite code, enabling programs that use multiple LLMs.\",\\n              \"source\": \"What Is LangChain? | IBM (https://www.ibm.com/think/topics/langchain)\"\\n            },\\n            {\\n              \"fact\": \"LangChain includes core packages (langchain-core) with base abstractions and the LangChain Expression Language, plus integration packages for specific providers like OpenAI and Anthropic.\",\\n              \"source\": \"LangChain: A Powerful Framework for LLM Applications - Medium (https://medium.com/@Shamimw/langchain-a-powerful-framework-for-llm-applications-basics-and-architecture-e63d7304702e)\"\\n            }\\n          ]\\n        },\\n        {\\n          \"point\": \"Use Cases\",\\n          \"supporting_information\": [\\n            {\\n              \"fact\": \"LangChain is ideal for building applications with multiple LLMs, creating complex workflows with prompts, data retrieval, and memory, and developing scalable, maintainable AI applications.\",\\n              \"source\": \"LangChain, LangGraph, LangFlow and LangSmith Ultimate Guide | DZone (https://dzone.com/articles/langchain-langgraph-langflow-langsmith-ai-guide)\"\\n            },\\n            {\\n              \"fact\": \"The framework enables interaction with different LLMs, external data sources, and memory components, making it ideal for chatbots, AI agents, knowledge retrieval systems, and automation tools.\",\\n              \"source\": \"LangChain: A Powerful Framework for LLM Applications - Medium (https://medium.com/@Shamimw/langchain-a-powerful-framework-for-llm-applications-basics-and-architecture-e63d7304702e)\"\\n            },\\n            {\\n              \"fact\": \"Without LangChain, developers would need to manually manage API calls, memory, and agent logic, leading to complex, hard-to-maintain code.\",\\n              \"source\": \"LangChain, LangGraph, LangFlow and LangSmith Ultimate Guide | DZone (https://dzone.com/articles/langchain-langgraph-langflow-langsmith-ai-guide)\"\\n            }\\n          ]\\n        }\\n      ]\\n    },\\n    {\\n      \"section_title\": \"LangSmith: A Platform for Monitoring and Optimization\",\\n      \"key_points\": [\\n        {\\n          \"point\": \"Core Purpose and Functionality\",\\n          \"supporting_information\": [\\n            {\\n              \"fact\": \"LangSmith is a platform developed by LangChain creators that provides tools for developing, debugging, and deploying LLM applications. It helps trace requests, evaluate outputs, test prompts, and manage deployments in one place.\",\\n              \"source\": \"LangSmith docs - Docs by LangChain (https://docs.langchain.com/langsmith/home)\"\\n            },\\n            {\\n              \"fact\": \"LangSmith is framework agnostic, so you can use it with or without LangChain\\'s open-source libraries langchain and langgraph, allowing developers to prototype locally and then move to production with integrated monitoring and evaluation.\",\\n              \"source\": \"LangSmith docs - Docs by LangChain (https://docs.langchain.com/langsmith/home)\"\\n            },\\n            {\\n              \"fact\": \"As you build and run agents with LangChain, LangSmith provides visibility into how they behave: which tools they call, what prompts they generate, and how they make decisions through detailed tracing.\",\\n              \"source\": \"LangSmith Observability - Docs by LangChain (https://docs.langchain.com/oss/python/langchain/observability)\"\\n            }\\n          ]\\n        },\\n        {\\n          \"point\": \"Key Features and Capabilities\",\\n          \"supporting_information\": [\\n            {\\n              \"fact\": \"LangSmith\\'s tracing features record every step of an agent\\'s execution, from the initial user input to the final response, including all tool calls, model interactions, and decision points.\",\\n              \"source\": \"LangSmith Observability - Docs by LangChain (https://docs.langchain.com/oss/python/langchain/observability)\"\\n            },\\n            {\\n              \"fact\": \"With LangSmith\\'s tracing, every LLM call, tool invocation, and intermediate reasoning step is observable, allowing you to understand why an agent took a certain action instead of having to infer it from the logs.\",\\n              \"source\": \"LangSmith Explained: Debugging and Evaluating LLM Agents | DigitalOcean (https://www.digitalocean.com/community/tutorials/langsmith-debudding-evaluating-llm-agents)\"\\n            },\\n            {\\n              \"fact\": \"LangSmith\\'s dataset-driven evaluation workflow (available both offline and online) allows you to measure your application\\'s quality, compare prompt/model versions, and detect regressions before releasing changes to production.\",\\n              \"source\": \"LangSmith Explained: Debugging and Evaluating LLM Agents | DigitalOcean (https://www.digitalocean.com/community/tutorials/langsmith-debudding-evaluating-llm-agents)\"\\n            },\\n            {\\n              \"fact\": \"LangSmith meets the highest standards of data security and privacy with HIPAA, SOC 2 Type 2, and GDPR compliance.\",\\n              \"source\": \"LangSmith docs - Docs by LangChain (https://docs.langchain.com/langsmith/home)\"\\n            }\\n          ]\\n        },\\n        {\\n          \"point\": \"Use Cases\",\\n          \"supporting_information\": [\\n            {\\n              \"fact\": \"LangSmith is suitable for complex applications needing extensive monitoring, production environments requiring performance optimization, and teams seeking detailed insights into LLM behavior.\",\\n              \"source\": \"LangChain, LangGraph, LangFlow and LangSmith Ultimate Guide | DZone (https://dzone.com/articles/langchain-langgraph-langflow-langsmith-ai-guide)\"\\n            },\\n            {\\n              \"fact\": \"Structured traces allow you to inspect and methodically diagnose prompt failures, tool failures, retrieval issues, orchestration bugs, and fix the exact point of failure.\",\\n              \"source\": \"LangSmith Explained: Debugging and Evaluating LLM Agents | DigitalOcean (https://www.digitalocean.com/community/tutorials/langsmith-debudding-evaluating-llm-agents)\"\\n            },\\n            {\\n              \"fact\": \"Observability is foundational for agent reliability, turning debugging into analysis through structured traces that enable you to understand agent behavior and performance.\",\\n              \"source\": \"LangSmith Explained: Debugging and Evaluating LLM Agents | DigitalOcean (https://www.digitalocean.com/community/tutorials/langsmith-debudding-evaluating-llm-agents)\"\\n            }\\n          ]\\n        }\\n      ]\\n    },\\n    {\\n      \"section_title\": \"Key Differences and Complementary Relationship\",\\n      \"key_points\": [\\n        {\\n          \"point\": \"Primary Function Distinction\",\\n          \"supporting_information\": [\\n            {\\n              \"fact\": \"LangChain simplifies every stage of the LLM application lifecycle through Development (using open-source components), Productionization (using LangSmith to inspect and monitor), and Deployment.\",\\n              \"source\": \"LangChain: A Powerful Framework for LLM Applications - Medium (https://medium.com/@Shamimw/langchain-a-powerful-framework-for-llm-applications-basics-and-architecture-e63d7304702e)\"\\n            },\\n            {\\n              \"fact\": \"LangChain is the development framework for building LLM applications, while LangSmith is the observability and evaluation layer that works with those applications.\",\\n              \"source\": \"LangSmith Explained: Debugging and Evaluating LLM Agents | DigitalOcean (https://www.digitalocean.com/community/tutorials/langsmith-debudding-evaluating-llm-agents)\"\\n            }\\n          ]\\n        },\\n        {\\n          \"point\": \"Integration and Workflow\",\\n          \"supporting_information\": [\\n            {\\n              \"fact\": \"LangChain agents built with create_agent automatically support tracing through LangSmith, demonstrating seamless integration between the two tools.\",\\n              \"source\": \"LangSmith Observability - Docs by LangChain (https://docs.langchain.com/oss/python/langchain/observability)\"\\n            },\\n            {\\n              \"fact\": \"A concrete example shows enabling LangSmith tracing in a LangChain application by setting environment variables (LANGSMITH_TRACING and LANGSMITH_API_KEY) and using the @traceable decorator to log function calls and responses.\",\\n              \"source\": \"LangChain, LangGraph, LangFlow and LangSmith Ultimate Guide | DZone (https://dzone.com/articles/langchain-langgraph-langflow-langsmith-ai-guide)\"\\n            },\\n            {\\n              \"fact\": \"The LangSmith dashboard provides insights into performance metrics, allowing developers to view structured traces of their LangChain applications\\' execution, including timings, inputs/outputs, and the ability to share traces and add annotations.\",\\n              \"source\": \"LangSmith Explained: Debugging and Evaluating LLM Agents | DigitalOcean (https://www.digitalocean.com/community/tutorials/langsmith-debudding-evaluating-llm-agents)\"\\n            }\\n          ]\\n        },\\n        {\\n          \"point\": \"Dependency and Independence\",\\n          \"supporting_information\": [\\n            {\\n              \"fact\": \"LangSmith is framework agnostic and can be used with or without LangChain\\'s open-source libraries, providing flexibility for developers who may use alternative frameworks.\",\\n              \"source\": \"LangSmith docs - Docs by LangChain (https://docs.langchain.com/langsmith/home)\"\\n            },\\n            {\\n              \"fact\": \"LangChain can be used independently for application development, while LangSmith is specifically designed to work with LLM applications (whether built with LangChain or other frameworks).\",\\n              \"source\": \"LangSmith docs - Docs by LangChain (https://docs.langchain.com/langsmith/home)\"\\n            }\\n          ]\\n        }\\n      ]\\n    },\\n    {\\n      \"section_title\": \"Broader Context: LLM Application Development Ecosystem\",\\n      \"key_points\": [\\n        {\\n          \"point\": \"Role in the Ecosystem\",\\n          \"supporting_information\": [\\n            {\\n              \"fact\": \"Tools for building LLM applications can be broadly categorized into four major groups: Input Processing Tools, LLM Development Tools (like LangChain), Output Tools, and Application Tools that oversee comprehensive management including monitoring.\",\\n              \"source\": \"[Week 5] Tools for Building LLM Applications - GitHub (https://github.com/aishwaryanr/awesome-generative-ai-guide/blob/main/free_courses/Applied_LLMs_Mastery_2024/week5_tools_for_LLM_apps.md)\"\\n            },\\n            {\\n              \"fact\": \"Orchestration tools like LangChain simplify application development by abstracting away the complexity of working directly with LLMs and providing templates for common use cases like chatbots, content generation, and information retrieval.\",\\n              \"source\": \"[Week 5] Tools for Building LLM Applications - GitHub (https://github.com/aishwaryanr/awesome-generative-ai-guide/blob/main/free_courses/Applied_LLMs_Mastery_2024/week5_tools_for_LLM_apps.md)\"\\n            },\\n            {\\n              \"fact\": \"These tools often design their systems to be model-agnostic, meaning they can work with different LLMs from various providers, allowing developers to switch between models without rewriting large portions of their application code.\",\\n              \"source\": \"[Week 5] Tools for Building LLM Applications - GitHub (https://github.com/aishwaryanr/awesome-generative-ai-guide/blob/main/free_courses/Applied_LLMs_Mastery_2024/week5_tools_for_LLM_apps.md)\"\\n            }\\n          ]\\n        }\\n      ]\\n    }\\n  ]\\n}\\n```\\n\\n## Summary of Key Findings for Essay Enhancement:\\n\\n### Concrete Integration Example\\nThe research provides a specific code example showing how LangSmith integrates with LangChain:\\n- Setting environment variables: `LANGSMITH_TRACING = \"true\"` and `LANGSMITH_API_KEY`\\n- Using the `@traceable` decorator to automatically log function calls\\n- Viewing structured traces in the LangSmith dashboard\\n\\n### Authoritative Sources\\nAll sources are from credible, official documentation:\\n- **Official LangChain Documentation** (docs.langchain.com) - Primary source for both tools\\n- **IBM Think** - Enterprise perspective on LangChain\\n- **DigitalOcean Community Tutorials** - Practical implementation guidance\\n- **DZone** - Technical architecture and workflow examples\\n- **Medium** - Detailed framework explanations\\n- **GitHub** - Academic/educational resource on LLM development tools\\n\\n### Citation Format Recommendation\\nFor formal citations, use:\\n- **APA Format**: Author/Organization. (Year). Title. Retrieved from URL\\n- **MLA Format**: Author/Organization. \"Title.\" Website Name, Date, URL.\\n\\n### Key Distinction for Revision Priority 2\\nThe research reveals a concrete workflow example: A LangChain application that uses GPT-4 and Llama 3 with agents and memory, then traced through LangSmith\\'s dashboard to view execution steps, timings, and performance metricsâ€”demonstrating how both tools work together in a real scenario.', additional_kwargs={}, response_metadata={'id': 'msg_01GtBaZLpFgUXh2qBPhpaJud', 'model': 'claude-haiku-4-5-20251001', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation': {'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 8685, 'output_tokens': 3885, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-haiku-4-5-20251001', 'model_provider': 'anthropic'}, id='lc_run--019c2360-450a-7e30-889f-640478b38b1e-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 8685, 'output_tokens': 3885, 'total_tokens': 12570, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}})\n",
      "  âœ… Added Last AIMessage to state content\n",
      "  âœ… Updated 'research'\n",
      "\n",
      "=== âœ… Research ===\n",
      "(\"[{'section_title': 'LangChain: A Framework for Building LLM Applications', \"\n",
      " \"'key_points': [{'point': 'Core Purpose and Functionality', \"\n",
      " \"'supporting_information': [{'fact': 'LangChain is an open-source framework \"\n",
      " 'that simplifies the creation of applications leveraging large language '\n",
      " 'models. It provides an ecosystem of tools to help developers build more '\n",
      " \"dynamic, context-aware, and efficient AI-driven applications.', 'source': \"\n",
      " \"'LangChain: A Powerful Framework for LLM Applications - Medium \"\n",
      " \"(https://medium.com/@Shamimw/langchain-a-powerful-framework-for-llm-applications-basics-and-architecture-e63d7304702e)'}, \"\n",
      " \"{'fact': 'LangChain serves as a generic interface for nearly any LLM, \"\n",
      " 'providing a centralized development environment to build LLM applications '\n",
      " \"and integrate them with external data sources and software workflows.', \"\n",
      " \"'source': 'What Is LangChain? | IBM \"\n",
      " \"(https://www.ibm.com/think/topics/langchain)'}, {'fact': 'LangChain \"\n",
      " 'simplifies every stage of the LLM application lifecycle: Development, '\n",
      " 'Productionization, and Deployment through its modular components and '\n",
      " \"integrations.', 'source': 'LangChain: A Powerful Framework for LLM \"\n",
      " 'Applications - Medium '\n",
      " \"(https://medium.com/@Shamimw/langchain-a-powerful-framework-for-llm-applications-basics-and-architecture-e63d7304702e)'}]}, \"\n",
      " \"{'point': 'Key Features and Components', 'supporting_information': [{'fact': \"\n",
      " \"'LangChain is built around modular components including prompt templates, \"\n",
      " 'retrievers, document loaders, and chains that can be used independently or '\n",
      " \"combined to create complex workflows.', 'source': 'LangChain: A Powerful \"\n",
      " 'Framework for LLM Applications - Medium '\n",
      " \"(https://medium.com/@Shamimw/langchain-a-powerful-framework-for-llm-applications-basics-and-architecture-e63d7304702e)'}, \"\n",
      " '{\\'fact\\': \"LangChain\\'s module-based approach allows developers to '\n",
      " 'dynamically compare different prompts and even different foundation models '\n",
      " 'with minimal need to rewrite code, enabling programs that use multiple '\n",
      " 'LLMs.\", \\'source\\': \\'What Is LangChain? | IBM '\n",
      " \"(https://www.ibm.com/think/topics/langchain)'}, {'fact': 'LangChain includes \"\n",
      " 'core packages (langchain-core) with base abstractions and the LangChain '\n",
      " 'Expression Language, plus integration packages for specific providers like '\n",
      " \"OpenAI and Anthropic.', 'source': 'LangChain: A Powerful Framework for LLM \"\n",
      " 'Applications - Medium '\n",
      " \"(https://medium.com/@Shamimw/langchain-a-powerful-framework-for-llm-applications-basics-and-architecture-e63d7304702e)'}]}, \"\n",
      " \"{'point': 'Use Cases', 'supporting_information': [{'fact': 'LangChain is \"\n",
      " 'ideal for building applications with multiple LLMs, creating complex '\n",
      " 'workflows with prompts, data retrieval, and memory, and developing scalable, '\n",
      " \"maintainable AI applications.', 'source': 'LangChain, LangGraph, LangFlow \"\n",
      " 'and LangSmith Ultimate Guide | DZone '\n",
      " \"(https://dzone.com/articles/langchain-langgraph-langflow-langsmith-ai-guide)'}, \"\n",
      " \"{'fact': 'The framework enables interaction with different LLMs, external \"\n",
      " 'data sources, and memory components, making it ideal for chatbots, AI '\n",
      " \"agents, knowledge retrieval systems, and automation tools.', 'source': \"\n",
      " \"'LangChain: A Powerful Framework for LLM Applications - Medium \"\n",
      " \"(https://medium.com/@Shamimw/langchain-a-powerful-framework-for-llm-applications-basics-and-architecture-e63d7304702e)'}, \"\n",
      " \"{'fact': 'Without LangChain, developers would need to manually manage API \"\n",
      " \"calls, memory, and agent logic, leading to complex, hard-to-maintain code.', \"\n",
      " \"'source': 'LangChain, LangGraph, LangFlow and LangSmith Ultimate Guide | \"\n",
      " 'DZone '\n",
      " \"(https://dzone.com/articles/langchain-langgraph-langflow-langsmith-ai-guide)'}]}]}, \"\n",
      " \"{'section_title': 'LangSmith: A Platform for Monitoring and Optimization', \"\n",
      " \"'key_points': [{'point': 'Core Purpose and Functionality', \"\n",
      " \"'supporting_information': [{'fact': 'LangSmith is a platform developed by \"\n",
      " 'LangChain creators that provides tools for developing, debugging, and '\n",
      " 'deploying LLM applications. It helps trace requests, evaluate outputs, test '\n",
      " \"prompts, and manage deployments in one place.', 'source': 'LangSmith docs - \"\n",
      " \"Docs by LangChain (https://docs.langchain.com/langsmith/home)'}, {'fact': \"\n",
      " '\"LangSmith is framework agnostic, so you can use it with or without '\n",
      " \"LangChain's open-source libraries langchain and langgraph, allowing \"\n",
      " 'developers to prototype locally and then move to production with integrated '\n",
      " 'monitoring and evaluation.\", \\'source\\': \\'LangSmith docs - Docs by '\n",
      " \"LangChain (https://docs.langchain.com/langsmith/home)'}, {'fact': 'As you \"\n",
      " 'build and run agents with LangChain, LangSmith provides visibility into how '\n",
      " 'they behave: which tools they call, what prompts they generate, and how they '\n",
      " \"make decisions through detailed tracing.', 'source': 'LangSmith \"\n",
      " 'Observability - Docs by LangChain '\n",
      " \"(https://docs.langchain.com/oss/python/langchain/observability)'}]}, \"\n",
      " \"{'point': 'Key Features and Capabilities', 'supporting_information': \"\n",
      " '[{\\'fact\\': \"LangSmith\\'s tracing features record every step of an agent\\'s '\n",
      " 'execution, from the initial user input to the final response, including all '\n",
      " 'tool calls, model interactions, and decision points.\", \\'source\\': '\n",
      " \"'LangSmith Observability - Docs by LangChain \"\n",
      " \"(https://docs.langchain.com/oss/python/langchain/observability)'}, {'fact': \"\n",
      " '\"With LangSmith\\'s tracing, every LLM call, tool invocation, and '\n",
      " 'intermediate reasoning step is observable, allowing you to understand why an '\n",
      " 'agent took a certain action instead of having to infer it from the logs.\", '\n",
      " \"'source': 'LangSmith Explained: Debugging and Evaluating LLM Agents | \"\n",
      " 'DigitalOcean '\n",
      " \"(https://www.digitalocean.com/community/tutorials/langsmith-debudding-evaluating-llm-agents)'}, \"\n",
      " '{\\'fact\\': \"LangSmith\\'s dataset-driven evaluation workflow (available both '\n",
      " \"offline and online) allows you to measure your application's quality, \"\n",
      " 'compare prompt/model versions, and detect regressions before releasing '\n",
      " 'changes to production.\", \\'source\\': \\'LangSmith Explained: Debugging and '\n",
      " 'Evaluating LLM Agents | DigitalOcean '\n",
      " \"(https://www.digitalocean.com/community/tutorials/langsmith-debudding-evaluating-llm-agents)'}, \"\n",
      " \"{'fact': 'LangSmith meets the highest standards of data security and privacy \"\n",
      " \"with HIPAA, SOC 2 Type 2, and GDPR compliance.', 'source': 'LangSmith docs - \"\n",
      " \"Docs by LangChain (https://docs.langchain.com/langsmith/home)'}]}, {'point': \"\n",
      " \"'Use Cases', 'supporting_information': [{'fact': 'LangSmith is suitable for \"\n",
      " 'complex applications needing extensive monitoring, production environments '\n",
      " 'requiring performance optimization, and teams seeking detailed insights into '\n",
      " \"LLM behavior.', 'source': 'LangChain, LangGraph, LangFlow and LangSmith \"\n",
      " 'Ultimate Guide | DZone '\n",
      " \"(https://dzone.com/articles/langchain-langgraph-langflow-langsmith-ai-guide)'}, \"\n",
      " \"{'fact': 'Structured traces allow you to inspect and methodically diagnose \"\n",
      " 'prompt failures, tool failures, retrieval issues, orchestration bugs, and '\n",
      " \"fix the exact point of failure.', 'source': 'LangSmith Explained: Debugging \"\n",
      " 'and Evaluating LLM Agents | DigitalOcean '\n",
      " \"(https://www.digitalocean.com/community/tutorials/langsmith-debudding-evaluating-llm-agents)'}, \"\n",
      " \"{'fact': 'Observability is foundational for agent reliability, turning \"\n",
      " 'debugging into analysis through structured traces that enable you to '\n",
      " \"understand agent behavior and performance.', 'source': 'LangSmith Explained: \"\n",
      " 'Debugging and Evaluating LLM Agents | DigitalOcean '\n",
      " \"(https://www.digitalocean.com/community/tutorials/langsmith-debudding-evaluating-llm-agents)'}]}]}, \"\n",
      " \"{'section_title': 'Key Differences and Complementary Relationship', \"\n",
      " \"'key_points': [{'point': 'Primary Function Distinction', \"\n",
      " \"'supporting_information': [{'fact': 'LangChain simplifies every stage of the \"\n",
      " 'LLM application lifecycle through Development (using open-source '\n",
      " 'components), Productionization (using LangSmith to inspect and monitor), and '\n",
      " \"Deployment.', 'source': 'LangChain: A Powerful Framework for LLM \"\n",
      " 'Applications - Medium '\n",
      " \"(https://medium.com/@Shamimw/langchain-a-powerful-framework-for-llm-applications-basics-and-architecture-e63d7304702e)'}, \"\n",
      " \"{'fact': 'LangChain is the development framework for building LLM \"\n",
      " 'applications, while LangSmith is the observability and evaluation layer that '\n",
      " \"works with those applications.', 'source': 'LangSmith Explained: Debugging \"\n",
      " 'and Evaluating LLM Agents | DigitalOcean '\n",
      " \"(https://www.digitalocean.com/community/tutorials/langsmith-debudding-evaluating-llm-agents)'}]}, \"\n",
      " \"{'point': 'Integration and Workflow', 'supporting_information': [{'fact': \"\n",
      " \"'LangChain agents built with create_agent automatically support tracing \"\n",
      " 'through LangSmith, demonstrating seamless integration between the two '\n",
      " \"tools.', 'source': 'LangSmith Observability - Docs by LangChain \"\n",
      " \"(https://docs.langchain.com/oss/python/langchain/observability)'}, {'fact': \"\n",
      " \"'A concrete example shows enabling LangSmith tracing in a LangChain \"\n",
      " 'application by setting environment variables (LANGSMITH_TRACING and '\n",
      " 'LANGSMITH_API_KEY) and using the @traceable decorator to log function calls '\n",
      " \"and responses.', 'source': 'LangChain, LangGraph, LangFlow and LangSmith \"\n",
      " 'Ultimate Guide | DZone '\n",
      " \"(https://dzone.com/articles/langchain-langgraph-langflow-langsmith-ai-guide)'}, \"\n",
      " '{\\'fact\\': \"The LangSmith dashboard provides insights into performance '\n",
      " 'metrics, allowing developers to view structured traces of their LangChain '\n",
      " \"applications' execution, including timings, inputs/outputs, and the ability \"\n",
      " 'to share traces and add annotations.\", \\'source\\': \\'LangSmith Explained: '\n",
      " 'Debugging and Evaluating LLM Agents | DigitalOcean '\n",
      " \"(https://www.digitalocean.com/community/tutorials/langsmith-debudding-evaluating-llm-agents)'}]}, \"\n",
      " \"{'point': 'Dependency and Independence', 'supporting_information': [{'fact': \"\n",
      " '\"LangSmith is framework agnostic and can be used with or without '\n",
      " \"LangChain's open-source libraries, providing flexibility for developers who \"\n",
      " 'may use alternative frameworks.\", \\'source\\': \\'LangSmith docs - Docs by '\n",
      " \"LangChain (https://docs.langchain.com/langsmith/home)'}, {'fact': 'LangChain \"\n",
      " 'can be used independently for application development, while LangSmith is '\n",
      " 'specifically designed to work with LLM applications (whether built with '\n",
      " \"LangChain or other frameworks).', 'source': 'LangSmith docs - Docs by \"\n",
      " \"LangChain (https://docs.langchain.com/langsmith/home)'}]}]}, \"\n",
      " \"{'section_title': 'Broader Context: LLM Application Development Ecosystem', \"\n",
      " \"'key_points': [{'point': 'Role in the Ecosystem', 'supporting_information': \"\n",
      " \"[{'fact': 'Tools for building LLM applications can be broadly categorized \"\n",
      " 'into four major groups: Input Processing Tools, LLM Development Tools (like '\n",
      " 'LangChain), Output Tools, and Application Tools that oversee comprehensive '\n",
      " \"management including monitoring.', 'source': '[Week 5] Tools for Building \"\n",
      " 'LLM Applications - GitHub '\n",
      " \"(https://github.com/aishwaryanr/awesome-generative-ai-guide/blob/main/free_courses/Applied_LLMs_Mastery_2024/week5_tools_for_LLM_apps.md)'}, \"\n",
      " \"{'fact': 'Orchestration tools like LangChain simplify application \"\n",
      " 'development by abstracting away the complexity of working directly with LLMs '\n",
      " 'and providing templates for common use cases like chatbots, content '\n",
      " \"generation, and information retrieval.', 'source': '[Week 5] Tools for \"\n",
      " 'Building LLM Applications - GitHub '\n",
      " \"(https://github.com/aishwaryanr/awesome-generative-ai-guide/blob/main/free_courses/Applied_LLMs_Mastery_2024/week5_tools_for_LLM_apps.md)'}, \"\n",
      " \"{'fact': 'These tools often design their systems to be model-agnostic, \"\n",
      " 'meaning they can work with different LLMs from various providers, allowing '\n",
      " 'developers to switch between models without rewriting large portions of '\n",
      " \"their application code.', 'source': '[Week 5] Tools for Building LLM \"\n",
      " 'Applications - GitHub '\n",
      " \"(https://github.com/aishwaryanr/awesome-generative-ai-guide/blob/main/free_courses/Applied_LLMs_Mastery_2024/week5_tools_for_LLM_apps.md)'}]}]}]\")\n",
      "\n",
      "============================================================\n",
      "GENERATING DRAFT - ITERATION 3\n",
      "============================================================\n",
      "  âœ… Added HumanMessage to state content\n",
      "  âœ… Added Last AIMessage to state content\n",
      "  âœ… Updated 'essay'\n",
      "\n",
      "=== âœ… Essay ===\n",
      "('# LangChain and LangSmith: Distinct Tools in the LLM Development Ecosystem\\n'\n",
      " '\\n'\n",
      " 'As large language models become increasingly central to software '\n",
      " 'development, developers need tools to both build and maintain these '\n",
      " 'applications effectively. LangChain and LangSmith are two prominent tools in '\n",
      " 'the AI development space that often appear together in discussions, yet they '\n",
      " 'address fundamentally different aspects of LLM application development. '\n",
      " 'While LangChain and LangSmith are complementary tools within the LLM '\n",
      " 'development ecosystem, they serve distinct purposes: LangChain is a '\n",
      " 'framework for building applications with language models, whereas LangSmith '\n",
      " 'is a platform for monitoring, debugging, and optimizing those applications. '\n",
      " 'This essay will clarify the distinct roles of each tool and explain how they '\n",
      " 'complement one another.\\n'\n",
      " '\\n'\n",
      " 'LangChain serves as an open-source framework designed to simplify the '\n",
      " 'development of applications powered by language models. According to IBM, '\n",
      " 'LangChain \"serves as a generic interface for nearly any LLM, providing a '\n",
      " 'centralized development environment to build LLM applications and integrate '\n",
      " 'them with external data sources and software workflows.\" The framework '\n",
      " 'achieves this through a modular, component-based architecture. As noted in '\n",
      " 'Medium\\'s comprehensive guide, \"LangChain is built around modular components '\n",
      " 'including prompt templates, retrievers, document loaders, and chains that '\n",
      " 'can be used independently or combined to create complex workflows.\" This '\n",
      " 'modularity is particularly powerful because it allows developers to '\n",
      " 'dynamically compare different prompts and even different foundation models '\n",
      " 'with minimal code rewriting. LangChain simplifies every stage of the LLM '\n",
      " 'application lifecycleâ€”development, productionization, and deploymentâ€”making '\n",
      " 'it ideal for building chatbots, question-answering systems, document '\n",
      " 'analysis tools, and AI agents. Without LangChain, developers would need to '\n",
      " 'manually manage API calls, memory, and agent logic, resulting in complex, '\n",
      " 'hard-to-maintain code.\\n'\n",
      " '\\n'\n",
      " 'While LangChain provides the building blocks for creating LLM applications, '\n",
      " 'LangSmith offers a complementary platform for observing and optimizing those '\n",
      " 'applications in production and development environments. According to '\n",
      " 'LangChain\\'s official documentation, \"LangSmith is a platform developed by '\n",
      " 'LangChain creators that provides tools for developing, debugging, and '\n",
      " 'deploying LLM applications. It helps trace requests, evaluate outputs, test '\n",
      " 'prompts, and manage deployments in one place.\" The platform\\'s tracing '\n",
      " \"features record every step of an agent's execution, from initial user input \"\n",
      " 'to final response, including all tool calls, model interactions, and '\n",
      " 'decision points. As DigitalOcean explains, \"With LangSmith\\'s tracing, every '\n",
      " 'LLM call, tool invocation, and intermediate reasoning step is observable, '\n",
      " 'allowing you to understand why an agent took a certain action instead of '\n",
      " 'having to infer it from the logs.\" Beyond tracing, LangSmith provides '\n",
      " 'dataset-driven evaluation workflows that allow developers to measure '\n",
      " 'application quality, compare prompt and model versions, and detect '\n",
      " 'regressions before releasing changes to production. These capabilities make '\n",
      " 'LangSmith essential for complex applications requiring extensive monitoring '\n",
      " 'and teams seeking detailed insights into LLM behavior.\\n'\n",
      " '\\n'\n",
      " 'The relationship between LangChain and LangSmith exemplifies how these tools '\n",
      " 'serve distinct yet complementary functions within the LLM development '\n",
      " 'lifecycle. LangChain is the development framework for building LLM '\n",
      " 'applications, while LangSmith is the observability and evaluation layer that '\n",
      " 'works with those applications. The integration between them is seamless: '\n",
      " 'LangChain agents built with create_agent automatically support tracing '\n",
      " 'through LangSmith, and developers can enable LangSmith tracing by simply '\n",
      " 'setting environment variables and using the @traceable decorator. '\n",
      " 'Importantly, while LangSmith is framework agnostic and can be used with or '\n",
      " \"without LangChain's open-source libraries, LangChain can be used \"\n",
      " 'independently for application development. This flexibility means that '\n",
      " 'LangChain serves as a foundational tool for building, while LangSmith is '\n",
      " 'specifically designed to provide visibility into how LLM applications behave '\n",
      " 'and perform.\\n'\n",
      " '\\n'\n",
      " 'LangChain and LangSmith address different stages of LLM application '\n",
      " 'development: LangChain provides the building blocks for creating '\n",
      " 'applications, while LangSmith offers the tools for understanding and '\n",
      " 'improving them. Together, they form a comprehensive ecosystem that enables '\n",
      " 'developers to build robust, observable, and optimized language model '\n",
      " 'applications. LangChain simplifies the development stage through its modular '\n",
      " 'components and integrations, while LangSmith enables the productionization '\n",
      " 'and deployment stages by providing visibility into application behavior and '\n",
      " 'performance metrics. Understanding the distinction between these tools is '\n",
      " 'essential for developers seeking to leverage the full potential of modern '\n",
      " 'LLM development practices, as each tool addresses a critical but distinct '\n",
      " 'need in the journey from conception to production.')\n",
      "\n",
      "============================================================\n",
      "DETERMINE DRAFT NEED TO BE ASSESSED ?\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "html = bot.execute(\"what is the difference between langchain and langsmith, you can do 5 web search and 2 revision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CpQ43iolqJVE"
   },
   "source": [
    "# EmailAgent with Agent Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "hM9TW5H377kc"
   },
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "auth.authenticate_user()\n",
    "gmail_service = build('gmail', 'v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "eyEkxCQug17U"
   },
   "outputs": [],
   "source": [
    "# Get latest data from sheet\n",
    "creds, _ = default()\n",
    "gc = gspread.authorize(creds)\n",
    "sheet = gc.open_by_url(\"https://docs.google.com/spreadsheets/d/1Kg-j1_zjdk2UJdVNQanTsF_mLu8S4X9LuXYiBLOBWGA/edit?gid=0#gid=0\").sheet1\n",
    "data = sheet.get_all_records()\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 144
    },
    "id": "0YrlIqjGgyJB",
    "outputId": "f73abb7f-a852-4c02-9675-90b41a7c4651"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>persona</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marcel</td>\n",
       "      <td>Data analyst and scientist who is actively lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Safrina</td>\n",
       "      <td>Working mom that have store in the supply chai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Peter</td>\n",
       "      <td>Working father that have store in the supply c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name                                            persona\n",
       "0   Marcel  Data analyst and scientist who is actively lea...\n",
       "1  Safrina  Working mom that have store in the supply chai...\n",
       "2    Peter  Working father that have store in the supply c..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.DataFrame()\n",
    "df = pd.concat([df, a])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y1cHDIesUqLx"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain.agents import create_agent\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.messages import AnyMessage, HumanMessage, AIMessage, SystemMessage, ToolMessage\n",
    "from langchain.tools import tool\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.types import interrupt, Command\n",
    "from typing import TypedDict, Annotated, List\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "import re\n",
    "import ast\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "import gspread\n",
    "from google.auth import default\n",
    "import pandas as pd\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import base64\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "# Initialize ChromaDB client\n",
    "client = chromadb.Client(Settings(\n",
    "    persist_directory=\"/content/chroma_db\",\n",
    "    anonymized_telemetry=False\n",
    "))\n",
    "\n",
    "# Create or get collection\n",
    "collection = client.get_or_create_collection(\n",
    "    name=\"user_personas\",\n",
    "    metadata={\"description\": \"User persona and preference data\"}\n",
    ")\n",
    "\n",
    "###########\n",
    "# UTILITY #\n",
    "###########\n",
    "def extract_dict_from_string(text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extract and convert a dictionary from a string that may contain extra text.\n",
    "    Tries JSON first, then falls back to ast.literal_eval.\n",
    "    \"\"\"\n",
    "    # Strip markdown code fences if present\n",
    "    cleaned = text.strip()\n",
    "\n",
    "    if re.search(r'```json', cleaned):\n",
    "      list_substr = cleaned.split(\"```json\")\n",
    "      cleaned = list_substr[1]\n",
    "    if re.search(r'```', cleaned):\n",
    "      list_substr = cleaned.split(\"```\")\n",
    "      cleaned = list_substr[0]\n",
    "\n",
    "    cleaned = cleaned.strip()\n",
    "\n",
    "    try:\n",
    "        result = json.loads(cleaned)\n",
    "        if isinstance(result, dict):\n",
    "            return result\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "\n",
    "    print(f\"âŒ Failed to extract dict from response:\\n{text[:200]}\")\n",
    "    return {}\n",
    "\n",
    "def sync_personas_from_sheets(url:str, df_append:pd.DataFrame = pd.DataFrame()):\n",
    "    \"\"\"Sync persona data from Google Sheets to ChromaDB\"\"\"\n",
    "\n",
    "    # Get latest data from sheet\n",
    "    creds, _ = default()\n",
    "    gc = gspread.authorize(creds)\n",
    "    sheet = gc.open_by_url(url).sheet1\n",
    "    data = sheet.get_all_records()\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Append new info\n",
    "    df = pd.DataFrame\n",
    "\n",
    "    # Clear existing collection\n",
    "    client.delete_collection(\"user_personas\")\n",
    "    collection = client.create_collection(\"user_personas\")\n",
    "\n",
    "    # Re-populate\n",
    "    documents = []\n",
    "    metadatas = []\n",
    "    ids = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        doc_text = \" | \".join([f\"{k}: {v}\" for k, v in row.items()])\n",
    "        documents.append(doc_text)\n",
    "        metadatas.append({key: str(value) for key, value in row.items()})\n",
    "        ids.append(f\"user_{idx}\")\n",
    "\n",
    "    collection.add(documents=documents, metadatas=metadatas, ids=ids)\n",
    "    print(f\"âœ… Synced {len(documents)} personas from Google Sheets\")\n",
    "\n",
    "    return collection\n",
    "\n",
    "##########\n",
    "# PROMPT #\n",
    "##########\n",
    "BASE_PROMPT = \"\"\"\n",
    "  ROLE\n",
    "  You are an intelligent Email Classification Agent designed to help busy professionals manage their inbox efficiently by categorizing incoming emails based on urgency, relevance, and required action.\n",
    "\n",
    "  # BACKGROUND: USER PERSONA\n",
    "  You are assisting {name}, a {persona}\n",
    "\"\"\"\n",
    "\n",
    "PROMPT_ROUTER = \"\"\"\n",
    "  {base_prompt}\n",
    "\n",
    "  INSTRUCTION\n",
    "  Classify user intent\n",
    "\n",
    "  Use \"email_workflow\" if:\n",
    "    - User provides an email to analyze/classify\n",
    "    - User asks to draft/send an email\n",
    "    - User mentions responding to an email\n",
    "\n",
    "    Use \"general_query\" if:\n",
    "    - User asks about calendar availability\n",
    "    - User asks to schedule a meeting (without email context)\n",
    "    - General questions or requests\n",
    "\n",
    "  INPUT\n",
    "  {message}\n",
    "\n",
    "  OUTPUT, in json format\n",
    "  ```json\n",
    "  name : [The inferred user name]\n",
    "  user_intent : [email_workflow/general_query]\n",
    "  ```\n",
    "\"\"\"\n",
    "\n",
    "PROMPT_PERSONA = \"\"\"\n",
    "  ROLE\n",
    "  You are an AI that can help inferred the user persona based on the chain of message asked by that user\n",
    "\n",
    "  INPUT\n",
    "  {conversation}\n",
    "\n",
    "  OUTPUT\n",
    "  Summary of the user persona\n",
    "\"\"\"\n",
    "\n",
    "PROMPT_TRIAGE = \"\"\"\n",
    "  {base_prompt}\n",
    "\n",
    "  # INSTRUCTION\n",
    "  For each incoming email, analyze its content, sender, subject, and context to categorize it into one of three actions: IGNORE, NOTIFY, or RESPOND.\n",
    "\n",
    "  # RULES: EMAIL CATEGORY DEFINITIONS\n",
    "\n",
    "  ## IGNORE\n",
    "  Emails that require NO action and NO attention.\n",
    "\n",
    "  **Criteria:**\n",
    "  Marketing newsletters, spam emails, mass company announcements\n",
    "\n",
    "  ## NOTIFY\n",
    "  Emails that Marcel should be AWARE of but don't require immediate response.\n",
    "\n",
    "  **Criteria:**\n",
    "  Team member out sick, build system notifications, project status updates\n",
    "\n",
    "  ## RESPOND\n",
    "  Emails that require Marcel's direct action, response, or decision.\n",
    "\n",
    "  **Criteria:**\n",
    "  Direct questions from team members, meeting requests, critical bug reports\n",
    "\n",
    "  INPUT\n",
    "  Email : {email}\n",
    "\n",
    "  OUTPUT, in json format\n",
    "  ```json\n",
    "  from : [The sender of the email]\n",
    "  to : [The user that get the email]\n",
    "  subject : [The subject of the email]\n",
    "  email_content : [The content of the email]\n",
    "  email_classification : [IGNORE/NOTIFY/RESPOND]\n",
    "  classification_reason : [The reason behind the value of email_classification]\n",
    "  ```\n",
    "\"\"\"\n",
    "\n",
    "PROMPT_RESPOND = \"\"\"\n",
    "  {base_prompt}\n",
    "\n",
    "  INSTRUCTION\n",
    "  Draft and call send_email tool with :\n",
    "  - to_email: recipient's email address\n",
    "  - subject: email subject line\n",
    "  - body: the complete email you drafted\n",
    "\n",
    "  INPUT\n",
    "  From : {from}\n",
    "  To : {to}\n",
    "  Subject : {subject}\n",
    "  Content : {email_content}\n",
    "\n",
    "  OUTPUT, in json format\n",
    "  ```json\n",
    "  respond_subject : [Subject of the respond email based on user persona]\n",
    "  respond_content : [Content of the respond email based on user persona]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "########\n",
    "# TOOL #\n",
    "########\n",
    "@tool\n",
    "def send_email(to_email: str, subject: str, body: str) -> str:\n",
    "  \"\"\"\n",
    "  Actually send an email via Gmail API.\n",
    "  The LLM should provide the to_email, subject, and body.\n",
    "\n",
    "  Args:\n",
    "      to_email: Recipient email address\n",
    "      subject: Email subject line\n",
    "      body: Complete email body (already drafted by LLM)\n",
    "\n",
    "  Returns:\n",
    "      Confirmation message\n",
    "  \"\"\"\n",
    "\n",
    "  try:\n",
    "      # Create message\n",
    "      message = MIMEText(body, 'plain')\n",
    "      message['to'] = to_email\n",
    "      message['subject'] = subject\n",
    "\n",
    "      # Encode message\n",
    "      raw_message = base64.urlsafe_b64encode(message.as_bytes()).decode('utf-8')\n",
    "\n",
    "      # Send email\n",
    "      send_message = gmail_service.users().messages().send(\n",
    "          userId='me',\n",
    "          body={'raw': raw_message}\n",
    "      ).execute()\n",
    "\n",
    "      return f\"âœ… Email sent successfully to {to_email}! Message ID: {send_message['id']}\"\n",
    "\n",
    "  except Exception as e:\n",
    "      return f\"âŒ Failed to send email: {str(e)}\"\n",
    "\n",
    "\n",
    "#########\n",
    "# AGENT #\n",
    "#########\n",
    "class AgentState(TypedDict):\n",
    "  task: str\n",
    "  name: str\n",
    "  persona: str\n",
    "  user_intent: str\n",
    "  sender: str\n",
    "  email_subject: str\n",
    "  email_content: str\n",
    "  email_classification: str\n",
    "  classification_reason: str\n",
    "  email_respond_subject: str\n",
    "  email_respond_content: str\n",
    "\n",
    "class EmailAgent:\n",
    "  def __init__(self, tools, middleware):\n",
    "    self.config = {'configurable': {'thread_id': 101}}\n",
    "    self.checkpointer = InMemorySaver()\n",
    "\n",
    "    # Store tools as dictionary\n",
    "    self.tools = {t.name: t for t in tools}\n",
    "\n",
    "    # create LLM with tool binding\n",
    "    self.llm = init_chat_model(\n",
    "        model=\"claude-haiku-4-5-20251001\",\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    # Bind tools to the model\n",
    "    self.llm_with_tools = self.llm.bind_tools(tools)\n",
    "\n",
    "    # to initiate the Graph\n",
    "    self.graph = StateGraph(AgentState)\n",
    "    self.graph.add_node('router', self.call_agent_plan)\n",
    "    self.graph.add_node('persona', self.call_get_user_persona)\n",
    "    self.graph.add_edge('router', 'persona')\n",
    "    self.graph.add_node('generate', self.call_agent_generate)\n",
    "    self.graph.add_edge('research', 'generate')\n",
    "    self.graph.add_conditional_edges(\n",
    "        'generate',\n",
    "        self.check_revision_iteration,\n",
    "        {True: 'reflect', False: END})\n",
    "    self.graph.add_node('reflect', self.call_agent_reflect)\n",
    "    self.graph.add_edge('reflect', 'research')\n",
    "    self.graph.set_entry_point('plan')\n",
    "\n",
    "    self.graph_np = self.graph.compile(\n",
    "        checkpointer=self.checkpointer,\n",
    "        )\n",
    "\n",
    "  def _update_state(self, new_dict:dict, state: AgentState):\n",
    "    \"\"\"Check whether the state will be updated based on the JSON output from the LLM response \"\"\"\n",
    "    for key, value in new_dict.items():\n",
    "      if key in state:\n",
    "        print(f\"  âœ… Updated '{key}'\")\n",
    "      else:\n",
    "        print(f\"  âš ï¸  Unknown key '{key}' - skipped\")\n",
    "\n",
    "  def call_agent_router(self, state:AgentState):\n",
    "\n",
    "    # Initial sync of the user persona data\n",
    "    sync_personas_from_sheets(\"https://docs.google.com/spreadsheets/d/1Kg-j1_zjdk2UJdVNQanTsF_mLu8S4X9LuXYiBLOBWGA/edit?gid=0#gid=0\")\n",
    "\n",
    "    # Invoke LLM\n",
    "    message = HumanMessage(content = PROMPT_ROUTER.format(\n",
    "        base_prompt=BASE_PROMPT,\n",
    "        message=state['task'],\n",
    "      )\n",
    "    )\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ROUTING}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    result = self.llm.invoke(message)\n",
    "    json_result = extract_dict_from_string(result.content)\n",
    "    self._update_state(json_result, state)\n",
    "\n",
    "    print(f\"\\nUser : {json_result.get('name', '')}\")\n",
    "    print(f\"\\Task Type : {json_result.get('user_intent', '')}\")\n",
    "\n",
    "    return {\n",
    "      'name': json_result.get('name', ''),\n",
    "      'user_intent': json_result.get('user_intent', ''),\n",
    "    }\n",
    "\n",
    "  def call_get_user_persona(self, state:AgentState):\n",
    "    \"\"\" Retrieve user persona and preference information \"\"\"\n",
    "\n",
    "    # Filter by specific user\n",
    "    result = collection.get(\n",
    "          where={\"name\": state['name']}\n",
    "      )\n",
    "\n",
    "    if len(result['metadata']) > 0 :\n",
    "      print(f\"âœ… User Persona {state['name']} found, proceed with it\")\n",
    "\n",
    "      return result['metadata'][0]\n",
    "\n",
    "    else:\n",
    "      if state['']\n",
    "      print(f\"âŒ No user persona found, proceed with default\")\n",
    "      result = {\n",
    "          'name':state['name'],\n",
    "          'persona':'User not specified, treat it as default persona'\n",
    "      }\n",
    "\n",
    "  def execute(self, message) :\n",
    "    \"\"\"Function to run the agent graph flow\"\"\"\n",
    "\n",
    "    self.input_message = message\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TOPIC FROM THE USER\")\n",
    "    print(f\"{'='*60}\")\n",
    "    pprint(f\"{self.input_message}\")\n",
    "\n",
    "    # âœ… Initialize ALL required state fields\n",
    "    initial_state = {\n",
    "        'task': self.input_message,\n",
    "        'name': '',\n",
    "        'persona': '',\n",
    "        'user_intent': '',\n",
    "        'sender': '',\n",
    "        'email_subject': '',\n",
    "        'email_content' : '',\n",
    "        'email_classification': '',\n",
    "        'classification_reason': '',\n",
    "        'email_respond_subject': '',\n",
    "        'email_respond_content' : ''\n",
    "    }\n",
    "\n",
    "    # Run the graph\n",
    "    result = self.graph_np.invoke(\n",
    "        initial_state,\n",
    "        config=self.config\n",
    "    )\n",
    "\n",
    "    # Get final answer\n",
    "    final_answer = result['essay']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "id": "-60DzKAjsIVF",
    "outputId": "3d165c18-0691-4524-efe8-db5197cbab1f"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'prompts'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-248117747.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mprompts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtriage_system_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtriage_user_prompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'prompts'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wG_Iyr6-sIc2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
