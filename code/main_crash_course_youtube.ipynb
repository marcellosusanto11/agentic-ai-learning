{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Setup"
   ],
   "metadata": {
    "id": "ypLn-6DUydgJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Setup Keys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ],
   "metadata": {
    "id": "BqbHDy7ilHRM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Mount drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J5gDQmpqRphC",
    "outputId": "c210d2d4-7169-4f86-80f3-5765ebba2664"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Change WD\n",
    "import os\n",
    "\n",
    "new_directory = '/content/drive/My Drive/Python/LangChain'\n",
    "os.chdir(new_directory)"
   ],
   "metadata": {
    "id": "qFDbEitCR2Xv"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get Weather"
   ],
   "metadata": {
    "id": "EMEhKxZfyiiD"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Start building agent for get weather\n",
    "import requests\n",
    "from langchain.agents import create_agent\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool('get_weather', description='Get Weather', return_direct=False)\n",
    "def get_weather(city: str) :\n",
    "  response = requests.get(f'https://wttr.in/{city}?format=j1')\n",
    "\n",
    "  return response.json()\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-3-flash-preview\")\n",
    "\n",
    "agent = create_agent(\n",
    "    # model = \"gpt-3.5-turbo\",\n",
    "    model = llm,\n",
    "    tools = [get_weather],\n",
    "    system_prompt = 'You are a helpful weather assistant, who shared the report in a efficient and concise way.'\n",
    ")\n",
    "\n",
    "response = agent.invoke({\n",
    "    'messages': [\n",
    "        {\n",
    "          'role':'user',\n",
    "          'content':'What is the weather like in Banjar Wijaya ?'\n",
    "         }\n",
    "    ]\n",
    "})\n",
    "\n"
   ],
   "metadata": {
    "id": "wJ44KD9-lX1x"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from pprint import pprint\n",
    "pprint(response['messages'][-1].content[0]['text'])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "66rUtyWaq0ti",
    "outputId": "122756ee-4cc3-49cc-cb59-7585f7270777"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('In Banjar Wijaya (Tangerang), the current weather is **28Â°C** with **light '\n",
      " 'rain showers**.\\n'\n",
      " '\\n'\n",
      " '*   **Feels Like:** 33Â°C\\n'\n",
      " '*   **Humidity:** 79%\\n'\n",
      " '*   **Wind:** 16 km/h (WSW)\\n'\n",
      " '*   **Conditions:** Expect patchy rain to continue through the evening.')\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# No Tools but Using Agent"
   ],
   "metadata": {
    "id": "fbh4pN7qykvM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Start building agent without any tools defined\n",
    "import requests\n",
    "from langchain.agents import create_agent\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool('get_weather', description='Get Weather', return_direct=False)\n",
    "def get_weather(city: str) :\n",
    "  response = requests.get(f'https://wttr.in/{city}?format=j1')\n",
    "\n",
    "  return response.json()\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-3-flash-preview\")\n",
    "\n",
    "agent = create_agent(\n",
    "    # model = \"gpt-3.5-turbo\",\n",
    "    model = llm,\n",
    "    # tools = [get_weather],\n",
    "    system_prompt = 'You are a seasoned traveler agent that specialize in low budget travel'\n",
    ")\n",
    "\n",
    "response = agent.invoke({\n",
    "    'messages': [\n",
    "        {\n",
    "          'role':'user',\n",
    "          'content':'Can you recommend a 1 day trip near Jakarta for weekend ?'\n",
    "         }\n",
    "    ]\n",
    "})\n",
    "\n"
   ],
   "metadata": {
    "id": "HyIws1YatAY3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from pprint import pprint\n",
    "pprint(response['messages'][-1].content[0]['text'])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C2tV66Ufw8gU",
    "outputId": "bcfd4922-265d-45d3-9fbe-81a354588bf7"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('Hello there! As a budget travel specialist, I know that \"near Jakarta\" on a '\n",
      " 'weekend can be a challenge because of the traffic. To get the best bang for '\n",
      " 'your buck without spending 6 hours stuck in a car, I have three solid '\n",
      " 'recommendations categorized by \"vibe.\"\\n'\n",
      " '\\n'\n",
      " 'Here are my top 3 picks for a low-budget 1-day trip:\\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '### 1. The Island Escape: Pari Island (Kepulauan Seribu)\\n'\n",
      " 'If you want to forget youâ€™re in a megacity, head to the sea. Pari Island is '\n",
      " 'one of the most budget-friendly islands.\\n'\n",
      " '\\n'\n",
      " '*   **How to get there:** Go to **Muara Angke Port** (Kali Adem) early in '\n",
      " 'the morning (be there by 6:00 AM). Take the traditional wooden boat (Kapal '\n",
      " 'Dishub or traditional boat).\\n'\n",
      " '*   **Cost:** \\n'\n",
      " '    *   Boat: Rp 44,000 â€“ Rp 70,000 (one way).\\n'\n",
      " '    *   Entrance to Pantai Pasir Perawan: Rp 10,000.\\n'\n",
      " '    *   Bike rental: Rp 20,000 for the whole day.\\n'\n",
      " '*   **What to do:** Rent a bike, cycle around the tiny island, and spend the '\n",
      " 'afternoon at **Pasir Perawan Beach**. You can rent a small canoe to go '\n",
      " 'through the mangroves for about Rp 30,000.\\n'\n",
      " '*   **Budget Tip:** Pack your own snacks and a large bottle of water from a '\n",
      " 'Jakarta minimarket. Food on the island is slightly pricier, though \"Nasi '\n",
      " 'Bungkus\" is still affordable.\\n'\n",
      " '\\n'\n",
      " '### 2. The Nature Trek: Sentul (Bogor)\\n'\n",
      " 'Sentul is the best alternative to Puncak. Itâ€™s closer, and you avoid the '\n",
      " '\"one-way\" traffic madness of the main Puncak road.\\n'\n",
      " '\\n'\n",
      " '*   **How to get there:** Take the **LRT to Harjamukti Station** or the '\n",
      " '**KRL to Bogor Station**, then take a Grab/Gojek to the Sentul trekking '\n",
      " 'starting point (specifically **Babakan Madang** area).\\n'\n",
      " '*   **Cost:**\\n'\n",
      " '    *   KRL/LRT: Under Rp 15,000.\\n'\n",
      " '    *   Entrance to waterfalls (Curug): Rp 15,000 â€“ Rp 25,000.\\n'\n",
      " '    *   Local Guide (optional but recommended for hidden spots): Rp '\n",
      " '100k-150k for a group.\\n'\n",
      " '*   **What to do:** Hike to **Curug Leuwi Hejo** or **Curug Putri Kencana**. '\n",
      " 'These are stunning \"blue\" water natural pools. You can swim, jump off rocks, '\n",
      " 'and enjoy the forest.\\n'\n",
      " '*   **Budget Tip:** Go in a group of 3-4 to split the Grab/Gojek cost from '\n",
      " 'the station. Avoid the \"VIP\" trekking packages sold online; just show up at '\n",
      " 'the trailhead and pay the local entrance fee.\\n'\n",
      " '\\n'\n",
      " '### 3. The Heritage & Culinary Walk: Bogor City\\n'\n",
      " 'This is the easiest, most \"fail-proof\" budget trip.\\n'\n",
      " '\\n'\n",
      " '*   **How to get there:** Take the **KRL Commuter Line** to Bogor Station. \\n'\n",
      " '*   **Cost:**\\n'\n",
      " '    *   KRL: Rp 5,000 (one way).\\n'\n",
      " '    *   Bogor Botanical Garden Entrance: Rp 15,500 (weekdays) â€“ Rp 25,500 '\n",
      " '(weekends).\\n'\n",
      " '*   **What to do:** \\n'\n",
      " '    1.  Walk from the station to the **Bogor Botanical Gardens (Kebun '\n",
      " \"Raya)**. It's massive and perfect for a picnic.\\n\"\n",
      " '    2.  Afterward, walk to **Suryakencana Street** (right across the gate). '\n",
      " 'This is a legendary street food heaven. \\n'\n",
      " '*   **Budget Tip:** For food in Suryakencana, look for *Soto Kuning Pak '\n",
      " 'Yusup* or *Doclang*. These are filling, local, and cost less than Rp '\n",
      " '30,000. \\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '### Pro-Tips for the Weekend Warrior:\\n'\n",
      " '1.  **The \"6 AM Rule\":** If you leave after 8 AM, you will spend half your '\n",
      " 'day in traffic. Leave at 6 AM, and youâ€™ll be the first at the beach or the '\n",
      " 'waterfall.\\n'\n",
      " '2.  **Cash is King:** While Jakarta is digital, the \"ojeks\" (motorcycle '\n",
      " 'taxis) and small warungs in Sentul or Pari Island still prefer cash.\\n'\n",
      " '3.  **App Savvy:** Use the **Access by KAI** app to check KRL schedules and '\n",
      " '**Grab/Gojek** to estimate transport costs before you leave.\\n'\n",
      " '\\n'\n",
      " '**My top pick?** If you want to feel like you actually left the city, go to '\n",
      " '**Sentul**. The fresh air and the dip in the cold river water will reset '\n",
      " 'your brain for Monday!')\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# No Tools, Using Chat Models"
   ],
   "metadata": {
    "id": "4jDry7OSyp-Y"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Start building agent without any tools defined\n",
    "import requests\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "agent = init_chat_model(\n",
    "    model = \"gemini-2.5-flash\",\n",
    "    model_provider=\"google_genai\",\n",
    "    temperature = 0.1\n",
    ")\n",
    "\n",
    "# Can be used to determine converstaion chain\n",
    "conversation = [\n",
    "    SystemMessage('You are a seasoned software engineer with 20 years experience using Python'),\n",
    "    HumanMessage('What is Python ?')\n",
    "]\n",
    "\n",
    "\n",
    "# response = agent.invoke(\n",
    "#     'What is \"taxi\" in chinese, can you also give the hanzi pronounciation ?'\n",
    "# )\n",
    "\n",
    "response = agent.invoke(conversation)\n",
    "\n"
   ],
   "metadata": {
    "id": "YSpXeDfcyrgb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from pprint import pprint\n",
    "pprint(response.content)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W6TSkulZ4jEp",
    "outputId": "93fe2799-980c-4f2f-9f5f-331ae0e65fdf"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(\"Alright, let's talk about Python. As someone who's been writing Python code \"\n",
      " \"for two decades, I've seen it evolve from a niche scripting language to one \"\n",
      " 'of the most dominant and versatile programming languages in the world.\\n'\n",
      " '\\n'\n",
      " 'At its core, **Python is a high-level, interpreted, general-purpose '\n",
      " 'programming language.**\\n'\n",
      " '\\n'\n",
      " \"Let's break down what that means and why it's so significant:\\n\"\n",
      " '\\n'\n",
      " '1.  **High-Level:**\\n'\n",
      " \"    *   This means you don't have to worry about low-level details like \"\n",
      " 'managing memory, CPU registers, or other complex hardware interactions. '\n",
      " 'Python handles all of that for you, allowing you to focus on solving the '\n",
      " 'problem at hand. It abstracts away the complexities, making development '\n",
      " 'faster and less error-prone.\\n'\n",
      " '\\n'\n",
      " '2.  **Interpreted:**\\n'\n",
      " '    *   Unlike compiled languages (like C++ or Java, where your code is '\n",
      " 'translated into machine code *before* it runs), Python code is executed line '\n",
      " 'by line by an interpreter at runtime.\\n'\n",
      " '    *   **Pros:** This makes the development cycle much faster (you can run '\n",
      " \"code immediately after writing it), and it's highly portable (the same \"\n",
      " 'Python code can run on Windows, macOS, Linux, etc., as long as an '\n",
      " 'interpreter is available).\\n'\n",
      " '    *   **Cons:** Generally, interpreted languages can be slower than '\n",
      " 'compiled languages for CPU-bound tasks, though this is often mitigated by '\n",
      " \"Python's ability to integrate with highly optimized C/C++ libraries (like \"\n",
      " 'NumPy for numerical operations).\\n'\n",
      " '\\n'\n",
      " '3.  **General-Purpose:**\\n'\n",
      " \"    *   This is one of Python's greatest strengths. It's not specialized for \"\n",
      " 'one particular domain. You can use Python for almost anything:\\n'\n",
      " '        *   **Web Development:** (Django, Flask, FastAPI)\\n'\n",
      " '        *   **Data Science & Machine Learning:** (NumPy, Pandas, '\n",
      " 'Scikit-learn, TensorFlow, PyTorch) - *This is a huge driver of its current '\n",
      " 'popularity.*\\n'\n",
      " '        *   **Automation & Scripting:** (DevOps, system administration, task '\n",
      " 'automation)\\n'\n",
      " '        *   **Desktop GUIs:** (Tkinter, PyQt, Kivy)\\n'\n",
      " '        *   **Scientific & Numeric Computing:** (SciPy)\\n'\n",
      " '        *   **Education:** Its simplicity makes it a fantastic first '\n",
      " 'language.\\n'\n",
      " '        *   **Game Development:** (Pygame)\\n'\n",
      " '        *   **Embedded Systems:** (MicroPython)\\n'\n",
      " '        *   ...and much more.\\n'\n",
      " '\\n'\n",
      " \"### Key Characteristics & Why It's So Popular:\\n\"\n",
      " '\\n'\n",
      " \"*   **Readability & Simplicity:** Python's syntax is designed to be very \"\n",
      " 'clean and readable, often described as \"executable pseudocode.\" It uses '\n",
      " 'whitespace indentation to define code blocks, which enforces a consistent '\n",
      " 'and easy-to-understand style. This makes it easier to learn, write, and '\n",
      " 'maintain.\\n'\n",
      " '*   **\"Batteries Included\" Philosophy:** Python comes with a comprehensive '\n",
      " 'standard library that provides modules and packages for a vast array of '\n",
      " 'tasks, from file I/O and network communication to regular expressions and '\n",
      " 'data compression.\\n'\n",
      " \"*   **Vast Ecosystem & Community:** Beyond the standard library, there's an \"\n",
      " 'enormous ecosystem of third-party libraries and frameworks (available via '\n",
      " \"`pip` on PyPI). Whatever you're trying to do, chances are someone has \"\n",
      " 'already built a Python library for it. This, combined with a massive and '\n",
      " 'active global community, means abundant resources, tutorials, and support.\\n'\n",
      " '*   **Multi-Paradigm:** Python supports multiple programming paradigms, '\n",
      " 'including:\\n'\n",
      " '    *   **Object-Oriented Programming (OOP):** Encapsulation, inheritance, '\n",
      " 'polymorphism.\\n'\n",
      " '    *   **Procedural Programming:** Functions, sequential execution.\\n'\n",
      " '    *   **Functional Programming:** First-class functions, lambda '\n",
      " 'expressions.\\n'\n",
      " \"*   **Dynamically Typed:** You don't need to declare the type of a variable \"\n",
      " 'explicitly (e.g., `x = 10` instead of `int x = 10`). The interpreter infers '\n",
      " 'the type at runtime. This offers flexibility but requires careful testing.\\n'\n",
      " \"*   **Created by Guido van Rossum:** First released in 1991, Python's design \"\n",
      " 'philosophy (often summarized in \"The Zen of Python\") emphasizes simplicity, '\n",
      " 'explicit over implicit, and readability.\\n'\n",
      " '\\n'\n",
      " '### In Summary:\\n'\n",
      " '\\n'\n",
      " 'Python is a powerful, versatile, and user-friendly language that has become '\n",
      " 'a cornerstone in many areas of software development. Its blend of '\n",
      " 'simplicity, a rich ecosystem, and a supportive community makes it an '\n",
      " 'excellent choice for beginners and seasoned professionals alike, enabling '\n",
      " \"rapid development and tackling complex problems across diverse domains. It's \"\n",
      " 'a language that truly empowers developers to build almost anything they can '\n",
      " 'imagine.')\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Combining all together"
   ],
   "metadata": {
    "id": "tiskO0bF_x05"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Start building agent for get weather\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import requests\n",
    "from langchain.agents import create_agent\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "## Setup classess and tools\n",
    "@dataclass\n",
    "class Context:\n",
    "  user_id : str\n",
    "\n",
    "@dataclass\n",
    "class ResponseFormat:\n",
    "  summary : str\n",
    "  temperature_celcius : float\n",
    "  temperature_fahrenheit : float\n",
    "  humidity : float\n",
    "\n",
    "@tool('locate_user',\n",
    "      description=\"\"\"\n",
    "        Get the user's city from the database based on their user_id.\n",
    "        Returns the city name or 'Unknown' if user not found.\n",
    "      \"\"\")\n",
    "def locate_user(runtime: ToolRuntime[Context], user_id: str = None) :\n",
    "\n",
    "  # Can change this to connect to DB instead\n",
    "  user_cities = {\n",
    "        'Cello': 'Bukittinggi',\n",
    "        'Evelyn': 'Banjar Wijaya',\n",
    "        'Parjo': 'Medan'\n",
    "    }\n",
    "\n",
    "  # Use provided user_id or fall back to context user_id\n",
    "  lookup_id = user_id if user_id else runtime.context.user_id\n",
    "\n",
    "  return user_cities.get(lookup_id, 'Unknown')\n",
    "\n",
    "@tool('get_weather',\n",
    "      description=\"\"\"\n",
    "          Get current weather information for a specific city.\n",
    "\n",
    "          Args:\n",
    "              city: Name of the city to get weather for\n",
    "\n",
    "          Returns:\n",
    "              Weather data including temperature and humidity\n",
    "          \"\"\",\n",
    "      return_direct=False)\n",
    "def get_weather(city: str) :\n",
    "  # if city != 'Try Again' :\n",
    "  #   response = requests.get(f'https://wttr.in/{city}?format=j1').json()\n",
    "  # else :\n",
    "    # response = 'City of the user is unknown, can help ask the user to specify it manually in the prompt'\n",
    "    # the above response is not good becauset he the initial prompt is asking \"What is the weather\" and the response doesn't contains weather information at all\n",
    "\n",
    "  if city == 'Unknown':\n",
    "        return {\n",
    "            'error': 'City unknown. Please ask the user to specify their city.',\n",
    "            'status': 'failed'\n",
    "        }\n",
    "\n",
    "  try:\n",
    "      response = requests.get(f'https://wttr.in/{city}?format=j1', timeout=60).json()\n",
    "\n",
    "      return response\n",
    "  except Exception as e:\n",
    "      return {\n",
    "          'error': f'Failed to fetch weather: {str(e)}',\n",
    "          'status': 'failed'\n",
    "      }\n",
    "\n",
    "  return response\n",
    "\n",
    "## Setup LLM model\n",
    "llm = init_chat_model(\n",
    "    model = \"claude-haiku-4-5-20251001\",\n",
    "    # model_provider=\"google_genai\",\n",
    "    temperature = 0.1\n",
    ")\n",
    "\n",
    "checkpointer = InMemorySaver() # to make the LLM remember the past prompt context\n",
    "\n",
    "agent = create_agent(\n",
    "    model = llm,\n",
    "    tools = [get_weather, locate_user],\n",
    "    system_prompt = \"\"\"\n",
    "      You are a helpful weather assistant with a good sense of humour.\n",
    "\n",
    "      When a user asks about weather:\n",
    "      1. If they don't specify a city, use locate_user tool to find their city\n",
    "      2. If the user is not found, politely ask them to specify a city\n",
    "      3. Once you have a city, use get_weather tool to get the weather\n",
    "      4. Present the weather information in a friendly, conversational way\n",
    "\n",
    "      When a user asks for certain user_id:\n",
    "      1. Check whether we have that user_id information using locate_user tool\n",
    "      2. If yes, can ignore the context of user_id you got from the prompting, just use the city from the user_id provided by the user and give the weather information\n",
    "      3. If no, then politely say to the user that we can't find that user_id information and ask whether he want to see other user_id instead or specify the city name\n",
    "\n",
    "      Only use tools when necessary. Don't loop or retry tools unnecessarily.\n",
    "      \"\"\",\n",
    "    context_schema = Context,\n",
    "    # response_format = ResponseFormat, ## can make it run longer because the LLM need to match the raw response to the format semantic\n",
    "    checkpointer = checkpointer\n",
    ")\n",
    "\n",
    "config = {'configurable': {'thread_id': 1}} # to determine the \"session_id\", if this change the previous context is lost\n",
    "\n",
    "response = agent.invoke({\n",
    "    'messages': [\n",
    "        {\n",
    "          'role':'user',\n",
    "          'content':'What is the weather like ?'\n",
    "         }\n",
    "    ]},\n",
    "    config = config,\n",
    "    context = Context(user_id='asd')\n",
    ")\n",
    "\n",
    "print(f'Prompt : {response['messages'][0].content}')\n",
    "print(f'Answer : {response['messages'][-1].content}')\n",
    "\n",
    "response = agent.invoke({\n",
    "    'messages': [\n",
    "        {\n",
    "          'role':'user',\n",
    "          'content':'Oh sorry I am in Berlin'\n",
    "         }\n",
    "    ]},\n",
    "    config = config,\n",
    "    context = Context(user_id='asd')\n",
    ")\n",
    "\n",
    "print(f'')\n",
    "print(f'='*100)\n",
    "print(f'\\nPrompt : {response['messages'][0].content}')\n",
    "print(f'Answer : {response['messages'][-1].content}')\n",
    "\n",
    "response = agent.invoke({\n",
    "    'messages': [\n",
    "        {\n",
    "          'role':'user',\n",
    "          'content':\"Can you get the weather from user_id Cello's city instead\"\n",
    "         }\n",
    "    ]},\n",
    "    config = config,\n",
    "    context = Context(user_id='asd')\n",
    ")\n",
    "\n",
    "print(f'')\n",
    "print(f'='*100)\n",
    "print(f'\\nPrompt : {response['messages'][0].content}')\n",
    "print(f'Answer : {response['messages'][-1].content}')\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t_cCkar31t4G",
    "outputId": "24d485aa-5b5e-4d54-acb1-155fd8abc13a"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Prompt : What is the weather like ?\n",
      "Answer : It looks like I don't have your location on file. Could you please tell me which city you'd like to know the weather for? ðŸŒ¤ï¸\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Prompt : What is the weather like ?\n",
      "Answer : Oops! I'm having a bit of technical trouble fetching the weather data at the moment. It seems my weather service is being a bit temperamental (ironically, given that we're trying to check the temperature! ðŸ˜„).\n",
      "\n",
      "Could you try again in a moment, or alternatively, you could check a weather website directly for Berlin's current conditions. I apologize for the hiccup!\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Prompt : What is the weather like ?\n",
      "Answer : Perfect! Here's the weather for Cello in **Bukittinggi, Indonesia** ðŸŒ\n",
      "\n",
      "**Current Conditions (10:11 PM):**\n",
      "- ðŸŒ«ï¸ **Mist** \n",
      "- Temperature: **19Â°C (67Â°F)**\n",
      "- Humidity: **95%** (quite humid!)\n",
      "- Wind: Light breeze from the west at 4 km/h\n",
      "- Visibility: 2 km\n",
      "\n",
      "**Today's Forecast:**\n",
      "- High: **28Â°C (82Â°F)**\n",
      "- Low: **18Â°C (65Â°F)**\n",
      "- Mostly sunny during the day with some clouds rolling in later\n",
      "- No rain expected today\n",
      "\n",
      "**Tomorrow (Jan 21):**\n",
      "- High: **29Â°C (84Â°F)**\n",
      "- Low: **19Â°C (65Â°F)**\n",
      "- Sunny morning, but watch out for some patchy rain in the afternoon/evening\n",
      "- Humidity will be quite high throughout the day\n",
      "\n",
      "Looks like Cello's got some tropical weather going on! It's warm and humid, with a mix of sunny spells and occasional rain showers. Perfect weather for staying hydrated! ðŸ’§â˜€ï¸\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Using image as input"
   ],
   "metadata": {
    "id": "X35ITwWN_5J6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Start building agent for get weather\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import requests\n",
    "from langchain.agents import create_agent\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "## Tools\n",
    "@tool('search_image')\n",
    "def search_image(description: str) -> str:\n",
    "    \"\"\"Search the web for information about a person based on image description.\n",
    "\n",
    "    Args:\n",
    "        description: Visual description of the person (clothing, setting, etc.)\n",
    "    \"\"\"\n",
    "    # In practice, you'd use Google Image Search API or similar\n",
    "    # For now, return placeholder\n",
    "    return f\"Searched for: {description}\"\n",
    "\n",
    "\n",
    "## Setup LLM model\n",
    "llm = init_chat_model(\n",
    "    model = \"claude-haiku-4-5-20251001\",\n",
    "    # model_provider=\"google_genai\",\n",
    "    temperature = 0.1\n",
    ")\n",
    "\n",
    "checkpointer = InMemorySaver() # to make the LLM remember the past prompt context\n",
    "\n",
    "agent = create_agent(\n",
    "    model = llm,\n",
    "    tools = [search_image],\n",
    "    system_prompt = \"\"\"\n",
    "      You are a helpful assistant that can identify people in images.\n",
    "\n",
    "      When given an image:\n",
    "      1. First, describe what you see (physical features, clothing, setting, text in image)\n",
    "      2. If there are context clues (jerseys, uniforms, logos), use those\n",
    "      3. Use the search_image tool to find information based on visual clues\n",
    "      4. Provide your best identification based on available information\n",
    "\n",
    "      Be helpful and thorough in your analysis.\n",
    "      \"\"\",\n",
    "    # context_schema = Context,\n",
    "    # response_format = ResponseFormat, ## can make it run longer because the LLM need to match the raw response to the format semantic\n",
    "    checkpointer = checkpointer\n",
    ")\n",
    "\n",
    "config = {'configurable': {'thread_id': 1}} # to determine the \"session_id\", if this change the previous context is lost\n",
    "\n",
    "response = agent.invoke({\n",
    "    'messages': [\n",
    "        {\n",
    "          'role':'user',\n",
    "          'content': [\n",
    "              {'type':'text', 'text':'Can you identified who is the person in the image, he is a musician with main genre of jazz rap'},\n",
    "              {\n",
    "                  'type':'image',\n",
    "                  'url':'https://www.rollingstone.com/wp-content/uploads/2023/05/MCKINLEY-DIXON_001.jpg'\n",
    "              }\n",
    "          ]\n",
    "         }\n",
    "    ]},\n",
    "    config = config,\n",
    ")\n",
    "\n",
    "print(f'Prompt : {response['messages'][0].content}')\n",
    "print(f'Answer : {response['messages'][-1].content}')\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YT2HDRsG7Nim",
    "outputId": "d326f06e-ff4a-488d-fb43-7a7970fad78e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Prompt : [{'type': 'text', 'text': 'Can you identified who is the person in the image, he is a musician with main genre of jazz rap'}, {'type': 'image', 'url': 'https://www.rollingstone.com/wp-content/uploads/2023/05/MCKINLEY-DIXON_001.jpg'}]\n",
      "Answer : Based on the visual characteristics in the image - the braided hair, nose piercing, facial hair, and the professional styling - combined with your mention that this is a jazz rap musician, this appears to be **Saba**, a prominent jazz rap artist known for his innovative blend of jazz and hip-hop. He's recognized for his distinctive style, including his braided hair and artistic aesthetic.\n",
      "\n",
      "However, without additional context clues like text, logos, or other identifying markers in the image itself, I cannot be 100% certain. If you could confirm or provide additional details, I'd be happy to verify the identification further.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Start building agent for get weather\n",
    "from dataclasses import dataclass\n",
    "from base64 import b64encode\n",
    "\n",
    "import requests\n",
    "from langchain.agents import create_agent\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "## Tools\n",
    "@tool('search_image')\n",
    "def search_image(description: str) -> str:\n",
    "    \"\"\"Search the web for information about a person based on image description.\n",
    "\n",
    "    Args:\n",
    "        description: Visual description of the person (clothing, setting, etc.)\n",
    "    \"\"\"\n",
    "    # In practice, you'd use Google Image Search API or similar\n",
    "    # For now, return placeholder\n",
    "    return f\"Searched for: {description}\"\n",
    "\n",
    "\n",
    "## Setup LLM model\n",
    "llm = init_chat_model(\n",
    "    model = \"claude-haiku-4-5-20251001\",\n",
    "    # model_provider=\"google_genai\",\n",
    "    temperature = 0.1\n",
    ")\n",
    "\n",
    "checkpointer = InMemorySaver() # to make the LLM remember the past prompt context\n",
    "\n",
    "agent = create_agent(\n",
    "    model = llm,\n",
    "    tools = [search_image],\n",
    "    system_prompt = \"\"\"\n",
    "      You are a helpful assistant that can identify people in images.\n",
    "\n",
    "      When given an image:\n",
    "      1. First, describe what you see (physical features, clothing, setting, text in image)\n",
    "      2. If there are context clues (jerseys, uniforms, logos), use those\n",
    "      3. Use the search_image tool to find information based on visual clues\n",
    "      4. Provide your best identification based on available information\n",
    "\n",
    "      Be helpful and thorough in your analysis.\n",
    "      \"\"\",\n",
    "    # context_schema = Context,\n",
    "    # response_format = ResponseFormat, ## can make it run longer because the LLM need to match the raw response to the format semantic\n",
    "    checkpointer = checkpointer\n",
    ")\n",
    "\n",
    "config = {'configurable': {'thread_id': 1}} # to determine the \"session_id\", if this change the previous context is lost\n",
    "\n",
    "response = agent.invoke({\n",
    "    'messages': [\n",
    "        {\n",
    "          'role':'user',\n",
    "          'content': [\n",
    "              {'type':'text', 'text':'Can you identified who is the person in the image'},\n",
    "              {\n",
    "                  'type':'image',\n",
    "                  'base64':b64encode(open('sga.jpeg', 'rb').read()).decode(),\n",
    "                  'mime_type':'image/jpeg'\n",
    "              }\n",
    "          ]\n",
    "         }\n",
    "    ]},\n",
    "    config = config,\n",
    ")\n",
    "\n",
    "print(f'Prompt : {response['messages'][0].content}')\n",
    "print(f'Answer : {response['messages'][-1].content}')\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u9mo7fC7FKX6",
    "outputId": "493d9916-7380-4c74-d766-38fc0d143a13"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Prompt : [{'type': 'text', 'text': 'Can you identified who is the person in the image'}, {'type': 'image', 'base64': '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', 'mime_type': 'image/jpeg'}]\n",
      "Answer : Based on the visual evidence in the image:\n",
      "\n",
      "**This appears to be Shai Gilgeous-Alexander**, who wears number 2 for the Oklahoma City Thunder. The blue Thunder jersey with number 2, combined with the player's athletic build and playing style visible in the photo, matches Shai Gilgeous-Alexander's profile. He is a star guard for the Thunder and one of the team's primary ball handlers.\n",
      "\n",
      "The image shows him in action during an NBA game, dribbling the basketball in the Thunder's home blue uniform.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Start building agent for get weather\n",
    "from dataclasses import dataclass\n",
    "from base64 import b64encode\n",
    "\n",
    "import requests\n",
    "from langchain.agents import create_agent\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "## Tools\n",
    "@tool('search_image')\n",
    "def search_image(description: str) -> str:\n",
    "    \"\"\"Search the web for information about a person based on image description.\n",
    "\n",
    "    Args:\n",
    "        description: Visual description of the person (clothing, setting, etc.)\n",
    "    \"\"\"\n",
    "    # In practice, you'd use Google Image Search API or similar\n",
    "    # For now, return placeholder\n",
    "    return f\"Searched for: {description}\"\n",
    "\n",
    "\n",
    "## Setup LLM model\n",
    "llm = init_chat_model(\n",
    "    model = \"claude-haiku-4-5-20251001\",\n",
    "    # model_provider=\"google_genai\",\n",
    "    temperature = 0.1\n",
    ")\n",
    "\n",
    "checkpointer = InMemorySaver() # to make the LLM remember the past prompt context\n",
    "\n",
    "agent = create_agent(\n",
    "    model = llm,\n",
    "    tools = [search_image],\n",
    "    system_prompt = \"\"\"\n",
    "      You are a helpful assistant that can identify people in images.\n",
    "\n",
    "      When given an image:\n",
    "      1. First, describe what you see (physical features, clothing, setting, text in image)\n",
    "      2. If there are context clues (jerseys, uniforms, logos), use those\n",
    "      3. Use the search_image tool to find information based on visual clues\n",
    "      4. Provide your best identification based on available information\n",
    "\n",
    "      Be helpful and thorough in your analysis.\n",
    "      \"\"\",\n",
    "    # context_schema = Context,\n",
    "    # response_format = ResponseFormat, ## can make it run longer because the LLM need to match the raw response to the format semantic\n",
    "    checkpointer = checkpointer\n",
    ")\n",
    "\n",
    "config = {'configurable': {'thread_id': 1}} # to determine the \"session_id\", if this change the previous context is lost\n",
    "\n",
    "message = HumanMessage(\n",
    "    content=[\n",
    "      {'type':'text', 'text':'Can you identified who is the person in the image'},\n",
    "      {\n",
    "          'type':'image',\n",
    "          'base64':b64encode(open('sga.jpeg', 'rb').read()).decode(),\n",
    "          'mime_type':'image/jpeg'\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [message]},\n",
    "    config = config,\n",
    ")\n",
    "\n",
    "print(f'Prompt : {response['messages'][0].content}')\n",
    "print(f'Answer : {response['messages'][-1].content}')\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EjQDMW8rSOAI",
    "outputId": "03b0401d-538d-4684-8cb5-7956a0adf56a"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Prompt : [{'type': 'text', 'text': 'Can you identified who is the person in the image'}, {'type': 'image', 'base64': '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', 'mime_type': 'image/jpeg'}]\n",
      "Answer : Based on the visual evidence in the image:\n",
      "\n",
      "**This appears to be Shai Gilgeous-Alexander**, who wears number 2 for the Oklahoma City Thunder. The blue Thunder jersey with number 2, combined with the player's athletic build and playing style visible in the photo, matches Shai Gilgeous-Alexander's profile. He is a star guard for the Thunder and one of the team's primary ball handlers.\n",
      "\n",
      "However, if you could confirm or provide additional context, I can verify this identification with certainty.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RAG Example"
   ],
   "metadata": {
    "id": "ABTpAHPEbY4p"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# initiate embeddings\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-3-small')\n",
    "\n",
    "texts = [\n",
    "    'Apple makes very good computers',\n",
    "    'I believe Apple is innovative',\n",
    "    'I love apples',\n",
    "    'I enjoy oranges',\n",
    "    'I like Lenovo Thinkpads',\n",
    "    'I think pears taste very good'\n",
    "]\n",
    "\n",
    "# initiate vector store\n",
    "vector_store = FAISS.from_texts(texts, embedding=embeddings)\n",
    "\n",
    "for i in vector_store.similarity_search(\"I want to drink juice\", k=5) :\n",
    "  print(i)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xQmveD4NasM7",
    "outputId": "01d0714a-4995-411b-bb97-3b05f6244ce0"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "page_content='I enjoy oranges'\n",
      "page_content='I love apples'\n",
      "page_content='I think pears taste very good'\n",
      "page_content='I believe Apple is innovative'\n",
      "page_content='I like Lenovo Thinkpads'\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Start building agent for get weather\n",
    "from dataclasses import dataclass\n",
    "from base64 import b64encode\n",
    "\n",
    "import requests\n",
    "from langchain.agents import create_agent\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langchain_core.tools import create_retriever_tool\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "## Initiate knowledge base\n",
    "texts = [\n",
    "    'I like to read medium article',\n",
    "    'I like to watch tutorial in youtube',\n",
    "    \"I don't like watch video from Indian guys as I find it hard to understand the dialect\",\n",
    "    'I want to learn LLM Agent',\n",
    "    'I want to explore cafe in BSD',\n",
    "    'I want to learn about causal impact modelling'\n",
    "]\n",
    "\n",
    "## Initiate vector store\n",
    "vector_store = FAISS.from_texts(texts, embedding=embeddings)\n",
    "\n",
    "## Tools\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_kwargs={'k':3}\n",
    "    )\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    name='knowledge_base_search',\n",
    "    description=\"\"\"\n",
    "      The base knowledge that contains my preference for stuff\n",
    "\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "@tool('search_for_information')\n",
    "def search_for_information(knowledge_user_preference: str) -> str:\n",
    "    \"\"\"Search the web, medium, youtube to get the information that can be a recommendation for the thing's that user interested to learn or watch\n",
    "\n",
    "    Args:\n",
    "        knowledge_user_preference: user preference\n",
    "    \"\"\"\n",
    "    # In practice, you'd use Google Image Search API or similar\n",
    "    # For now, return placeholder\n",
    "    return f\"Based on your preference for {knowledge_user_preference} we recommend\"\n",
    "\n",
    "## Setup LLM model\n",
    "llm = init_chat_model(\n",
    "    model = \"claude-haiku-4-5-20251001\",\n",
    "    # model_provider=\"google_genai\",\n",
    "    temperature = 0.1\n",
    ")\n",
    "\n",
    "checkpointer = InMemorySaver() # to make the LLM remember the past prompt context\n",
    "\n",
    "agent = create_agent(\n",
    "    model = llm,\n",
    "    tools = [retriever_tool, search_for_information],\n",
    "    system_prompt = \"\"\"\n",
    "      You are a helpful assistant, that can stored, retrieve, and give recommendation based on the user preference.\n",
    "\n",
    "      When ask about the user preference:\n",
    "      1. Call the knowledge_base_search tools to retrieve context, then answer succintly\n",
    "      2. Maybe you need to use it multiple times before answering\n",
    "\n",
    "      When ask about the recommendation to acommodate the user preference:\n",
    "      1. Call the knowledge_base_search tools to retrieve context, then answer succintly\n",
    "      2. Use the search_for_information tools to find information that you can recommend, according to the user preference context that you got from the previous step\n",
    "\n",
    "      Be helpful and thorough in your analysis.\n",
    "      \"\"\",\n",
    "    # context_schema = Context,\n",
    "    # response_format = ResponseFormat, ## can make it run longer because the LLM need to match the raw response to the format semantic\n",
    "    checkpointer = checkpointer\n",
    ")\n",
    "\n",
    "config = {'configurable': {'thread_id': 1}} # to determine the \"session_id\", if this change the previous context is lost\n",
    "\n",
    "message = HumanMessage(\n",
    "    content=[\n",
    "      {'type':'text', 'text':'Can you know what is the thing that I like, dislike, and want to learn'},\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [message]},\n",
    "    config = config,\n",
    ")\n",
    "\n",
    "print(f'Prompt : {response['messages'][0].content}')\n",
    "print(f'Answer : {response['messages'][-1].content}')\n",
    "\n",
    "\n",
    "message = HumanMessage(\n",
    "    content=[\n",
    "      {'type':'text', 'text':'Based on my preference, can you recommend me any source that I can use ?'},\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [message]},\n",
    "    config = config,\n",
    ")\n",
    "\n",
    "print('')\n",
    "print('='*100)\n",
    "print(f'\\nPrompt : {response['messages'][0].content}')\n",
    "print(f'Answer : {response['messages'][-1].content}')\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AFif0fT-hrjQ",
    "outputId": "3c698a8a-b448-4ef2-fcfc-618b8209319d"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Prompt : [{'type': 'text', 'text': 'Can you know what is the thing that I like, dislike, and want to learn'}]\n",
      "Answer : Based on your knowledge base, here's what I found about your preferences:\n",
      "\n",
      "**Things You Like:**\n",
      "- Reading Medium articles\n",
      "- Watching tutorials on YouTube\n",
      "- Exploring cafes in BSD (Bumi Serpong Damai)\n",
      "\n",
      "**Things You Dislike:**\n",
      "- Watching videos from Indian creators, as you find the dialect hard to understand\n",
      "\n",
      "**Things You Want to Learn:**\n",
      "- LLM Agent (Large Language Model Agent)\n",
      "- Causal Impact Modelling\n",
      "\n",
      "So in summary, you prefer learning through written content (Medium articles) and video tutorials (YouTube), but prefer non-Indian creators. You're interested in advanced topics like LLM Agents and causal impact modelling, and you also enjoy exploring local cafes in the BSD area. Would you like me to find specific recommendations for learning LLM Agents or causal impact modelling based on these preferences?\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Prompt : [{'type': 'text', 'text': 'Can you know what is the thing that I like, dislike, and want to learn'}]\n",
      "Answer : Based on your preferences, here are my recommendations:\n",
      "\n",
      "**For Learning LLM Agent:**\n",
      "- **YouTube Channels**: Look for tutorials from creators like:\n",
      "  - DeepLearning.AI (Andrew Ng's team) - excellent for LLM fundamentals and agents\n",
      "  - Hugging Face - official tutorials on LLM agents and transformers\n",
      "  - Jeremy Howard (fast.ai) - practical deep learning content\n",
      "  \n",
      "- **Medium Articles**: Search for:\n",
      "  - Articles on \"Building LLM Agents\" or \"LLM Agent Architecture\"\n",
      "  - Posts about \"ReAct\" (Reasoning + Acting) frameworks\n",
      "  - Guides on integrating LLMs with tools and APIs\n",
      "\n",
      "**For Learning Causal Impact Modelling:**\n",
      "- **YouTube Channels**: \n",
      "  - StatQuest with Josh Starmer - excellent for statistical concepts including causal inference\n",
      "  - Causal Data Science - dedicated to causal inference methods\n",
      "  - 3Blue1Brown - for mathematical foundations\n",
      "  \n",
      "- **Medium Articles**:\n",
      "  - Search for \"Causal Impact Analysis\" or \"Causal Inference in Python\"\n",
      "  - Articles about Bayesian structural time-series models\n",
      "  - Posts on using Google's CausalImpact library\n",
      "\n",
      "**Why these sources match your preference:**\n",
      "âœ… Available on YouTube and Medium (your preferred platforms)\n",
      "âœ… Non-Indian creators with clear English dialects\n",
      "âœ… Tutorial-focused and practical content\n",
      "âœ… Suitable for advanced learners\n",
      "\n",
      "Would you like me to help you find more specific resources or channels for either topic?\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build a simple agent that can get input from PDF and retrieve information based on user inquiry"
   ],
   "metadata": {
    "id": "X8Zw2y7H-R-q"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import requests\n",
    "from langchain.agents import create_agent\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langchain_core.tools import create_retriever_tool\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Read the pdf\n",
    "loader = PDFPlumberLoader('07 - Beyond Confounders â€” Causal Inference for the Brave and True.PDF')\n",
    "documents = loader.load()\n",
    "\n",
    "## Split the data to make it into chunk of text as the knowlede base\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "knowledge_base = text_splitter.split_documents(documents)\n",
    "\n",
    "## Initiate vector store\n",
    "vector_store = FAISS.from_documents(knowledge_base, embedding=embeddings)\n",
    "\n",
    "## Tools\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_kwargs={'k':3}\n",
    "    )\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    name='knowledge_base_search',\n",
    "    description=\"\"\"\n",
    "      The base knowledge that contains the content of the documents\n",
    "\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "@tool('search_for_information')\n",
    "def search_for_information(content: str) -> str:\n",
    "    \"\"\"Search the web to get the additional information that might not be provided in the knowledge base\n",
    "\n",
    "    Args:\n",
    "        content: The content of the document that have been provided or asked by the user\n",
    "    \"\"\"\n",
    "    # In practice, you'd use Google Image Search API or similar\n",
    "    # For now, return placeholder\n",
    "    return f\"Based on your inquiry regarding {content}, here is the information we can provide\"\n",
    "\n",
    "## Setup LLM model\n",
    "llm = init_chat_model(\n",
    "    model = \"claude-haiku-4-5-20251001\",\n",
    "    # model_provider=\"google_genai\",\n",
    "    temperature = 0.1\n",
    ")\n",
    "\n",
    "checkpointer = InMemorySaver() # to make the LLM remember the past prompt context\n",
    "\n",
    "agent = create_agent(\n",
    "    model = llm,\n",
    "    tools = [retriever_tool],\n",
    "    system_prompt = \"\"\"\n",
    "      You are a helpful assistant, that can read through the whole pdf document's and help the user get information from there.\n",
    "      You might be ask to summarize the content of the document, and also provide additional source learn mode about specific content\n",
    "\n",
    "      When ask about the content of the document:\n",
    "      1. Call the knowledge_base_search tools to retrieve context, then answer succintly\n",
    "      2. Maybe you need to use it multiple times before answering\n",
    "\n",
    "      When ask about additional information about certain content from the document:\n",
    "      1. Call the knowledge_base_search tools to retrieve context, then answer succintly\n",
    "      2. Use search_for_information tools if the user is asking for additional information / source for them to read\n",
    "=\n",
    "      \"\"\",\n",
    "    # context_schema = Context,\n",
    "    # response_format = ResponseFormat, ## can make it run longer because the LLM need to match the raw response to the format semantic\n",
    "    checkpointer = checkpointer\n",
    ")\n",
    "\n",
    "config = {'configurable': {'thread_id': 1}} # to determine the \"session_id\", if this change the previous context is lost\n",
    "\n",
    "message = HumanMessage(\n",
    "    content=[\n",
    "      {'type':'text', 'text':'Can you summarize the content of the documents for me ?'},\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [message]},\n",
    "    config = config,\n",
    ")\n",
    "\n",
    "print(f'Prompt : {response['messages'][0].content}')\n",
    "print(f'Answer : {response['messages'][-1].content}')\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RhdKHAne9rGV",
    "outputId": "e5d6f936-76a1-458b-d5a0-844127f0d4c1"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:pdfminer.pdffont:Could not get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING:pdfminer.pdffont:Could not get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING:pdfminer.pdffont:Could not get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING:pdfminer.pdffont:Could not get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING:pdfminer.pdffont:Could not get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING:pdfminer.pdffont:Could not get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING:pdfminer.pdffont:Could not get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING:pdfminer.pdffont:Could not get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING:pdfminer.pdffont:Could not get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING:pdfminer.pdffont:Could not get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING:pdfminer.pdffont:Could not get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING:pdfminer.pdffont:Could not get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING:pdfminer.pdffont:Could not get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING:pdfminer.pdffont:Could not get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING:pdfminer.pdffont:Could not get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "WARNING:pdfminer.pdffont:Could not get FontBBox from font descriptor because None cannot be parsed as 4 floats\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Prompt : [{'type': 'text', 'text': 'Can you summarize the content of the documents for me ?'}]\n",
      "Answer : ## Summary of the Documents\n",
      "\n",
      "Based on my search through the documents, here's a comprehensive summary:\n",
      "\n",
      "### **Document Title & Purpose**\n",
      "**\"Causal Inference for the Brave and True\"** - An open-source educational material on causal inference and the statistics of science, written by Matheus Facure Alves. The book uses free software and Python, aiming to be accessible both monetarily and intellectually.\n",
      "\n",
      "### **Main Content Focus**\n",
      "The documents focus on **Chapter 07: Beyond Confounders**, which explores the nuanced topic of variable selection in causal inference models. The key themes include:\n",
      "\n",
      "#### **1. Good Controls**\n",
      "- Adding controls to regression models helps identify causal effects\n",
      "- Variables that are good predictors of the outcome should be included, even if they don't predict the treatment\n",
      "- This reduces variance and increases the likelihood of finding statistically significant results\n",
      "\n",
      "#### **2. Mostly Harmful Controls**\n",
      "- Adding variables that predict only the treatment (but not the outcome) is counterproductive\n",
      "- These variables reduce treatment variability, making it harder to identify causal effects\n",
      "- In the big data era, blindly adding 1000+ variables is unnecessary and detrimental\n",
      "\n",
      "#### **3. Bad Controls - Selection Bias**\n",
      "- Selection bias occurs when controlling for variables that are:\n",
      "  - In the causal path between treatment and outcome (mediators)\n",
      "  - Common effects of both treatment and outcome\n",
      "- This bias can occur even in randomized experiments\n",
      "- Examples include filtering for participants only or adding dummies for outcomes\n",
      "\n",
      "### **Key Takeaway**\n",
      "The document emphasizes a practical rule: **Always include confounders and good predictors of the outcome; always exclude variables that only predict treatment, mediators, or common effects.**\n",
      "\n",
      "Would you like me to dive deeper into any specific section?\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "message = HumanMessage(\n",
    "    content=[\n",
    "      {'type':'text', 'text':'I want to deep dive more about the selection bias part, can you elaborate it and recommend other source to learn about it ?'},\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [message]},\n",
    "    config = config,\n",
    ")\n",
    "\n",
    "print(f'Prompt : {response['messages'][0].content}')\n",
    "print(f'Answer : {response['messages'][-1].content}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cVIYi8tTb3z8",
    "outputId": "a1591b9b-670a-461a-b78f-713083d5912e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Prompt : [{'type': 'text', 'text': 'Can you summarize the content of the documents for me ?'}]\n",
      "Answer : Perfect! Now I have comprehensive information. Let me provide you with a detailed deep dive on selection bias:\n",
      "\n",
      "## **Deep Dive: Selection Bias**\n",
      "\n",
      "### **What is Selection Bias?**\n",
      "\n",
      "Selection bias occurs when you **control for (include in your model) a variable that is either:**\n",
      "1. **A mediator** - a variable that lies in the causal path between treatment and outcome (T â†’ X â†’ Y)\n",
      "2. **A collider/common effect** - a variable that is caused by both the treatment and the outcome (T â†’ X â† Y)\n",
      "\n",
      "This is fundamentally different from **confounding bias**, which comes from failing to control for a common cause (X â†’ T and X â†’ Y).\n",
      "\n",
      "### **Why is Selection Bias So Dangerous?**\n",
      "\n",
      "The document emphasizes several critical points:\n",
      "\n",
      "1. **It's Pervasive and Hard to Spot** - Selection bias is so common that it's often introduced by well-intentioned but misguided practices. It appears \"underneath some supposedly clever idea, making it even harder to uncover.\"\n",
      "\n",
      "2. **Randomization Cannot Fix It** - Unlike confounding bias, which randomization can eliminate, selection bias can occur **even in perfectly randomized experiments**. This is crucial: having random assignment doesn't protect you from selection bias if you control for the wrong variables.\n",
      "\n",
      "3. **It Requires Practice to Avoid** - The document states: \"Spotting and avoiding selection bias requires more practice than skill.\"\n",
      "\n",
      "---\n",
      "\n",
      "### **Real-World Examples from the Document**\n",
      "\n",
      "#### **Example 1: Hospital Treatment Study**\n",
      "\n",
      "**The Setup:**\n",
      "- Patients are randomly assigned to treatment (drug) or control (placebo)\n",
      "- Outcome: days in hospital\n",
      "- Variables: treatment, severity, hospital\n",
      "\n",
      "**The Problem:**\n",
      "When you run a simple regression of days on treatment, you get a **positive coefficient** (treatment increases hospital days). This seems counterintuitive!\n",
      "\n",
      "**Why This Happens:**\n",
      "- Severity causes both hospital assignment AND days in hospital\n",
      "- Hospital 1 treats more severe cases and gives 90% drug\n",
      "- Hospital 2 treats less severe cases and gives 10% drug\n",
      "- When you look at both hospitals together, the untreated group has more patients from Hospital 2 (less severe), making them appear to have better outcomes\n",
      "\n",
      "**The Causal Graph:**\n",
      "```\n",
      "Severity â†’ Hospital â†’ Treatment\n",
      "   â†“\n",
      "  Days\n",
      "```\n",
      "\n",
      "**The Solution:**\n",
      "Control for severity (the confounder), NOT hospital. Once you control for severity, hospital becomes irrelevant because it no longer predicts the outcome.\n",
      "\n",
      "**What NOT to do:**\n",
      "If you control for hospital (which only causes treatment, not the outcome), you introduce selection bias and get a biased estimate.\n",
      "\n",
      "---\n",
      "\n",
      "#### **Example 2: Collections Email Campaign**\n",
      "\n",
      "**The Setup:**\n",
      "- Email is randomly assigned to customers\n",
      "- Outcome: payments made\n",
      "- Variables: email, opened, agreement, credit_limit, risk_score\n",
      "\n",
      "**The Causal Chain:**\n",
      "```\n",
      "Email â†’ Opened â†’ Agreement â†’ Payments\n",
      "```\n",
      "\n",
      "**The Problem:**\n",
      "If you control for \"opened\" or \"agreement\" in your model, you introduce selection bias because:\n",
      "- These variables are **caused by** the treatment (email)\n",
      "- They lie in the causal path from treatment to outcome\n",
      "- Controlling for them blocks the effect of email on payments\n",
      "\n",
      "**Why This Matters:**\n",
      "- You can't open an email you didn't receive\n",
      "- Agreement only counts negotiations that happened AFTER the email was sent\n",
      "- These are mediators, not confounders\n",
      "\n",
      "---\n",
      "\n",
      "#### **Example 3: Debt Payment Dummy (COP - Conditional on Participation)**\n",
      "\n",
      "**The Problem:**\n",
      "When estimating the effect of a collections strategy on payments, researchers sometimes add a dummy variable for \"paying the entire debt\" or filter to only include customers who made any payment.\n",
      "\n",
      "**Why This Introduces Bias:**\n",
      "When you filter to only customers who paid (Y > 0), you're conditioning on the outcome. This creates a selection problem:\n",
      "\n",
      "**Mathematical Breakdown:**\n",
      "The document shows:\n",
      "```\n",
      "E[Y|Y>0, T=1] - E[Y|Y>0, T=0] = Causal Effect + Selection Bias\n",
      "```\n",
      "\n",
      "Where:\n",
      "- **Causal Effect** = E[Yâ‚ - Yâ‚€ | Yâ‚ > 0] (effect on those who would participate)\n",
      "- **Selection Bias** = E[Yâ‚€ | Yâ‚ > 0] - E[Yâ‚€ | Yâ‚€ > 0]\n",
      "\n",
      "**The Intuition:**\n",
      "- Customers who pay when treated might be different from those who pay without treatment\n",
      "- Rich customers pay regardless of treatment\n",
      "- Frugal customers only pay if treated\n",
      "- When you filter to only payers, you're comparing \"rich + frugal\" (treated) vs \"rich only\" (untreated)\n",
      "- This creates a negative bias because rich customers spend more than frugal ones\n",
      "\n",
      "---\n",
      "\n",
      "### **The Golden Rule**\n",
      "\n",
      "**Always:**\n",
      "- âœ… Include confounders (common causes of T and Y)\n",
      "- âœ… Include good predictors of the outcome Y (even if they don't predict T)\n",
      "\n",
      "**Never:**\n",
      "- âŒ Control for mediators (variables in the causal path T â†’ X â†’ Y)\n",
      "- âŒ Control for colliders/common effects (variables caused by both T and Y)\n",
      "- âŒ Control for variables that only predict T but not Y\n",
      "- âŒ Filter or condition on the outcome\n",
      "\n",
      "---\n",
      "\n",
      "## **Recommended Sources to Learn More**\n",
      "\n",
      "Based on the references mentioned in the document, here are the authoritative sources:\n",
      "\n",
      "### **1. \"Causal Inference: The Mixtape\" by Scott Cunningham**\n",
      "- **Focus:** Practical causal inference with accessible explanations\n",
      "- **Why:** Great for understanding selection bias with intuitive examples\n",
      "- **Link:** https://mixtape.scunning.com/\n",
      "\n",
      "### **2. \"Mostly Harmless Econometrics\" by Joshua Angrist & JÃ¶rn-Steffen Pischke**\n",
      "- **Focus:** Econometric methods for causal inference\n",
      "- **Why:** The document explicitly credits this as foundational; covers confounding and selection bias in depth\n",
      "- **Key Chapters:** Chapters on regression and causal identification\n",
      "\n",
      "### **3. \"Mastering 'Metrics\" by Joshua Angrist & JÃ¶rn-Steffen Pischke**\n",
      "- **Focus:** More accessible version of econometric causal inference\n",
      "- **Why:** Excellent for understanding when to include/exclude variables\n",
      "\n",
      "### **4. \"Causal Inference: The Book\" by Miguel Hernan & Jamie Robins**\n",
      "- **Focus:** Comprehensive treatment of causal inference theory\n",
      "- **Why:** The document author calls this their \"trustworthy companion in the most thorny causal questions\"\n",
      "- **Key Concept:** Excellent on collider bias and d-separation\n",
      "- **Link:** https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/\n",
      "\n",
      "### **5. Pearl's Causal Inference Framework**\n",
      "- **Focus:** Graphical models and d-separation\n",
      "- **Why:** Provides the theoretical foundation for understanding why controlling for colliders creates bias\n",
      "- **Key Concept:** d-separation rules explain when variables are independent\n",
      "\n",
      "---\n",
      "\n",
      "## **Key Takeaway**\n",
      "\n",
      "Selection bias is one of the most insidious problems in causal inference because:\n",
      "1. It can occur even with perfect randomization\n",
      "2. It's often introduced by seemingly reasonable practices\n",
      "3. It requires understanding causal graphs and variable relationships\n",
      "4. The solution is NOT to add more controls, but to be strategic about which variables to include\n",
      "\n",
      "The best defense is to **think carefully about your causal graph before running any analysis** and ask: \"Does this variable cause the treatment, the outcome, or both?\"\n",
      "\n",
      "Would you like me to explain any specific aspect further, such as d-separation, collider bias, or how to draw causal graphs?\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Middleware"
   ],
   "metadata": {
    "id": "oZ9CHgJ4lxBv"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Change the system prompt based on the user role"
   ],
   "metadata": {
    "id": "g3noxGKEpx5e"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import requests\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import ModelRequest, ModelResponse, dynamic_prompt\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langchain_core.tools import create_retriever_tool\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "## Tools and Context\n",
    "@dataclass\n",
    "class Context:\n",
    "  user_role : str\n",
    "\n",
    "@dynamic_prompt\n",
    "def user_role_prompt(request: ModelRequest, user_role: str = None) -> str:\n",
    "  base_prompt = 'You are a helpful and very concise assistant.'\n",
    "\n",
    "  # Can change this to connect to DB instead\n",
    "  dict_role = {\n",
    "        'expert': f'{base_prompt} Provide detailed technical response',\n",
    "        'beginner': f'{base_prompt} Keep it simple and basic',\n",
    "        'child': f'{base_prompt} Explained it like if you were teaching it to a child'\n",
    "    }\n",
    "\n",
    "  # Use provided user_id or fall back to context user_id\n",
    "  try :\n",
    "    lookup_id = user_role if user_role else request.runtime.context.user_role\n",
    "  except :\n",
    "    lookup_id = 'unknown'\n",
    "\n",
    "  return dict_role.get(lookup_id, base_prompt)\n",
    "\n",
    "\n",
    "## Setup LLM model\n",
    "llm = init_chat_model(\n",
    "    model = \"claude-haiku-4-5-20251001\",\n",
    "    # model_provider=\"google_genai\",\n",
    "    temperature = 0.1\n",
    ")\n",
    "\n",
    "checkpointer = InMemorySaver() # to make the LLM remember the past prompt context\n",
    "\n",
    "agent = create_agent(\n",
    "    model = llm,\n",
    "    middleware = [user_role_prompt],\n",
    "    system_prompt = \"\"\"\n",
    "      You are a helpful assistant, that can read through the whole pdf document's and help the user get information from there.\n",
    "      You might be ask to summarize the content of the document, and also provide additional source learn mode about specific content\n",
    "\n",
    "      When ask about the content of the document:\n",
    "      1. Call the knowledge_base_search tools to retrieve context, then answer succintly\n",
    "      2. Maybe you need to use it multiple times before answering\n",
    "\n",
    "      When ask about additional information about certain content from the document:\n",
    "      1. Call the knowledge_base_search tools to retrieve context, then answer succintly\n",
    "      2. Use search_for_information tools if the user is asking for additional information / source for them to read\n",
    "=\n",
    "      \"\"\",\n",
    "    context_schema = Context,\n",
    "    # response_format = ResponseFormat, ## can make it run longer because the LLM need to match the raw response to the format semantic\n",
    "    checkpointer = checkpointer\n",
    ")\n",
    "\n",
    "config = {'configurable': {'thread_id': 1}} # to determine the \"session_id\", if this change the previous context is lost\n",
    "\n",
    "message = HumanMessage(\n",
    "    content=[\n",
    "      {'type':'text', 'text':'Explain simpson paradox in statistics'},\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [message]},\n",
    "    config = config,\n",
    "    context = Context(user_role='child')\n",
    ")\n",
    "\n",
    "print(f'Prompt : {response['messages'][0].content}')\n",
    "print(f'Answer : {response['messages'][-1].content}')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XvgyVVbGduu9",
    "outputId": "04dbad4d-5f51-4a9b-d0eb-1f5f7c334ac2"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Prompt : [{'type': 'text', 'text': 'Explain simpson paradox in statistics'}]\n",
      "Answer : # Simpson's Paradox - Simple Explanation\n",
      "\n",
      "Imagine you're comparing two ice cream shops:\n",
      "\n",
      "**Shop A vs Shop B - Who sells more chocolate ice cream?**\n",
      "\n",
      "- **Summer:** Shop A sells more chocolate ðŸ¦\n",
      "- **Winter:** Shop A sells more chocolate ðŸ¦\n",
      "\n",
      "So Shop A is better, right?\n",
      "\n",
      "**BUT WAIT!** \n",
      "\n",
      "When you add summer AND winter together, Shop B actually sold MORE chocolate overall! ðŸ¤¯\n",
      "\n",
      "---\n",
      "\n",
      "## Why does this happen?\n",
      "\n",
      "Shop A was super busy in summer (sold tons of ice cream), so even though it had a smaller percentage of chocolate sales, the total was big.\n",
      "\n",
      "Shop B was quieter in summer but had a HUGE winter, and winter customers loved chocolate more!\n",
      "\n",
      "---\n",
      "\n",
      "## The trick:\n",
      "\n",
      "**The groups are different sizes!** When you combine them wrong, the answer flips.\n",
      "\n",
      "It's like saying \"I'm taller than my friend in the morning, and taller at night, but he's taller on average!\" â€” it seems impossible but can happen with tricky numbers!\n",
      "\n",
      "**Lesson:** Always check *how many* people are in each group, not just the percentages! ðŸ“Š\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Change the model used"
   ],
   "metadata": {
    "id": "1Sc5hQt8p4hL"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import requests\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import ModelRequest, ModelResponse, dynamic_prompt\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langchain_core.tools import create_retriever_tool\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "## Tools and Context\n",
    "@dataclass\n",
    "class Context:\n",
    "  user_role : str\n",
    "\n",
    "@dynamic_prompt\n",
    "def user_role_prompt(request: ModelRequest, user_role: str = None) -> str:\n",
    "  base_prompt = 'You are a helpful and very concise assistant.'\n",
    "\n",
    "  # Can change this to connect to DB instead\n",
    "  dict_role = {\n",
    "        'expert': f'{base_prompt} Provide detailed technical response',\n",
    "        'beginner': f'{base_prompt} Keep it simple and basic',\n",
    "        'child': f'{base_prompt} Explained it like if you were teaching it to a child'\n",
    "    }\n",
    "\n",
    "  # Use provided user_id or fall back to context user_id\n",
    "  try :\n",
    "    lookup_id = user_role if user_role else request.runtime.context.user_role\n",
    "  except :\n",
    "    lookup_id = 'unknown'\n",
    "\n",
    "  return dict_role.get(lookup_id, base_prompt)\n",
    "\n",
    "## Make agent that can switch base model based on task complexity\n",
    "class AdaptiveAgent:\n",
    "    def __init__(self):\n",
    "        self.classifier = init_chat_model(\n",
    "            model=\"claude-haiku-4-5-20251001\",\n",
    "            temperature=0\n",
    "        )\n",
    "\n",
    "    def detect_user_role(self, question: str, context: Context) -> str:\n",
    "      \"\"\"\n",
    "      Automatically detect user role from the question text.\n",
    "\n",
    "      Looks for keywords like:\n",
    "      - \"child\", \"kid\", \"ELI5\" â†’ child\n",
    "      - \"beginner\", \"simple\", \"basic\" â†’ beginner\n",
    "      - \"expert\", \"technical\", \"detailed\" â†’ expert\n",
    "      \"\"\"\n",
    "\n",
    "      # Extract text from HumanMessage if needed\n",
    "      if isinstance(question, HumanMessage):\n",
    "          # Extract text from content\n",
    "          if isinstance(question.content, list):\n",
    "              text = ' '.join([item.get('text', '') for item in question.content if item.get('type') == 'text'])\n",
    "          else:\n",
    "              text = question.content\n",
    "      else:\n",
    "          text = str(question)\n",
    "\n",
    "      text_lower = text.lower()\n",
    "      list_indicator = []\n",
    "\n",
    "\n",
    "      # Check for child indicators\n",
    "      child_keywords = ['child', 'kid', 'eli5', \"i'm 5\", 'like i\\'m a child', 'teaching a child', 'for a child']\n",
    "      if any(keyword in text_lower for keyword in child_keywords):\n",
    "        list_indicator.append('child')\n",
    "\n",
    "      # Check for expert indicators\n",
    "      expert_keywords = ['expert', 'technical', 'advanced', 'detailed', 'in-depth', 'comprehensive']\n",
    "      if any(keyword in text_lower for keyword in expert_keywords):\n",
    "        list_indicator.append('expert')\n",
    "\n",
    "      # Check for beginner indicators\n",
    "      beginner_keywords = ['beginner', 'simple', 'basic', 'easy', 'new to', 'just started', 'general']\n",
    "      if any(keyword in text_lower for keyword in beginner_keywords):\n",
    "        list_indicator.append('beginner')\n",
    "\n",
    "      # Check ambiguity\n",
    "      if context is not None :\n",
    "        print(f'User Role is manually configured by the user')\n",
    "        print(f'User Role Detected : {context.user_role}')\n",
    "      elif len(list_indicator) == 1 :\n",
    "        print(f'User Role is identified by the basic Regex')\n",
    "        print(f'User Role Detected : {list_indicator[0]}')\n",
    "        return list_indicator[0]\n",
    "      else :\n",
    "        print(f'User Role is ambiguous, running LLM detection')\n",
    "\n",
    "        prompt = f\"\"\"Classify as child/beginner/expert:\n",
    "\n",
    "            {question}\n",
    "\n",
    "            child: If the way that the question suggest it's being asked by a child or to help explain it to a child\n",
    "            beginner: If the way that the question suggest it's being asked by a normal user or to help explain it in generanl\n",
    "            expert: If the way that the question suggest it's being asked by a professional that is expert in the domain\n",
    "\n",
    "            Reply ONLY: child, beginner, or expert\n",
    "\n",
    "            If you are unsure on the classification, can return beginner\n",
    "\n",
    "            \"\"\"\n",
    "\n",
    "        response = self.classifier.invoke(prompt)\n",
    "        print(f'User Role Detected : {response.content.strip().lower()}')\n",
    "\n",
    "        return response.content.strip().lower()\n",
    "\n",
    "\n",
    "    def classify_complexity(self, question: str) -> str:\n",
    "        \"\"\"Classify question complexity\"\"\"\n",
    "        prompt = f\"\"\"Classify as SIMPLE/MEDIUM/COMPLEX:\n",
    "\n",
    "            {question}\n",
    "\n",
    "            SIMPLE: Basic facts, greetings, simple lookups\n",
    "            MEDIUM: Explanations, summaries, analysis\n",
    "            COMPLEX: Deep analysis, multi-step reasoning, research\n",
    "\n",
    "            Reply ONLY: SIMPLE, MEDIUM, or COMPLEX\"\"\"\n",
    "\n",
    "        response = self.classifier.invoke(prompt)\n",
    "\n",
    "        return response.content.strip().upper()\n",
    "\n",
    "    def create_agent_for_complexity(self, complexity: str, tools: list, middleware: list, checkpointer: InMemorySaver):\n",
    "        \"\"\"Create agent with appropriate model\"\"\"\n",
    "\n",
    "        model_map = {\n",
    "            \"SIMPLE\": \"claude-haiku-4-5-20251001\",\n",
    "            \"MEDIUM\": \"claude-haiku-4-5-20251001\",\n",
    "            \"COMPLEX\": \"claude-sonnet-4-5-20250929\"\n",
    "        }\n",
    "\n",
    "        model = model_map.get(complexity, \"claude-haiku-4-5-20251001\")\n",
    "        llm = init_chat_model(model=model, temperature=0.1)\n",
    "\n",
    "        print(f\"ðŸŽ¯ Creating agent with {model}\")\n",
    "\n",
    "        return create_agent(\n",
    "            model=llm,\n",
    "            middleware=middleware,\n",
    "            tools=tools,\n",
    "            system_prompt=\"You are a helpful assistant.\",\n",
    "            checkpointer = checkpointer\n",
    "        )\n",
    "\n",
    "    def invoke(self, question: str, tools: list, middleware: list, checkpointer: InMemorySaver, config: dict, context: Context = None):\n",
    "        \"\"\"Smart agent invocation\"\"\"\n",
    "\n",
    "        # Classify question complexiy\n",
    "        complexity = self.classify_complexity(question)\n",
    "        print(f\"ðŸ“Š Classified as: {complexity}\")\n",
    "\n",
    "        # Classify user role\n",
    "        user_role = self.detect_user_role(question, context)\n",
    "\n",
    "        # Create appropriate agent\n",
    "        agent = self.create_agent_for_complexity(complexity, tools, middleware, checkpointer)\n",
    "\n",
    "        # Invoke\n",
    "        response = agent.invoke(\n",
    "            {\"messages\": [question]},\n",
    "            context=context or Context(user_role=\"beginner\"),\n",
    "            config = config,\n",
    "        )\n",
    "\n",
    "        return response\n",
    "\n",
    "\n",
    "# Building agent and used it to answer question\n",
    "checkpointer = InMemorySaver() # to make the LLM remember the past prompt context\n",
    "agent = AdaptiveAgent()\n",
    "config = {'configurable': {'thread_id': 1}} # to determine the \"session_id\", if this change the previous context is lost\n",
    "\n",
    "message = HumanMessage(\n",
    "    content=[\n",
    "      {'type':'text', 'text':'Explain simpson paradox in statistics'},\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = agent.invoke(\n",
    "    message,\n",
    "    tools = [],\n",
    "    middleware = [user_role_prompt],\n",
    "    checkpointer = checkpointer,\n",
    "    config = config,\n",
    "    context = Context(user_role='child')\n",
    ")\n",
    "\n",
    "print(f'\\nPrompt : {response['messages'][-2].content}')\n",
    "print(f'Answer : {response['messages'][-1].content}')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7IJDjaW3nfac",
    "outputId": "be0368a0-7f70-429e-a367-bce43669ad9f"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ðŸ“Š Classified as: MEDIUM\n",
      "User Role is manually configured by the user\n",
      "User Role Detected : child\n",
      "ðŸŽ¯ Creating agent with claude-haiku-4-5-20251001\n",
      "\n",
      "Prompt : [{'type': 'text', 'text': 'Explain simpson paradox in statistics'}]\n",
      "Answer : # Simpson's Paradox - Simple Explanation\n",
      "\n",
      "Imagine you're comparing two basketball players:\n",
      "\n",
      "**Player A vs Player B**\n",
      "\n",
      "- **Game 1:** Player A makes 9 out of 10 shots. Player B makes 1 out of 2 shots.\n",
      "  - A is better! âœ“\n",
      "\n",
      "- **Game 2:** Player A makes 1 out of 10 shots. Player B makes 9 out of 10 shots.\n",
      "  - B is better! âœ“\n",
      "\n",
      "**But here's the trick:** If you combine both games:\n",
      "- Player A: 10 out of 20 shots (50%)\n",
      "- Player B: 10 out of 12 shots (83%)\n",
      "\n",
      "**B is better overall!** ðŸ¤”\n",
      "\n",
      "Even though A was better in EACH game separately, B is better when you add everything together!\n",
      "\n",
      "## Why does this happen?\n",
      "\n",
      "Player B played way more shots in the game where they were hot. Player A played more shots when they were cold. So the \"mix\" matters!\n",
      "\n",
      "**The lesson:** Sometimes what's true for each group separately isn't true when you combine them. You have to be careful when adding things up!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "message = HumanMessage(\n",
    "    content=[\n",
    "      {'type':'text', 'text':\"How about if you want to explain it to an expert\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = agent.invoke(\n",
    "    message,\n",
    "    tools = [],\n",
    "    middleware = [user_role_prompt],\n",
    "    checkpointer = checkpointer,\n",
    "    config = config,\n",
    ")\n",
    "\n",
    "print(f'\\nPrompt : {response['messages'][-2].content}')\n",
    "print(f'Answer : {response['messages'][-1].content}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r5PjrWkxqNwB",
    "outputId": "7e61f321-fdb6-45c9-d013-e59f21a2dc3c"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ðŸ“Š Classified as: MEDIUM\n",
      "User Role is identified by the basic Regex\n",
      "User Role Detected : expert\n",
      "ðŸŽ¯ Creating agent with claude-haiku-4-5-20251001\n",
      "\n",
      "Prompt : [{'type': 'text', 'text': 'How about if you want to explain it to an expert'}]\n",
      "Answer : # Simpson's Paradox - Technical Explanation\n",
      "\n",
      "Simpson's Paradox occurs when a trend reverses when data is aggregated across subgroups, violating the principle of monotonicity in comparative statistics.\n",
      "\n",
      "## Formal Definition\n",
      "\n",
      "For variables X, Y, and stratifying variable Z:\n",
      "- P(Y|X, Z=z) may favor X over X' for all z\n",
      "- Yet P(Y|X) favors X' over X when Z is marginalized out\n",
      "\n",
      "This arises from **confounding by Z** and unequal sample sizes across strata.\n",
      "\n",
      "## Mathematical Mechanism\n",
      "\n",
      "The reversal stems from Simpson's inequality:\n",
      "\n",
      "$$\\frac{a}{b} > \\frac{c}{d} \\text{ and } \\frac{a'}{b'} > \\frac{c'}{d'} \\not\\Rightarrow \\frac{a+a'}{b+b'} > \\frac{c+c'}{d+d'}$$\n",
      "\n",
      "The weights (denominators) determine the aggregate relationship.\n",
      "\n",
      "## Causal Interpretation\n",
      "\n",
      "- **Confounding:** Z is a common cause of both X and Y; stratification removes bias\n",
      "- **Collider bias:** Conditioning on Z (a common effect) can induce spurious associations\n",
      "- **Selection bias:** Non-random assignment to strata\n",
      "\n",
      "## Resolution\n",
      "\n",
      "Requires causal reasoning via DAGs to determine whether to:\n",
      "1. **Stratify** (if Z confounds)\n",
      "2. **Marginalize** (if Z is a mediator or collider)\n",
      "\n",
      "The paradox highlights that statistical association â‰  causal effect.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "message = HumanMessage(\n",
    "    content=[\n",
    "      {'type':'text', 'text':\"What's 1 + 1\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = agent.invoke(\n",
    "    message,\n",
    "    tools = [],\n",
    "    middleware = [user_role_prompt],\n",
    "    checkpointer = checkpointer,\n",
    "    config = config,\n",
    "    # context = Context(user_role='expert')\n",
    ")\n",
    "\n",
    "print(f'\\nPrompt : {response['messages'][-2].content}')\n",
    "print(f'Answer : {response['messages'][-1].content}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DLKvP_GbxQeM",
    "outputId": "23469b21-cd98-4b5f-d233-42afe3e50fa0"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ðŸ“Š Classified as: SIMPLE\n",
      "User Role is ambiguous, running LLM detection\n",
      "User Role Detected : child\n",
      "ðŸŽ¯ Creating agent with claude-haiku-4-5-20251001\n",
      "\n",
      "Prompt : [{'type': 'text', 'text': \"What's 1 + 1\"}]\n",
      "Answer : 2\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "message = HumanMessage(\n",
    "    content=[\n",
    "      {'type':'text', 'text':\"I have a child, and I want to learn about parenting in general can you recommend me any tips\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = agent.invoke(\n",
    "    message,\n",
    "    tools = [],\n",
    "    middleware = [user_role_prompt],\n",
    "    checkpointer = checkpointer,\n",
    "    config = config,\n",
    "    # context = Context(user_role='expert')\n",
    ")\n",
    "\n",
    "print(f'\\nPrompt : {response['messages'][-2].content}')\n",
    "print(f'Answer : {response['messages'][-1].content}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7f1TL6Q3xadL",
    "outputId": "d7567fc2-c520-4634-95ba-a34aabd093df"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ðŸ“Š Classified as: MEDIUM\n",
      "User Role is ambiguous, running LLM detection\n",
      "User Role Detected : beginner\n",
      "ðŸŽ¯ Creating agent with claude-haiku-4-5-20251001\n",
      "\n",
      "Prompt : [{'type': 'text', 'text': 'I have a child, and I want to learn about parenting in general can you recommend me any tips'}]\n",
      "Answer : # Basic Parenting Tips\n",
      "\n",
      "**Communication & Connection**\n",
      "- Listen actively to your child\n",
      "- Spend quality one-on-one time regularly\n",
      "- Explain rules clearly and calmly\n",
      "\n",
      "**Discipline & Boundaries**\n",
      "- Set consistent, age-appropriate limits\n",
      "- Use natural consequences rather than punishment\n",
      "- Stay calm when enforcing rules\n",
      "\n",
      "**Emotional Development**\n",
      "- Validate their feelings\n",
      "- Model emotional regulation\n",
      "- Praise effort, not just results\n",
      "\n",
      "**Health & Safety**\n",
      "- Establish routines (sleep, meals, exercise)\n",
      "- Limit screen time\n",
      "- Ensure adequate physical activity\n",
      "\n",
      "**Self-Care**\n",
      "- Take care of your own mental health\n",
      "- Don't aim for perfection\n",
      "- Ask for help when needed\n",
      "\n",
      "**Resources**\n",
      "- Read books like \"The Whole-Brain Child\" or \"Parenting with Love and Logic\"\n",
      "- Consider parenting classes in your community\n",
      "- Talk to your pediatrician\n",
      "\n",
      "**Key Principle:** Every child is different. What works for one may not work for anotherâ€”stay flexible and patient with yourself.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "_8NLvogM5Zy6"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}